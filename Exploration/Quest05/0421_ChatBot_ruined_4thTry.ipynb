{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c780dc",
   "metadata": {},
   "source": [
    "# 프로젝트: 한국어 데이터로 챗봇 만들기 C1 류지호"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe774284",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집 및 전처리 개선\n",
    "\n",
    "- data 수집: Songys, KorQuAD 등 다양한 한국어 대화/질의응답 데이터를 통합 수집\n",
    "- 수행한 전처리 과정: 불필요한 특수문자/불용어 제거, 형태소 분석, 중복 및 품질 저하 샘플 필터링 \n",
    "- 결과: 데이터 손실 없이 99% 이상 보존된 고품질 대화 데이터셋 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c67fa",
   "metadata": {},
   "source": [
    "### 1-1. 필요 라이브러리 설치 및 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89871e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 버전: 2.6.0\n",
      "GPU 사용 가능 여부: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (4.6.3)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.9/site-packages (from konlpy) (1.21.4)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (2.26.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.11.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.19)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.0.17->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: soynlp in /opt/conda/lib/python3.9/site-packages (0.0.493)\n",
      "Requirement already satisfied: psutil>=5.0.1 in /opt/conda/lib/python3.9/site-packages (from soynlp) (5.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.9/site-packages (from soynlp) (1.0)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /opt/conda/lib/python3.9/site-packages (from soynlp) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from soynlp) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.20.0->soynlp) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.9/site-packages (2.14.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.9/site-packages (1.8.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.9/site-packages (from wordcloud) (1.21.4)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.9/site-packages (from wordcloud) (8.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.21.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (1.9.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (4.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.9/site-packages (4.12.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from pymongo) (2.7.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# 경고 메시지 필터링\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"chatbot_preprocessing.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "print(\"TensorFlow 버전:\", tf.__version__)\n",
    "print(\"GPU 사용 가능 여부:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# KoNLPy 형태소 분석기 및 필요 라이브러리 설치\n",
    "!pip install konlpy\n",
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install soynlp\n",
    "!pip install emoji\n",
    "!pip install wordcloud\n",
    "!pip install gensim\n",
    "!pip install torch\n",
    "!pip install pymongo\n",
    "\n",
    "# 한국어 NLP 관련 라이브러리 임포트\n",
    "from konlpy.tag import Mecab, Okt, Hannanum, Kkma\n",
    "from transformers import BertModel, BertTokenizer, ElectraModel, ElectraTokenizer\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "from soynlp.word import WordExtractor\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b025f2a6",
   "metadata": {},
   "source": [
    "### 1-2 기본 오픈소스 대화 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee1a37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:35,833 - __main__ - INFO - songys_chatbot 데이터셋 로드 중...\n",
      "2025-04-21 01:54:35,834 - __main__ - INFO - 파일 ChatbotData.csv이(가) 이미 존재합니다.\n",
      "2025-04-21 01:54:35,864 - __main__ - INFO - songys_chatbot 데이터셋 크기: 11823\n",
      "2025-04-21 01:54:35,865 - __main__ - INFO - songys_chatbot 데이터셋 컬럼: ['Q', 'A', 'label']\n",
      "2025-04-21 01:54:35,865 - __main__ - INFO - songys_chatbot 데이터셋 미리보기:\n",
      "2025-04-21 01:54:35,870 - __main__ - INFO - korquad 데이터셋 로드 중...\n",
      "2025-04-21 01:54:35,871 - __main__ - INFO - 파일 KorQuAD_train.json이(가) 이미 존재합니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:36,620 - __main__ - INFO - korquad 데이터셋 크기: 1420\n",
      "2025-04-21 01:54:36,621 - __main__ - INFO - aihub_sample 데이터셋 로드 중...\n",
      "2025-04-21 01:54:36,622 - __main__ - WARNING - aihub_dialog_sample.csv은(는) 수동으로 다운로드해야 합니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 대화 데이터셋 크기: 11823\n",
      "기본 대화 데이터셋 샘플:\n",
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 저장 디렉토리 생성\n",
    "data_dir = \"chatbot_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# 챗봇 데이터셋 목록 정의\n",
    "datasets = {\n",
    "    \"songys_chatbot\": {\n",
    "        \"url\": \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n",
    "        \"filename\": \"ChatbotData.csv\",\n",
    "        \"type\": \"csv\"\n",
    "    },\n",
    "    \"korquad\": {\n",
    "        \"url\": \"https://korquad.github.io/dataset/KorQuAD_v1.0_train.json\",\n",
    "        \"filename\": \"KorQuAD_train.json\",\n",
    "        \"type\": \"json\"\n",
    "    },\n",
    "    \"aihub_sample\": {\n",
    "        \"url\": None,  # 직접 다운로드 필요\n",
    "        \"filename\": \"aihub_dialog_sample.csv\",\n",
    "        \"type\": \"csv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 데이터셋 다운로드 및 로드 함수\n",
    "def download_dataset(dataset_info):\n",
    "    filepath = os.path.join(data_dir, dataset_info[\"filename\"])\n",
    "    \n",
    "    # 파일이 이미 존재하는지 확인\n",
    "    if os.path.exists(filepath):\n",
    "        logger.info(f\"파일 {dataset_info['filename']}이(가) 이미 존재합니다.\")\n",
    "    elif dataset_info[\"url\"] is not None:\n",
    "        logger.info(f\"{dataset_info['filename']} 다운로드 중...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(dataset_info[\"url\"], filepath)\n",
    "            logger.info(f\"{dataset_info['filename']} 다운로드 완료!\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{dataset_info['filename']} 다운로드 실패: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        logger.warning(f\"{dataset_info['filename']}은(는) 수동으로 다운로드해야 합니다.\")\n",
    "        return None\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "def load_dataset(dataset_info):\n",
    "    filepath = download_dataset(dataset_info)\n",
    "    if filepath is None:\n",
    "        return None\n",
    "    \n",
    "    if dataset_info[\"type\"] == \"csv\":\n",
    "        try:\n",
    "            return pd.read_csv(filepath)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{filepath} 로드 실패: {e}\")\n",
    "            return None\n",
    "    elif dataset_info[\"type\"] == \"json\":\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{filepath} 로드 실패: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        logger.error(f\"지원하지 않는 파일 형식: {dataset_info['type']}\")\n",
    "        return None\n",
    "\n",
    "# 각 데이터셋 로드\n",
    "loaded_datasets = {}\n",
    "for name, info in datasets.items():\n",
    "    logger.info(f\"{name} 데이터셋 로드 중...\")\n",
    "    data = load_dataset(info)\n",
    "    if data is not None:\n",
    "        loaded_datasets[name] = data\n",
    "        \n",
    "        # 데이터셋 정보 출력\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            logger.info(f\"{name} 데이터셋 크기: {len(data)}\")\n",
    "            logger.info(f\"{name} 데이터셋 컬럼: {data.columns.tolist()}\")\n",
    "            logger.info(f\"{name} 데이터셋 미리보기:\")\n",
    "            print(data.head())\n",
    "        elif name == \"korquad\":\n",
    "            logger.info(f\"{name} 데이터셋 크기: {len(data['data'])}\")\n",
    "            \n",
    "# 기본 대화 데이터셋 (songys)\n",
    "main_chat_data = loaded_datasets.get(\"songys_chatbot\")\n",
    "if main_chat_data is not None:\n",
    "    print(f\"기본 대화 데이터셋 크기: {len(main_chat_data)}\")\n",
    "    print(f\"기본 대화 데이터셋 샘플:\\n{main_chat_data.head()}\")\n",
    "else:\n",
    "    logger.error(\"기본 대화 데이터셋을 로드할 수 없습니다.\")\n",
    "    main_chat_data = pd.DataFrame(columns=[\"Q\", \"A\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace4108",
   "metadata": {},
   "source": [
    "### 1-3 추가 데이터 수집 및 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ec3fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:36,721 - __main__ - INFO - KorQuAD Q&A 변환 결과: 60407개\n",
      "2025-04-21 01:54:36,726 - __main__ - INFO - KorQuAD 데이터 샘플링: 1000개\n",
      "2025-04-21 01:54:36,726 - __main__ - INFO - 웹 크롤링 시뮬레이션: 10개 대화 데이터 생성\n",
      "2025-04-21 01:54:36,728 - __main__ - INFO - 사용자 정의 대화 데이터: 10개 생성\n",
      "2025-04-21 01:54:36,745 - __main__ - INFO - 통합 데이터셋 크기: 12770\n",
      "2025-04-21 01:54:36,746 - __main__ - INFO - 출처별 데이터 수: {'songys': 11750, 'korquad': 1000, 'simulated': 10, 'custom': 10}\n",
      "2025-04-21 01:54:36,777 - __main__ - INFO - 통합 데이터셋 저장 완료: chatbot_data/combined_chat_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "통합 데이터셋 샘플:\n",
      "                 Q            A  source\n",
      "0           12시 땡!   하루가 또 가네요.  songys\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.  songys\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.  songys\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.  songys\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.  songys\n"
     ]
    }
   ],
   "source": [
    "# KorQuAD 데이터를 Q&A 형식으로 변환하는 함수\n",
    "def convert_korquad_to_qa(korquad_data):\n",
    "    qa_pairs = []\n",
    "    \n",
    "    try:\n",
    "        for article in korquad_data[\"data\"]:\n",
    "            for paragraph in article[\"paragraphs\"]:\n",
    "                context = paragraph[\"context\"]\n",
    "                for qa in paragraph[\"qas\"]:\n",
    "                    question = qa[\"question\"]\n",
    "                    if qa[\"answers\"]:\n",
    "                        answer = qa[\"answers\"][0][\"text\"]\n",
    "                        qa_pairs.append({\"Q\": question, \"A\": answer, \"context\": context})\n",
    "    except Exception as e:\n",
    "        logger.error(f\"KorQuAD 데이터 변환 중 오류: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(qa_pairs)\n",
    "\n",
    "# 크롤링 시뮬레이션 함수 (실제 프로젝트에서는 웹 크롤링으로 대체)\n",
    "def simulate_web_crawling():\n",
    "    # 예시 대화 데이터 (실제로는 웹에서 크롤링)\n",
    "    simulated_dialogues = [\n",
    "        {\"Q\": \"오늘 날씨 어때?\", \"A\": \"오늘은 맑고 화창한 날씨예요.\", \"source\": \"simulated\"},\n",
    "        {\"Q\": \"점심 뭐 먹을까?\", \"A\": \"오늘은 한식 어떠세요?\", \"source\": \"simulated\"},\n",
    "        {\"Q\": \"내일 계획 있어?\", \"A\": \"아직 특별한 계획은 없습니다.\", \"source\": \"simulated\"},\n",
    "        {\"Q\": \"영화 추천해줘\", \"A\": \"요즘 '인터스텔라'가 인기 있어요.\", \"source\": \"simulated\"},\n",
    "        {\"Q\": \"주말에 뭐해?\", \"A\": \"친구들과 만나기로 했어요.\", \"source\": \"simulated\"},\n",
    "        # 추가 대화 예시\n",
    "        {\"Q\": \"한국어 공부하는 방법 알려줘\", \"A\": \"매일 조금씩 듣고 말하는 연습을 하는 것이 중요해요.\", \"source\": \"simulated\"},\n",
    "        {\"Q\": \"서울에서 가볼만한 곳 추천해줘\", \"A\": \"경복궁, 남산타워, 한강공원 등이 인기 있는 관광지입니다.\", \"source\": \"simulated\"},\n",
    "        {\"Q\": \"이번 주말 날씨 어때?\", \"A\": \"이번 주말은 비 소식이 있어요. 우산 챙기세요.\", \"source\": \"simulated\"},\n",
    "        {\"Q\": \"한국 음식 중에 추천해줄 만한 거 있어?\", \"A\": \"비빔밥, 불고기, 김치찌개 등이 외국인들에게도 인기가 많아요.\", \"source\": \"simulated\"},\n",
    "        {\"Q\": \"한국어로 '감사합니다'는 어떻게 말해?\", \"A\": \"'감사합니다'라고 말하면 됩니다. 격식 없이는 '고마워요'라고도 해요.\", \"source\": \"simulated\"}\n",
    "    ]\n",
    "    \n",
    "    logger.info(f\"웹 크롤링 시뮬레이션: {len(simulated_dialogues)}개 대화 데이터 생성\")\n",
    "    return pd.DataFrame(simulated_dialogues)\n",
    "\n",
    "# 사용자 정의 데이터 생성\n",
    "def create_custom_dialogues():\n",
    "    custom_qa_pairs = [\n",
    "        {\"Q\": \"너는 누구야?\", \"A\": \"저는 한국어로 대화하는 AI 챗봇입니다.\", \"category\": \"소개\"},\n",
    "        {\"Q\": \"뭘 도와줄 수 있어?\", \"A\": \"대화, 정보 검색, 추천 등 다양한 주제로 도움을 드릴 수 있어요.\", \"category\": \"소개\"},\n",
    "        {\"Q\": \"오늘 기분이 안 좋아\", \"A\": \"무슨 일이 있으셨나요? 제가 기분 전환에 도움이 되고 싶어요.\", \"category\": \"감정\"},\n",
    "        {\"Q\": \"재미있는 이야기 해줘\", \"A\": \"옛날 옛적에 한 마을에 재미있는 이야기꾼이 살았습니다...\", \"category\": \"엔터테인먼트\"},\n",
    "        {\"Q\": \"시간이 몇이야?\", \"A\": \"제가 실시간 시계에 접근할 수 없어서 정확한 시간을 알려드리지 못해요. 기기의 시간을 확인해주세요.\", \"category\": \"일반\"},\n",
    "        # 추가 대화 예시\n",
    "        {\"Q\": \"한국의 수도는?\", \"A\": \"한국의 수도는 서울입니다.\", \"category\": \"지식\"},\n",
    "        {\"Q\": \"인공지능이 뭐야?\", \"A\": \"인공지능은 인간의 학습능력, 추론능력, 지각능력을 인공적으로 구현한 컴퓨터 시스템입니다.\", \"category\": \"지식\"},\n",
    "        {\"Q\": \"오늘 날씨 어때?\", \"A\": \"제가 실시간 날씨 정보에 접근할 수 없어요. 날씨 앱이나 웹사이트를 확인해보세요.\", \"category\": \"일반\"},\n",
    "        {\"Q\": \"슬퍼\", \"A\": \"무슨 일이 있으신가요? 이야기 나누고 싶으시면 저에게 말씀해주세요.\", \"category\": \"감정\"},\n",
    "        {\"Q\": \"좋아하는 음식이 뭐야?\", \"A\": \"저는 AI라서 실제로 음식을 먹지 않지만, 한국 음식에 대해 많이 배웠어요.\", \"category\": \"소개\"}\n",
    "    ]\n",
    "    \n",
    "    logger.info(f\"사용자 정의 대화 데이터: {len(custom_qa_pairs)}개 생성\")\n",
    "    return pd.DataFrame(custom_qa_pairs)\n",
    "\n",
    "# 데이터 통합\n",
    "# 1. KorQuAD 데이터 변환 (있는 경우)\n",
    "korquad_qa = None\n",
    "if \"korquad\" in loaded_datasets:\n",
    "    korquad_qa = convert_korquad_to_qa(loaded_datasets[\"korquad\"])\n",
    "    logger.info(f\"KorQuAD Q&A 변환 결과: {len(korquad_qa)}개\")\n",
    "    # 샘플링하여 데이터 크기 관리\n",
    "    if len(korquad_qa) > 1000:\n",
    "        korquad_qa = korquad_qa.sample(1000, random_state=42)\n",
    "        logger.info(f\"KorQuAD 데이터 샘플링: 1000개\")\n",
    "\n",
    "# 2. 웹 크롤링 데이터 (시뮬레이션)\n",
    "crawled_data = simulate_web_crawling()\n",
    "\n",
    "# 3. 사용자 정의 데이터\n",
    "custom_data = create_custom_dialogues()\n",
    "\n",
    "# 4. 데이터 통합\n",
    "all_chat_data = []\n",
    "\n",
    "# 기본 대화 데이터 추가\n",
    "if main_chat_data is not None:\n",
    "    main_chat_data['source'] = 'songys'\n",
    "    all_chat_data.append(main_chat_data[['Q', 'A', 'source']])\n",
    "\n",
    "# KorQuAD 데이터 추가 (있는 경우)\n",
    "if korquad_qa is not None:\n",
    "    korquad_qa['source'] = 'korquad'\n",
    "    all_chat_data.append(korquad_qa[['Q', 'A', 'source']])\n",
    "\n",
    "# 크롤링 데이터 추가\n",
    "all_chat_data.append(crawled_data[['Q', 'A', 'source']])\n",
    "\n",
    "# 사용자 정의 데이터 추가\n",
    "custom_data['source'] = 'custom'\n",
    "all_chat_data.append(custom_data[['Q', 'A', 'source']])\n",
    "\n",
    "# 데이터프레임 병합\n",
    "combined_df = pd.concat(all_chat_data, ignore_index=True)\n",
    "\n",
    "# 중복 제거\n",
    "combined_df = combined_df.drop_duplicates(subset=['Q', 'A'])\n",
    "\n",
    "logger.info(f\"통합 데이터셋 크기: {len(combined_df)}\")\n",
    "logger.info(f\"출처별 데이터 수: {combined_df['source'].value_counts().to_dict()}\")\n",
    "print(f\"통합 데이터셋 샘플:\\n{combined_df.head()}\")\n",
    "\n",
    "# 데이터셋 저장\n",
    "combined_df.to_csv(os.path.join(data_dir, 'combined_chat_data.csv'), index=False)\n",
    "logger.info(f\"통합 데이터셋 저장 완료: {os.path.join(data_dir, 'combined_chat_data.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132c7e1",
   "metadata": {},
   "source": [
    "### 1-4 데이터 기본 통계 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da458c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:36,792 - __main__ - INFO - 데이터 분석 시작...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 대화 쌍: 12770\n",
      "질문 평균 길이: 14.47\n",
      "질문 최대 길이: 86\n",
      "질문 최소 길이: 1\n",
      "응답 평균 길이: 14.30\n",
      "응답 최대 길이: 77\n",
      "응답 최소 길이: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyze_chat_data(df):\n",
    "    logger.info(\"데이터 분석 시작...\")\n",
    "    \n",
    "    # 기본 통계\n",
    "    q_lengths = df['Q'].apply(len)\n",
    "    a_lengths = df['A'].apply(len)\n",
    "    \n",
    "    stats = {\n",
    "        \"총 대화 쌍\": len(df),\n",
    "        \"질문 평균 길이\": q_lengths.mean(),\n",
    "        \"질문 최대 길이\": q_lengths.max(),\n",
    "        \"질문 최소 길이\": q_lengths.min(),\n",
    "        \"응답 평균 길이\": a_lengths.mean(),\n",
    "        \"응답 최대 길이\": a_lengths.max(),\n",
    "        \"응답 최소 길이\": a_lengths.min()\n",
    "    }\n",
    "    \n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key}: {value:.2f}\" if isinstance(value, float) else f\"{key}: {value}\")\n",
    "    \n",
    "    # 그래프 설정\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. 질문/답변 길이 분포\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(q_lengths, bins=50, alpha=0.5, color='blue', label='질문')\n",
    "    plt.hist(a_lengths, bins=50, alpha=0.5, color='green', label='답변')\n",
    "    plt.xlabel('문장 길이 (글자 수)')\n",
    "    plt.ylabel('빈도')\n",
    "    plt.title('질문과 답변의 길이 분포')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 2. 출처별 데이터 비율\n",
    "    plt.subplot(2, 2, 2)\n",
    "    source_counts = df['source'].value_counts()\n",
    "    plt.pie(source_counts, labels=source_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title('데이터 출처별 비율')\n",
    "    \n",
    "    # 3. 질문 길이와 답변 길이의 관계\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.scatter(q_lengths, a_lengths, alpha=0.3)\n",
    "    plt.xlabel('질문 길이')\n",
    "    plt.ylabel('답변 길이')\n",
    "    plt.title('질문 길이와 답변 길이의 관계')\n",
    "    \n",
    "    # 4. 가장 빈번한 단어 (상위 20개)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    # 간단한 단어 빈도 분석\n",
    "    try:\n",
    "        # Mecab이 있으면 사용, 없으면 단순 공백 분리\n",
    "        try:\n",
    "            from konlpy.tag import Mecab\n",
    "            mecab = Mecab()\n",
    "            all_words = []\n",
    "            for text in df['Q'].str.cat(df['A'], sep=' '):\n",
    "                all_words.extend(mecab.nouns(text))\n",
    "        except:\n",
    "            all_words = []\n",
    "            for text in df['Q'].str.cat(df['A'], sep=' ').split():\n",
    "                all_words.append(text)\n",
    "                \n",
    "        word_counts = Counter(all_words)\n",
    "        common_words = dict(word_counts.most_common(20))\n",
    "        \n",
    "        plt.bar(range(len(common_words)), list(common_words.values()), align='center')\n",
    "        plt.xticks(range(len(common_words)), list(common_words.keys()), rotation=45)\n",
    "        plt.title('가장 빈번한 단어 (상위 20개)')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"단어 빈도 분석 중 오류: {e}\")\n",
    "        plt.text(0.5, 0.5, '단어 빈도 분석 실패', horizontalalignment='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(data_dir, 'chat_data_analysis.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# 데이터 분석 실행\n",
    "data_stats = analyze_chat_data(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9e03b",
   "metadata": {},
   "source": [
    "### 1-5 고급 텍스트 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3aac5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:39,118 - __main__ - INFO - 고급 텍스트 패턴 분석 시작...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "감정 표현 패턴 분석:\n",
      "긍정: 1580개 (12.37%)\n",
      "부정: 723개 (5.66%)\n",
      "질문: 4435개 (34.73%)\n",
      "명령: 797개 (6.24%)\n",
      "인사: 333개 (2.61%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "자주 함께 등장하는 단어 쌍:\n",
      "여자 - 친구: 233회\n",
      "남자 - 친구: 213회\n",
      "사람 - 사랑: 54회\n",
      "남자 - 여자: 49회\n",
      "사람 - 생각: 21회\n",
      "무엇 - 이름: 21회\n",
      "사람 - 짝사랑: 20회\n",
      "고민 - 친구: 18회\n",
      "사람 - 사람: 17회\n",
      "여자 - 연락: 17회\n",
      "연락 - 친구: 16회\n",
      "이별 - 준비: 16회\n",
      "이별 - 통보: 16회\n",
      "마음 - 사람: 14회\n",
      "친구 - 친구: 14회\n",
      "개월 - 이별: 14회\n",
      "여자 - 짝사랑: 14회\n",
      "결혼 - 사랑: 14회\n",
      "누구 - 사람: 13회\n",
      "그녀 - 생각: 13회\n"
     ]
    }
   ],
   "source": [
    "def analyze_text_patterns(df):\n",
    "    logger.info(\"고급 텍스트 패턴 분석 시작...\")\n",
    "    \n",
    "    # 감정 표현 패턴 (이모티콘, 감정 표현 단어 등)\n",
    "    emotion_patterns = {\n",
    "        '긍정': r'좋아|감사|행복|멋지|최고|짱|좋은|ㅋㅋ|ㅎㅎ|😊|😄|♥|❤',\n",
    "        '부정': r'싫어|안좋|못해|실패|나쁜|힘들|어려|불행|슬픔|화나|ㅜㅜ|ㅠㅠ|😢|😭|😠',\n",
    "        '질문': r'\\?|\\？|어떻|언제|누구|얼마|왜|무엇|뭐|몇|까|나요|가요|래요|ㅇㅇ|진짜',\n",
    "        '명령': r'해주|해봐|알려|가르쳐|찾아|시작|종료|그만|중지|계속',\n",
    "        '인사': r'안녕|반가워|또봐|잘가|다음에|만나|하이|헬로|굿모닝|굿나잇'\n",
    "    }\n",
    "    \n",
    "    emotion_counts = {emotion: 0 for emotion in emotion_patterns}\n",
    "    \n",
    "    # 질문과 답변에서 감정 패턴 검출\n",
    "    for idx, row in df.iterrows():\n",
    "        for emotion, pattern in emotion_patterns.items():\n",
    "            if re.search(pattern, row['Q']) or re.search(pattern, row['A']):\n",
    "                emotion_counts[emotion] += 1\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"\\n감정 표현 패턴 분석:\")\n",
    "    for emotion, count in emotion_counts.items():\n",
    "        print(f\"{emotion}: {count}개 ({count/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # 시각화\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(emotion_counts.keys(), emotion_counts.values())\n",
    "    plt.title('감정 표현 패턴 분포')\n",
    "    plt.xlabel('감정 패턴')\n",
    "    plt.ylabel('발생 횟수')\n",
    "    plt.savefig(os.path.join(data_dir, 'emotion_pattern_analysis.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # 단어 네트워크 분석 (자주 함께 등장하는 단어 쌍)\n",
    "    try:\n",
    "        # 형태소 분석기 초기화\n",
    "        try:\n",
    "            from konlpy.tag import Mecab\n",
    "            mecab = Mecab()\n",
    "            tokenize = lambda text: mecab.nouns(text)\n",
    "        except:\n",
    "            tokenize = lambda text: text.split()\n",
    "        \n",
    "        # 동시 발생 단어 쌍 분석\n",
    "        word_pairs = defaultdict(int)\n",
    "        for text in df['Q']:\n",
    "            words = tokenize(text)\n",
    "            for i in range(len(words)-1):\n",
    "                for j in range(i+1, min(i+3, len(words))):\n",
    "                    if words[i] and words[j] and len(words[i]) > 1 and len(words[j]) > 1:\n",
    "                        word_pair = tuple(sorted([words[i], words[j]]))\n",
    "                        word_pairs[word_pair] += 1\n",
    "        \n",
    "        # 가장 빈번한 단어 쌍\n",
    "        common_pairs = dict(sorted(word_pairs.items(), key=lambda x: x[1], reverse=True)[:20])\n",
    "        \n",
    "        print(\"\\n자주 함께 등장하는 단어 쌍:\")\n",
    "        for pair, count in common_pairs.items():\n",
    "            print(f\"{pair[0]} - {pair[1]}: {count}회\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"단어 네트워크 분석 중 오류: {e}\")\n",
    "    \n",
    "    return emotion_counts\n",
    "\n",
    "# 텍스트 패턴 분석 실행\n",
    "emotion_stats = analyze_text_patterns(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba83ae1d",
   "metadata": {},
   "source": [
    "### 1-6 통합 한국어 전처리 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddae3554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:40,670 - __main__ - INFO - 한국어 텍스트 전처리기 초기화 중...\n",
      "2025-04-21 01:54:40,673 - __main__ - INFO - Mecab 형태소 분석기 초기화 성공\n",
      "2025-04-21 01:54:40,679 - __main__ - INFO - 한국어 텍스트 전처리기 초기화 완료\n",
      "2025-04-21 01:54:40,680 - __main__ - INFO - 데이터프레임 전처리 시작 (크기: 12770)\n",
      "2025-04-21 01:54:43,596 - __main__ - INFO - 데이터프레임 전처리 완료\n",
      "2025-04-21 01:54:43,672 - __main__ - INFO - 전처리된 데이터 저장 완료: chatbot_data/processed_chat_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 데이터 샘플:\n",
      "                 Q      Q_processed             Q_morphemes            A  \\\n",
      "0           12시 땡!          12시 땡 !                12 시 땡 !   하루가 또 가네요.   \n",
      "1      1지망 학교 떨어졌어      1지망 학교 떨어졌어           1 지망 학교 떨어졌 어    위로해 드립니다.   \n",
      "2     3박4일 놀러가고 싶다     3박4일 놀러가고 싶다     3 박 4 일 놀 러 가 고 싶 다  여행은 언제나 좋죠.   \n",
      "3  3박4일 정도 놀러가고 싶다  3박4일 정도 놀러가고 싶다  3 박 4 일 정도 놀 러 가 고 싶 다  여행은 언제나 좋죠.   \n",
      "4          PPL 심하네          PPL 심하네                PPL 심하 네   눈살이 찌푸려지죠.   \n",
      "\n",
      "    A_processed     A_morphemes  \n",
      "0   하루가 또 가네요 .   하루 가 또 가 네요 .  \n",
      "1    위로해 드립니다 .     위로 해 드립니다 .  \n",
      "2  여행은 언제나 좋죠 .  여행 은 언제나 좋 죠 .  \n",
      "3  여행은 언제나 좋죠 .  여행 은 언제나 좋 죠 .  \n",
      "4   눈살이 찌푸려지죠 .  눈살 이 찌푸려 지 죠 .  \n"
     ]
    }
   ],
   "source": [
    "class KoreanTextPreprocessor:\n",
    "    \"\"\"한국어 텍스트 전처리를 위한 통합 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, use_mecab=True, use_soynlp=True):\n",
    "        logger.info(\"한국어 텍스트 전처리기 초기화 중...\")\n",
    "        \n",
    "        # 형태소 분석기 초기화\n",
    "        self.morpheme_analyzer = None\n",
    "        if use_mecab:\n",
    "            try:\n",
    "                from konlpy.tag import Mecab\n",
    "                self.morpheme_analyzer = Mecab()\n",
    "                logger.info(\"Mecab 형태소 분석기 초기화 성공\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Mecab 초기화 실패: {e}\")\n",
    "                \n",
    "        if self.morpheme_analyzer is None:\n",
    "            try:\n",
    "                from konlpy.tag import Okt\n",
    "                self.morpheme_analyzer = Okt()\n",
    "                logger.info(\"Okt 형태소 분석기 초기화 성공\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Okt 초기화 실패: {e}\")\n",
    "                logger.error(\"형태소 분석 기능이 비활성화됩니다.\")\n",
    "        \n",
    "        # SoyNLP 사용 설정\n",
    "        self.use_soynlp = use_soynlp\n",
    "        \n",
    "        # 불용어 목록 로드\n",
    "        self.stopwords = self.load_stopwords()\n",
    "        \n",
    "        # 신조어 및 축약어 사전 초기화\n",
    "        self.slang_dict = self.initialize_slang_dict()\n",
    "        \n",
    "        # 정규표현식 패턴 컴파일\n",
    "        self.patterns = {\n",
    "            'url': re.compile(r'https?://\\S+|www\\.\\S+'),\n",
    "            'email': re.compile(r'\\S+@\\S+'),\n",
    "            'emoji_pattern': re.compile('['\n",
    "                u'\\U0001F600-\\U0001F64F'  # 이모티콘\n",
    "                u'\\U0001F300-\\U0001F5FF'  # 심볼 및 픽토그램\n",
    "                u'\\U0001F680-\\U0001F6FF'  # 교통 및 지도 심볼\n",
    "                u'\\U0001F700-\\U0001F77F'  # 알케미\n",
    "                u'\\U0001F780-\\U0001F7FF'  # 기하학적 모양\n",
    "                u'\\U0001F800-\\U0001F8FF'  # 부가적인 화살표\n",
    "                u'\\U0001F900-\\U0001F9FF'  # 부가적인 심볼\n",
    "                u'\\U0001FA00-\\U0001FA6F'  # 확장된 심볼\n",
    "                u'\\U00002702-\\U000027B0'  # 기타 심볼\n",
    "                u'\\U000024C2-\\U0001F251' \n",
    "                u'\\U0001f926-\\U0001f937'  # 사람 이모티콘\n",
    "                ']+'),\n",
    "            'special_chars': re.compile(r\"[^가-힣a-zA-Z0-9\\s?.!,~]\"),\n",
    "            'numbers': re.compile(r'\\d+'),\n",
    "            'multiple_spaces': re.compile(r'\\s+'),\n",
    "            'jamo_pattern': re.compile(r'[ㄱ-ㅎㅏ-ㅣ]{2,}')\n",
    "        }\n",
    "        \n",
    "        logger.info(\"한국어 텍스트 전처리기 초기화 완료\")\n",
    "    \n",
    "    def load_stopwords(self):\n",
    "        \"\"\"한국어 불용어 목록 로드\"\"\"\n",
    "        # 기본 불용어 목록 (최소화하여 중요 단어 보존)\n",
    "        basic_stopwords = {\n",
    "            '이', '그', '저', '것', '수', '등', '들', '에', '의', '가', \n",
    "            '과', '도', '를', '으로', '자', '에서', '와'\n",
    "        }\n",
    "        \n",
    "        # 추가 불용어 파일이 있으면 로드\n",
    "        try:\n",
    "            stopwords_file = os.path.join(data_dir, 'korean_stopwords.txt')\n",
    "            if os.path.exists(stopwords_file):\n",
    "                with open(stopwords_file, 'r', encoding='utf-8') as f:\n",
    "                    file_stopwords = set([line.strip() for line in f])\n",
    "                return basic_stopwords.union(file_stopwords)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"불용어 파일 로드 실패: {e}\")\n",
    "        \n",
    "        return basic_stopwords\n",
    "    \n",
    "    def initialize_slang_dict(self):\n",
    "        \"\"\"신조어 및 축약어 사전 초기화\"\"\"\n",
    "        # 기본 신조어/축약어 사전\n",
    "        slang_dict = {\n",
    "            # 축약어\n",
    "            'ㄱㅅ': '감사',\n",
    "            'ㄴㄴ': '노노',\n",
    "            'ㅇㅇ': '응응',\n",
    "            'ㅇㅋ': '오케이',\n",
    "            'ㅋㅋ': '웃음',\n",
    "            'ㅎㅎ': '웃음',\n",
    "            'ㄷㄷ': '덜덜',\n",
    "            'ㅠㅠ': '슬픔',\n",
    "            'ㅜㅜ': '슬픔',\n",
    "            'ㅡㅡ': '무표정',\n",
    "            \n",
    "            # 신조어\n",
    "            '갑툭튀': '갑자기 툭 튀어나온',\n",
    "            '꾸안꾸': '꾸민 듯 안 꾸민 듯',\n",
    "            '별다줄': '별 다른 줄거리',\n",
    "            '억텐': '억지 텐션',\n",
    "            '완내스': '완전 내 스타일',\n",
    "            '좋댓구알': '좋아요 댓글 구독 알림설정',\n",
    "            '케바케': '케이스 바이 케이스',\n",
    "            '점메추': '점심 메뉴 추천',\n",
    "            '소확행': '소소하지만 확실한 행복',\n",
    "            '인싸': '인사이더',\n",
    "            '아싸': '아웃사이더',\n",
    "            '스불재': '스스로 불러온 재앙',\n",
    "            '떡상': '급등',\n",
    "            '떡락': '급락',\n",
    "            '일코노미': '일 + 이코노미',\n",
    "            '핵불호': '매우 싫음',\n",
    "            '핵추': '매우 추천',\n",
    "            '꿀잼': '재미있음',\n",
    "            '노잼': '재미없음',\n",
    "            '자삭': '자가 삭제'\n",
    "        }\n",
    "        \n",
    "        # 추가 신조어 파일이 있으면 로드\n",
    "        try:\n",
    "            slang_file = os.path.join(data_dir, 'korean_slangs.json')\n",
    "            if os.path.exists(slang_file):\n",
    "                with open(slang_file, 'r', encoding='utf-8') as f:\n",
    "                    file_slangs = json.load(f)\n",
    "                slang_dict.update(file_slangs)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"신조어 파일 로드 실패: {e}\")\n",
    "        \n",
    "        return slang_dict\n",
    "    \n",
    "    def replace_emojis(self, text):\n",
    "        \"\"\"이모지를 텍스트로 변환\"\"\"\n",
    "        try:\n",
    "            return emoji.demojize(text)\n",
    "        except:\n",
    "            return text\n",
    "    \n",
    "    def normalize_text(self, text):\n",
    "        \"\"\"텍스트 정규화 (반복 문자 처리, 대소문자 등)\"\"\"\n",
    "        if self.use_soynlp:\n",
    "            try:\n",
    "                # SoyNLP의 반복 문자 정규화\n",
    "                text = repeat_normalize(text, num_repeats=2)\n",
    "            except:\n",
    "                # 간단한 정규화 대체\n",
    "                text = re.sub(r'([ㄱ-ㅎㅏ-ㅣ가-힣])\\1{2,}', r'\\1\\1', text)\n",
    "                text = re.sub(r'([a-zA-Z])\\1{2,}', r'\\1\\1', text)\n",
    "        else:\n",
    "            # 간단한 정규화\n",
    "            text = re.sub(r'([ㄱ-ㅎㅏ-ㅣ가-힣])\\1{2,}', r'\\1\\1', text)\n",
    "            text = re.sub(r'([a-zA-Z])\\1{2,}', r'\\1\\1', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def process_text(self, text, normalize=True, remove_stopwords=False, replace_emoji=True):\n",
    "        \"\"\"텍스트 전처리 메인 함수 - 개선된 버전\"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return \"\"\n",
    "        \n",
    "        # 원본 텍스트 보존\n",
    "        original_text = text.strip()\n",
    "        \n",
    "        # 1. URL 및 이메일 치환\n",
    "        text = self.patterns['url'].sub('[URL]', text)\n",
    "        text = self.patterns['email'].sub('[EMAIL]', text)\n",
    "        \n",
    "        # 2. 이모지 처리 (텍스트 유지)\n",
    "        if replace_emoji:\n",
    "            text = self.replace_emojis(text)\n",
    "        \n",
    "        # 3. 특수문자는 완전히 제거하지 않고 공백으로 대체 (일부 보존)\n",
    "        # 한글, 영어, 숫자, 기본 구두점은 유지\n",
    "        text = re.sub(r\"[^\\w\\s가-힣a-zA-Z0-9?.!,~]\", \" \", text)\n",
    "        \n",
    "        # 4. 한글 자모 분리 현상 교정 (ㅋㅋㅋ, ㅎㅎㅎ 등은 보존)\n",
    "        jamo_matches = self.patterns['jamo_pattern'].findall(text)\n",
    "        for match in jamo_matches:\n",
    "            if match in ['ㅋㅋ', 'ㅎㅎ', 'ㅠㅠ', 'ㅜㅜ', 'ㅡㅡ']:  # 이모티콘은 보존\n",
    "                continue\n",
    "            text = text.replace(match, match[:2])  # 과도한 반복만 제거\n",
    "        \n",
    "        # 5. 신조어 및 축약어 처리\n",
    "        for slang, meaning in self.slang_dict.items():\n",
    "            if slang in text:\n",
    "                text = text.replace(slang, meaning)\n",
    "        \n",
    "        # 6. 텍스트 정규화\n",
    "        if normalize:\n",
    "            text = self.normalize_text(text)\n",
    "        \n",
    "        # 7. 여러 공백을 하나로 병합\n",
    "        text = self.patterns['multiple_spaces'].sub(' ', text)\n",
    "        \n",
    "        # 8. 구두점 앞뒤로 공백 추가\n",
    "        text = re.sub(r\"([?.!,~])\", r\" \\1 \", text)\n",
    "        text = self.patterns['multiple_spaces'].sub(' ', text)\n",
    "        \n",
    "        # 9. 최종 텍스트 정리\n",
    "        processed_text = text.strip()\n",
    "        \n",
    "        # 처리 결과가 너무 짧거나 없으면 원본 반환 (중요: 데이터 손실 방지)\n",
    "        if len(processed_text) < 2 or processed_text.isspace():\n",
    "            return original_text\n",
    "            \n",
    "        return processed_text\n",
    "    \n",
    "    def tokenize_morphemes(self, text):\n",
    "        \"\"\"형태소 분석\"\"\"\n",
    "        if not self.morpheme_analyzer or not text:\n",
    "            return text.split()\n",
    "        \n",
    "        try:\n",
    "            if isinstance(self.morpheme_analyzer, Mecab):\n",
    "                return self.morpheme_analyzer.morphs(text)\n",
    "            else:  # Okt 또는 다른 형태소 분석기\n",
    "                return self.morpheme_analyzer.morphs(text)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"형태소 분석 실패: {e}\")\n",
    "            return text.split()\n",
    "    \n",
    "    def get_pos_tags(self, text):\n",
    "        \"\"\"품사 태깅\"\"\"\n",
    "        if not self.morpheme_analyzer or not text:\n",
    "            return [(word, 'UNKNOWN') for word in text.split()]\n",
    "        \n",
    "        try:\n",
    "            return self.morpheme_analyzer.pos(text)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"품사 태깅 실패: {e}\")\n",
    "            return [(word, 'UNKNOWN') for word in text.split()]\n",
    "    \n",
    "    def extract_nouns(self, text):\n",
    "        \"\"\"명사 추출\"\"\"\n",
    "        if not self.morpheme_analyzer or not text:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            if isinstance(self.morpheme_analyzer, Mecab):\n",
    "                return [word for word, pos in self.morpheme_analyzer.pos(text) \n",
    "                       if pos.startswith('N')]\n",
    "            else:  # Okt\n",
    "                return self.morpheme_analyzer.nouns(text)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"명사 추출 실패: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def remove_stopwords(self, tokens):\n",
    "        \"\"\"불용어 제거\"\"\"\n",
    "        return [token for token in tokens if token not in self.stopwords]\n",
    "    \n",
    "    def enhanced_morpheme_tokenize(self, text):\n",
    "        \"\"\"품사 정보를 활용한 향상된 형태소 분석 - 개선된 버전\"\"\"\n",
    "        # 전처리 적용\n",
    "        preprocessed = self.process_text(text)\n",
    "        \n",
    "        if not preprocessed:\n",
    "            return text  # 원본 반환 (중요: 데이터 손실 방지)\n",
    "        \n",
    "        try:\n",
    "            # 품사 태깅\n",
    "            pos_tagged = self.get_pos_tags(preprocessed)\n",
    "            \n",
    "            # 중요 품사에 가중치 부여 (명사, 동사, 형용사 등)\n",
    "            if isinstance(self.morpheme_analyzer, Mecab):\n",
    "                important_pos = ['NNG', 'NNP', 'VV', 'VA', 'MAG']  # 일반명사, 고유명사, 동사, 형용사, 부사\n",
    "            else:  # Okt의 경우\n",
    "                important_pos = ['Noun', 'Verb', 'Adjective', 'Adverb']\n",
    "            \n",
    "            # 형태소와 품사 정보 결합\n",
    "            morphemes_with_pos = []\n",
    "            for word, pos in pos_tagged:\n",
    "                morphemes_with_pos.append(word)\n",
    "            \n",
    "            # 형태소를 공백으로 구분하여 결합\n",
    "            result = ' '.join(morphemes_with_pos)\n",
    "            \n",
    "            # 결과가 너무 짧으면 원본 반환\n",
    "            if len(result) < 2:\n",
    "                return text\n",
    "                \n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"향상된 형태소 분석 실패: {e}\")\n",
    "            return text  # 실패 시 원본 반환\n",
    "    \n",
    "    def process_dataframe(self, df, q_col='Q', a_col='A'):\n",
    "        \"\"\"데이터프레임의 질문/답변 컬럼 처리 - 개선된 버전\"\"\"\n",
    "        logger.info(f\"데이터프레임 전처리 시작 (크기: {len(df)})\")\n",
    "        \n",
    "        # 결과 저장할 새로운 컬럼 생성\n",
    "        df['Q_processed'] = df[q_col].apply(lambda x: self.process_text(x) if isinstance(x, str) else \"\")\n",
    "        df['A_processed'] = df[a_col].apply(lambda x: self.process_text(x) if isinstance(x, str) else \"\")\n",
    "        \n",
    "        # 빈 처리 결과는 원본으로 대체 (중요: 데이터 손실 방지)\n",
    "        df.loc[df['Q_processed'] == \"\", 'Q_processed'] = df.loc[df['Q_processed'] == \"\", q_col]\n",
    "        df.loc[df['A_processed'] == \"\", 'A_processed'] = df.loc[df['A_processed'] == \"\", a_col]\n",
    "        \n",
    "        # 형태소 분석 적용\n",
    "        df['Q_morphemes'] = df['Q_processed'].apply(lambda x: self.enhanced_morpheme_tokenize(x) if isinstance(x, str) else \"\")\n",
    "        df['A_morphemes'] = df['A_processed'].apply(lambda x: self.enhanced_morpheme_tokenize(x) if isinstance(x, str) else \"\")\n",
    "        \n",
    "        # 빈 형태소 결과는 처리된 텍스트로 대체\n",
    "        df.loc[df['Q_morphemes'] == \"\", 'Q_morphemes'] = df.loc[df['Q_morphemes'] == \"\", 'Q_processed']\n",
    "        df.loc[df['A_morphemes'] == \"\", 'A_morphemes'] = df.loc[df['A_morphemes'] == \"\", 'A_processed']\n",
    "        \n",
    "        logger.info(\"데이터프레임 전처리 완료\")\n",
    "        return df\n",
    "\n",
    "# 전처리기 초기화 및 데이터 처리\n",
    "preprocessor = KoreanTextPreprocessor(use_mecab=True, use_soynlp=True)\n",
    "processed_df = preprocessor.process_dataframe(combined_df)\n",
    "\n",
    "# 전처리 결과 확인\n",
    "print(\"전처리 후 데이터 샘플:\")\n",
    "sample_columns = ['Q', 'Q_processed', 'Q_morphemes', 'A', 'A_processed', 'A_morphemes']\n",
    "print(processed_df[sample_columns].head())\n",
    "\n",
    "# 전처리된 데이터 저장\n",
    "processed_df.to_csv(os.path.join(data_dir, 'processed_chat_data.csv'), index=False)\n",
    "logger.info(f\"전처리된 데이터 저장 완료: {os.path.join(data_dir, 'processed_chat_data.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d988dc",
   "metadata": {},
   "source": [
    "### 1-7 다중 턴 대화 생성 및 구조화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abac4fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:43,690 - __main__ - INFO - 대화 문맥 관리자 초기화 중...\n",
      "2025-04-21 01:54:43,691 - __main__ - INFO - 대화 문맥 관리자 초기화 완료\n",
      "2025-04-21 01:54:43,692 - __main__ - INFO - 간단한 다중 턴 대화 200개 생성 중...\n",
      "2025-04-21 01:54:43,788 - __main__ - INFO - 200개의 다중 턴 대화 생성 완료\n",
      "2025-04-21 01:54:43,789 - __main__ - INFO - 학습용 데이터 구조화 중...\n",
      "2025-04-21 01:54:43,792 - __main__ - INFO - 구조화된 데이터 800개 생성 완료\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대화 예시 #1\n",
      "Q: 소화제 먹어야겠다\n",
      "A: 급하게 먹거나 과식하지 말고 좋은 식습관을 가져보세요.\n",
      "\n",
      "Q: 짝남한테 주말에 만나자고 했는데 일 있대 계속 언제 되는지 물어봐도 되나.\n",
      "A: 거절 하는게 느껴지면 그만하는게 좋겠어요.\n",
      "\n",
      "Q: 나 노트북 사줘\n",
      "A: 노트북은 비싸요.\n",
      "\n",
      "Q: 집착인가\n",
      "A: 상대가 그렇게 느낀다면요.\n",
      "\n",
      "Q: 누구세요?\n",
      "A: 저는 위로해드리는 로봇이에요.\n",
      "\n",
      "대화 예시 #2\n",
      "Q: 매콤한 닭발 생각나\n",
      "A: 스트레스 받으시는 일 있으신가요?\n",
      "\n",
      "Q: 남자친구 승진 선물로 뭐가 좋을까?\n",
      "A: 평소에 필요했던 게 좋을 것 같아요.\n",
      "\n",
      "Q: 노메이크업인데 전남친 만남\n",
      "A: 남이니 신경쓰지 마세요.\n",
      "\n",
      "Q: 요즘 되는 일이 없네\n",
      "A: 이제부터 일이 잘 풀릴 거예요.\n",
      "\n",
      "Q: 비욘세의 앨범이 아이튠즈 스토어에서 6일간 판매된 수량은?\n",
      "A: 100만\n",
      "\n",
      "대화 예시 #3\n",
      "Q: 나이를 먹을수록 새로운 사람 만나는게 두려워.\n",
      "A: 두려워도 도전한 만큼 좋은 결과 있을 거예요.\n",
      "\n",
      "Q: 내가 더 사랑할까?\n",
      "A: 누가 더 사랑하는지는 중요하지 않아요.\n",
      "\n",
      "Q: 스튜디오 촬영하는 날이야!\n",
      "A: 예쁘게 찍고 오세요.\n",
      "\n",
      "Q: 봄은 오네\n",
      "A: 꽃도 필 거예요.\n",
      "\n",
      "Q: 벚꽃이 너무 예뻐\n",
      "A: 너무 아름답죠.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:43,810 - __main__ - INFO - 구조화된 대화 데이터 저장 완료: chatbot_data/structured_dialogue_data.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DialogueContextManager:\n",
    "    \"\"\"대화 문맥 관리 및 구조화 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, df, max_context_length=3):\n",
    "        logger.info(\"대화 문맥 관리자 초기화 중...\")\n",
    "        self.df = df\n",
    "        self.max_context_length = max_context_length\n",
    "        self.conversation_flows = []\n",
    "        logger.info(\"대화 문맥 관리자 초기화 완료\")\n",
    "    \n",
    "    def generate_simple_conversations(self, num_conversations=100, turns_per_conversation=5, seed=42):\n",
    "        \"\"\"간단한 다중 턴 대화 생성\"\"\"\n",
    "        logger.info(f\"간단한 다중 턴 대화 {num_conversations}개 생성 중...\")\n",
    "        random.seed(seed)\n",
    "        \n",
    "        conversations = []\n",
    "        df_sample = self.df.sample(n=min(len(self.df), num_conversations * turns_per_conversation), random_state=seed)\n",
    "        \n",
    "        # 대화 흐름 생성\n",
    "        for i in range(num_conversations):\n",
    "            conversation = []\n",
    "            start_idx = i * turns_per_conversation\n",
    "            end_idx = min((i + 1) * turns_per_conversation, len(df_sample))\n",
    "            \n",
    "            for j in range(start_idx, end_idx):\n",
    "                if j < len(df_sample):\n",
    "                    q = df_sample.iloc[j]['Q']\n",
    "                    a = df_sample.iloc[j]['A']\n",
    "                    conversation.append({\"Q\": q, \"A\": a})\n",
    "            \n",
    "            if conversation:  # 빈 대화는 추가하지 않음\n",
    "                conversations.append(conversation)\n",
    "        \n",
    "        self.conversation_flows = conversations\n",
    "        logger.info(f\"{len(conversations)}개의 다중 턴 대화 생성 완료\")\n",
    "        return conversations\n",
    "    \n",
    "    def generate_coherent_conversations(self, embedding_model=None):\n",
    "        \"\"\"임베딩 유사도를 활용한 일관성 있는 다중 턴 대화 생성\"\"\"\n",
    "        if embedding_model is None:\n",
    "            logger.warning(\"임베딩 모델이 없어 간단한 대화로 대체합니다.\")\n",
    "            return self.generate_simple_conversations()\n",
    "        \n",
    "        logger.info(\"유사도 기반 일관성 있는 대화 생성 중...\")\n",
    "        # 실제 구현은 임베딩 모델에 따라 달라짐\n",
    "        # 여기서는 예시로 generate_simple_conversations 함수 호출\n",
    "        return self.generate_simple_conversations()\n",
    "    \n",
    "    def structure_for_training(self):\n",
    "        \"\"\"학습용 데이터 구조화\"\"\"\n",
    "        logger.info(\"학습용 데이터 구조화 중...\")\n",
    "        \n",
    "        structured_data = []\n",
    "        \n",
    "        for conversation in self.conversation_flows:\n",
    "            for i in range(1, len(conversation)):\n",
    "                # 현재 턴의 질문\n",
    "                current_q = conversation[i][\"Q\"]\n",
    "                \n",
    "                # 현재 턴의 답변 (정답)\n",
    "                current_a = conversation[i][\"A\"]\n",
    "                \n",
    "                # 이전 대화 컨텍스트 (최대 max_context_length까지)\n",
    "                context = []\n",
    "                for j in range(max(0, i - self.max_context_length), i):\n",
    "                    context.append({\n",
    "                        \"Q\": conversation[j][\"Q\"],\n",
    "                        \"A\": conversation[j][\"A\"]\n",
    "                    })\n",
    "                \n",
    "                structured_data.append({\n",
    "                    \"context\": context,\n",
    "                    \"current_q\": current_q,\n",
    "                    \"current_a\": current_a\n",
    "                })\n",
    "        \n",
    "        logger.info(f\"구조화된 데이터 {len(structured_data)}개 생성 완료\")\n",
    "        return structured_data\n",
    "    \n",
    "    def save_structured_data(self, output_file=None):\n",
    "        \"\"\"구조화된 데이터 저장\"\"\"\n",
    "        if not self.conversation_flows:\n",
    "            logger.warning(\"저장할 대화 데이터가 없습니다. 먼저 대화를 생성하세요.\")\n",
    "            return False\n",
    "        \n",
    "        if output_file is None:\n",
    "            output_file = os.path.join(data_dir, 'structured_dialogue_data.json')\n",
    "        \n",
    "        # 학습용 데이터 구조화\n",
    "        structured_data = self.structure_for_training()\n",
    "        \n",
    "        try:\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(structured_data, f, ensure_ascii=False, indent=2)\n",
    "            logger.info(f\"구조화된 대화 데이터 저장 완료: {output_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"데이터 저장 실패: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def generate_dialogue_examples(self, num_examples=5):\n",
    "        \"\"\"대화 예시 생성 (시각화 용도)\"\"\"\n",
    "        if not self.conversation_flows:\n",
    "            logger.warning(\"표시할 대화 예시가 없습니다. 먼저 대화를 생성하세요.\")\n",
    "            return []\n",
    "        \n",
    "        examples = []\n",
    "        for i, conversation in enumerate(random.sample(self.conversation_flows, min(num_examples, len(self.conversation_flows)))):\n",
    "            examples.append(f\"대화 예시 #{i+1}\")\n",
    "            for turn in conversation:\n",
    "                examples.append(f\"Q: {turn['Q']}\")\n",
    "                examples.append(f\"A: {turn['A']}\")\n",
    "                examples.append(\"\")  # 빈 줄\n",
    "        \n",
    "        return examples\n",
    "\n",
    "# 대화 문맥 관리자 초기화 및 사용\n",
    "dialogue_manager = DialogueContextManager(processed_df)\n",
    "\n",
    "# 다중 턴 대화 생성\n",
    "conversations = dialogue_manager.generate_simple_conversations(num_conversations=200, turns_per_conversation=5)\n",
    "\n",
    "# 대화 예시 출력\n",
    "dialogue_examples = dialogue_manager.generate_dialogue_examples(num_examples=3)\n",
    "print(\"\\n\".join(dialogue_examples))\n",
    "\n",
    "# 구조화된 데이터 저장\n",
    "dialogue_manager.save_structured_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6c711",
   "metadata": {},
   "source": [
    "### 1-8 문맥을 고려한 질의-응답 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9083c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:43,825 - __main__ - INFO - 문맥을 고려한 질의-응답 쌍 생성 중 (컨텍스트 크기: 3)...\n",
      "2025-04-21 01:54:46,823 - __main__ - INFO - 문맥 고려 질의-응답 쌍 12770개 생성 완료\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문맥을 고려한 질의-응답 쌍 예시:\n",
      "\n",
      "예시 #1:\n",
      "컨텍스트: [{'Q': '좋아하는 애랑 카톡하면', 'A': '좋을 것 같네요.'}, {'Q': '좋아하는 애를 내가 너무 우상화하는 것 같아.', 'A': '마음이 커지면 그럴 수 있어요.'}, {'Q': '좋아하는 애한테 간접적으로 고백했는데 알아 차렸을까?', 'A': '눈치가 엄청 없지 않는 이상 알아 차렸을 거예요.'}]\n",
      "질문: 좋아하는 애한테 말도 못 해보고 졸업했어요.\n",
      "처리된 질문: 좋아하는 애한테 말도 못 해보고 졸업했어요 .\n",
      "형태소 분석 질문: 좋 아 하 는 애 한테 말 도 못 해 보 고 졸업 했 어요 .\n",
      "답변: 인연이라면 졸업 후에도 만날 수 있을 거예요.\n",
      "\n",
      "예시 #2:\n",
      "컨텍스트: [{'Q': '요즘 잠을 못자', 'A': '잠이 최고의 보약이에요. 노력해보세요.'}, {'Q': '요즘 제정신이 아니야', 'A': '그럴 때가 있죠.'}, {'Q': '요즘 조깅하고 있어', 'A': '건강에 좋은 습관이네요.'}]\n",
      "질문: 요즘 조심할 게 많아\n",
      "처리된 질문: 요즘 조심할 게 많아\n",
      "형태소 분석 질문: 요즘 조심 할 게 많 아\n",
      "답변: 무서운 세상이죠.\n",
      "\n",
      "예시 #3:\n",
      "컨텍스트: [{'Q': '애매한 관계', 'A': '인간 관계도 정리가 필요해요.'}, {'Q': '애버랜드 가고 싶어', 'A': '다녀오세요!'}, {'Q': '애완동물 키우고 싶어', 'A': '가족들과 상의해보세요.'}]\n",
      "질문: 애완동물 키우고 싶은데 아빠가 못 키우게 해\n",
      "처리된 질문: 애완동물 키우고 싶은데 아빠가 못 키우게 해\n",
      "형태소 분석 질문: 애완 동물 키우 고 싶 은데 아빠 가 못 키우 게 해\n",
      "답변: 이유가 있을 거예요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:47,241 - __main__ - INFO - 문맥 고려 질의-응답 쌍 저장 완료: chatbot_data/context_qa_pairs.json\n"
     ]
    }
   ],
   "source": [
    "def extract_conversation_pairs(df, preprocessor, context_size=3):\n",
    "    \"\"\"문맥을 고려한 질의-응답 쌍 생성\"\"\"\n",
    "    logger.info(f\"문맥을 고려한 질의-응답 쌍 생성 중 (컨텍스트 크기: {context_size})...\")\n",
    "    \n",
    "    # 문맥을 고려한 쌍을 저장할 리스트\n",
    "    context_pairs = []\n",
    "    \n",
    "    # 출처별로 그룹화하여 연속된 대화로 간주\n",
    "    source_groups = df.groupby('source')\n",
    "    \n",
    "    for source, group in source_groups:\n",
    "        rows = group.to_dict('records')\n",
    "        \n",
    "        # 각 그룹 내에서 슬라이딩 윈도우로 컨텍스트 구성\n",
    "        for i in range(len(rows)):\n",
    "            # 현재 질문과 답변\n",
    "            current_q = rows[i]['Q']\n",
    "            current_a = rows[i]['A']\n",
    "            \n",
    "            # 이전 컨텍스트 수집\n",
    "            context = []\n",
    "            for j in range(max(0, i - context_size), i):\n",
    "                context.append({\n",
    "                    'Q': rows[j]['Q'],\n",
    "                    'A': rows[j]['A']\n",
    "                })\n",
    "            \n",
    "            # 처리된 텍스트 버전\n",
    "            processed_q = preprocessor.process_text(current_q)\n",
    "            processed_a = preprocessor.process_text(current_a)\n",
    "            \n",
    "            # 형태소 분석 버전\n",
    "            morpheme_q = preprocessor.enhanced_morpheme_tokenize(current_q)\n",
    "            morpheme_a = preprocessor.enhanced_morpheme_tokenize(current_a)\n",
    "            \n",
    "            context_pairs.append({\n",
    "                'context': context,\n",
    "                'question': current_q,\n",
    "                'processed_question': processed_q,\n",
    "                'morpheme_question': morpheme_q,\n",
    "                'answer': current_a,\n",
    "                'processed_answer': processed_a,\n",
    "                'morpheme_answer': morpheme_a,\n",
    "                'source': source\n",
    "            })\n",
    "    \n",
    "    logger.info(f\"문맥 고려 질의-응답 쌍 {len(context_pairs)}개 생성 완료\")\n",
    "    return context_pairs\n",
    "\n",
    "# 문맥을 고려한 질의-응답 쌍 생성\n",
    "context_qa_pairs = extract_conversation_pairs(processed_df, preprocessor, context_size=3)\n",
    "\n",
    "# 샘플 출력\n",
    "print(\"문맥을 고려한 질의-응답 쌍 예시:\")\n",
    "for i, pair in enumerate(random.sample(context_qa_pairs, min(3, len(context_qa_pairs)))):\n",
    "    print(f\"\\n예시 #{i+1}:\")\n",
    "    print(f\"컨텍스트: {pair['context']}\")\n",
    "    print(f\"질문: {pair['question']}\")\n",
    "    print(f\"처리된 질문: {pair['processed_question']}\")\n",
    "    print(f\"형태소 분석 질문: {pair['morpheme_question']}\")\n",
    "    print(f\"답변: {pair['answer']}\")\n",
    "\n",
    "# 결과 저장\n",
    "with open(os.path.join(data_dir, 'context_qa_pairs.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(context_qa_pairs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "logger.info(f\"문맥 고려 질의-응답 쌍 저장 완료: {os.path.join(data_dir, 'context_qa_pairs.json')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86b5c3",
   "metadata": {},
   "source": [
    "### 1-9 단어 임베딩 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d42ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:47,268 - __main__ - INFO - 한국어 단어 임베딩 관리자 초기화 중...\n",
      "2025-04-21 01:54:47,269 - __main__ - INFO - 한국어 단어 임베딩 관리자 초기화 완료\n",
      "2025-04-21 01:54:47,270 - __main__ - INFO - 코퍼스 전처리 및 토큰화 중...\n",
      "100%|██████████| 25540/25540 [00:00<00:00, 628985.52it/s]\n",
      "2025-04-21 01:54:47,314 - __main__ - INFO - 전처리된 코퍼스 크기: 25540\n",
      "2025-04-21 01:54:47,315 - __main__ - INFO - Word2Vec 모델 학습 중...\n",
      "2025-04-21 01:54:47,316 - gensim.models.word2vec - INFO - collecting all words and their counts\n",
      "2025-04-21 01:54:47,316 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-04-21 01:54:47,329 - gensim.models.word2vec - INFO - PROGRESS: at sentence #10000, processed 64592 words, keeping 4905 word types\n",
      "2025-04-21 01:54:47,348 - gensim.models.word2vec - INFO - PROGRESS: at sentence #20000, processed 155071 words, keeping 9285 word types\n",
      "2025-04-21 01:54:47,356 - gensim.models.word2vec - INFO - collected 10608 word types from a corpus of 199941 raw words and 25540 sentences\n",
      "2025-04-21 01:54:47,357 - gensim.models.word2vec - INFO - Creating a fresh vocabulary\n",
      "2025-04-21 01:54:47,376 - gensim.utils - INFO - Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 5801 unique words (54.68514328808446%% of original 10608, drops 4807)', 'datetime': '2025-04-21T01:54:47.376182', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2025-04-21 01:54:47,376 - gensim.utils - INFO - Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 195134 word corpus (97.5957907582737%% of original 199941, drops 4807)', 'datetime': '2025-04-21T01:54:47.376895', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2025-04-21 01:54:47,403 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 10608 items\n",
      "2025-04-21 01:54:47,404 - gensim.models.word2vec - INFO - sample=0.001 downsamples 64 most-common words\n",
      "2025-04-21 01:54:47,404 - gensim.utils - INFO - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 134550.54968215193 word corpus (69.0%% of prior 195134)', 'datetime': '2025-04-21T01:54:47.404669', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2025-04-21 01:54:47,456 - gensim.models.word2vec - INFO - estimated required memory for 5801 words and 100 dimensions: 7541300 bytes\n",
      "2025-04-21 01:54:47,456 - gensim.models.word2vec - INFO - resetting layer weights\n",
      "2025-04-21 01:54:47,460 - gensim.utils - INFO - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T01:54:47.460774', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'build_vocab'}\n",
      "2025-04-21 01:54:47,461 - gensim.utils - INFO - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 5801 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-04-21T01:54:47.461342', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2025-04-21 01:54:47,714 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 3 more threads\n",
      "2025-04-21 01:54:47,732 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2025-04-21 01:54:47,737 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2025-04-21 01:54:47,737 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2025-04-21 01:54:47,738 - gensim.models.word2vec - INFO - EPOCH - 1 : training on 199941 raw words (134348 effective words) took 0.3s, 498538 effective words/s\n",
      "2025-04-21 01:54:47,991 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 3 more threads\n",
      "2025-04-21 01:54:48,007 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2025-04-21 01:54:48,009 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2025-04-21 01:54:48,016 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2025-04-21 01:54:48,016 - gensim.models.word2vec - INFO - EPOCH - 2 : training on 199941 raw words (134620 effective words) took 0.3s, 496265 effective words/s\n",
      "2025-04-21 01:54:48,266 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 3 more threads\n",
      "2025-04-21 01:54:48,281 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2025-04-21 01:54:48,290 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2025-04-21 01:54:48,290 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2025-04-21 01:54:48,291 - gensim.models.word2vec - INFO - EPOCH - 3 : training on 199941 raw words (134568 effective words) took 0.3s, 503298 effective words/s\n",
      "2025-04-21 01:54:48,533 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 3 more threads\n",
      "2025-04-21 01:54:48,566 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2025-04-21 01:54:48,568 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2025-04-21 01:54:48,570 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2025-04-21 01:54:48,570 - gensim.models.word2vec - INFO - EPOCH - 4 : training on 199941 raw words (134672 effective words) took 0.3s, 495924 effective words/s\n",
      "2025-04-21 01:54:48,842 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 3 more threads\n",
      "2025-04-21 01:54:48,847 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2025-04-21 01:54:48,860 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2025-04-21 01:54:48,867 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2025-04-21 01:54:48,868 - gensim.models.word2vec - INFO - EPOCH - 5 : training on 199941 raw words (134822 effective words) took 0.3s, 464816 effective words/s\n",
      "2025-04-21 01:54:48,868 - gensim.utils - INFO - Word2Vec lifecycle event {'msg': 'training on 999705 raw words (673030 effective words) took 1.4s, 478402 effective words/s', 'datetime': '2025-04-21T01:54:48.868864', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2025-04-21 01:54:48,869 - gensim.utils - INFO - Word2Vec lifecycle event {'params': 'Word2Vec(vocab=5801, vector_size=100, alpha=0.025)', 'datetime': '2025-04-21T01:54:48.869605', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'created'}\n",
      "2025-04-21 01:54:48,870 - __main__ - INFO - Word2Vec 모델 학습 완료\n",
      "2025-04-21 01:54:48,871 - __main__ - INFO - FastText 모델 학습 중...\n",
      "2025-04-21 01:54:48,872 - gensim.models.word2vec - INFO - collecting all words and their counts\n",
      "2025-04-21 01:54:48,872 - gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-04-21 01:54:48,884 - gensim.models.word2vec - INFO - PROGRESS: at sentence #10000, processed 64592 words, keeping 4905 word types\n",
      "2025-04-21 01:54:48,902 - gensim.models.word2vec - INFO - PROGRESS: at sentence #20000, processed 155071 words, keeping 9285 word types\n",
      "2025-04-21 01:54:48,910 - gensim.models.word2vec - INFO - collected 10608 word types from a corpus of 199941 raw words and 25540 sentences\n",
      "2025-04-21 01:54:48,911 - gensim.models.word2vec - INFO - Creating a fresh vocabulary\n",
      "2025-04-21 01:54:48,930 - gensim.utils - INFO - FastText lifecycle event {'msg': 'effective_min_count=2 retains 5801 unique words (54.68514328808446%% of original 10608, drops 4807)', 'datetime': '2025-04-21T01:54:48.930421', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2025-04-21 01:54:48,931 - gensim.utils - INFO - FastText lifecycle event {'msg': 'effective_min_count=2 leaves 195134 word corpus (97.5957907582737%% of original 199941, drops 4807)', 'datetime': '2025-04-21T01:54:48.931060', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2025-04-21 01:54:48,957 - gensim.models.word2vec - INFO - deleting the raw counts dictionary of 10608 items\n",
      "2025-04-21 01:54:48,958 - gensim.models.word2vec - INFO - sample=0.001 downsamples 64 most-common words\n",
      "2025-04-21 01:54:48,958 - gensim.utils - INFO - FastText lifecycle event {'msg': 'downsampling leaves estimated 134550.54968215193 word corpus (69.0%% of prior 195134)', 'datetime': '2025-04-21T01:54:48.958821', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}\n",
      "2025-04-21 01:54:49,020 - gensim.models.fasttext - INFO - estimated required memory for 5801 words, 2000000 buckets and 100 dimensions: 808211768 bytes\n",
      "2025-04-21 01:54:49,020 - gensim.models.word2vec - INFO - resetting layer weights\n",
      "2025-04-21 01:54:50,020 - gensim.utils - INFO - FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-04-21T01:54:50.020028', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'build_vocab'}\n",
      "2025-04-21 01:54:50,021 - gensim.utils - INFO - FastText lifecycle event {'msg': 'training model with 4 workers on 5801 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-04-21T01:54:50.021170', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2025-04-21 01:54:50,176 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 3 more threads\n",
      "2025-04-21 01:54:50,181 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2025-04-21 01:54:50,188 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2025-04-21 01:54:50,193 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2025-04-21 01:54:50,194 - gensim.models.word2vec - INFO - EPOCH - 1 : training on 199941 raw words (134385 effective words) took 0.2s, 811416 effective words/s\n",
      "2025-04-21 01:54:50,328 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 3 more threads\n",
      "2025-04-21 01:54:50,332 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2025-04-21 01:54:50,337 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2025-04-21 01:54:50,342 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2025-04-21 01:54:50,343 - gensim.models.word2vec - INFO - EPOCH - 2 : training on 199941 raw words (134486 effective words) took 0.1s, 950083 effective words/s\n",
      "2025-04-21 01:54:50,494 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 3 more threads\n",
      "2025-04-21 01:54:50,503 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2025-04-21 01:54:50,506 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2025-04-21 01:54:50,509 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2025-04-21 01:54:50,510 - gensim.models.word2vec - INFO - EPOCH - 3 : training on 199941 raw words (134451 effective words) took 0.2s, 843398 effective words/s\n",
      "2025-04-21 01:54:50,640 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 3 more threads\n",
      "2025-04-21 01:54:50,643 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2025-04-21 01:54:50,668 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2025-04-21 01:54:50,671 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2025-04-21 01:54:50,672 - gensim.models.word2vec - INFO - EPOCH - 4 : training on 199941 raw words (134606 effective words) took 0.2s, 868285 effective words/s\n",
      "2025-04-21 01:54:50,822 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 3 more threads\n",
      "2025-04-21 01:54:50,828 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 2 more threads\n",
      "2025-04-21 01:54:50,833 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 1 more threads\n",
      "2025-04-21 01:54:50,836 - gensim.models.word2vec - INFO - worker thread finished; awaiting finish of 0 more threads\n",
      "2025-04-21 01:54:50,836 - gensim.models.word2vec - INFO - EPOCH - 5 : training on 199941 raw words (134615 effective words) took 0.2s, 857430 effective words/s\n",
      "2025-04-21 01:54:50,837 - gensim.utils - INFO - FastText lifecycle event {'msg': 'training on 999705 raw words (672543 effective words) took 0.8s, 824814 effective words/s', 'datetime': '2025-04-21T01:54:50.837292', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'train'}\n",
      "2025-04-21 01:54:50,895 - gensim.utils - INFO - FastText lifecycle event {'params': 'FastText(vocab=5801, vector_size=100, alpha=0.025)', 'datetime': '2025-04-21T01:54:50.895952', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'created'}\n",
      "2025-04-21 01:54:50,896 - __main__ - INFO - FastText 모델 학습 완료\n",
      "2025-04-21 01:54:50,897 - gensim.utils - INFO - Word2Vec lifecycle event {'fname_or_handle': 'chatbot_data/word2vec_model.bin', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-04-21T01:54:50.897529', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'saving'}\n",
      "2025-04-21 01:54:50,898 - gensim.utils - INFO - not storing attribute cum_table\n",
      "2025-04-21 01:54:50,929 - gensim.utils - INFO - saved chatbot_data/word2vec_model.bin\n",
      "2025-04-21 01:54:50,930 - __main__ - INFO - Word2Vec 모델 저장 완료: chatbot_data/word2vec_model.bin\n",
      "2025-04-21 01:54:50,930 - gensim.utils - INFO - FastText lifecycle event {'fname_or_handle': 'chatbot_data/fasttext_model.bin', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-04-21T01:54:50.930859', 'gensim': '4.1.2', 'python': '3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) \\n[GCC 9.4.0]', 'platform': 'Linux-6.6.72+-x86_64-with-glibc2.31', 'event': 'saving'}\n",
      "2025-04-21 01:54:50,931 - gensim.utils - INFO - storing np array 'vectors_ngrams' to chatbot_data/fasttext_model.bin.wv.vectors_ngrams.npy\n",
      "2025-04-21 01:54:51,508 - gensim.utils - INFO - not storing attribute buckets_word\n",
      "2025-04-21 01:54:51,509 - gensim.utils - INFO - not storing attribute vectors\n",
      "2025-04-21 01:54:51,509 - gensim.utils - INFO - not storing attribute cum_table\n",
      "2025-04-21 01:54:51,527 - gensim.utils - INFO - saved chatbot_data/fasttext_model.bin\n",
      "2025-04-21 01:54:51,528 - __main__ - INFO - FastText 모델 저장 완료: chatbot_data/fasttext_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "단어 유사도 예시:\n",
      "\n",
      "'안녕'와(과) 유사한 단어 (Word2Vec):\n",
      "  - 너무너무: 0.9859\n",
      "  - 파혼: 0.9847\n",
      "  - 내려: 0.9830\n",
      "  - 벌레: 0.9828\n",
      "  - 변신: 0.9827\n",
      "\n",
      "'좋은'와(과) 유사한 단어 (Word2Vec):\n",
      "\n",
      "'날씨'와(과) 유사한 단어 (Word2Vec):\n",
      "  - 으련만: 0.9611\n",
      "  - 향: 0.9567\n",
      "  - 될지: 0.9564\n",
      "  - 멋있: 0.9547\n",
      "  - 텐데요: 0.9539\n",
      "\n",
      "'감사'와(과) 유사한 단어 (Word2Vec):\n",
      "  - 신기: 0.9674\n",
      "  - 잔인: 0.9656\n",
      "  - 적당: 0.9652\n",
      "  - 다양: 0.9649\n",
      "  - 어필: 0.9639\n",
      "\n",
      "'슬픔'와(과) 유사한 단어 (Word2Vec):\n",
      "  - 공허: 0.9752\n",
      "  - 지치: 0.9749\n",
      "  - 느라: 0.9742\n",
      "  - 지나가: 0.9738\n",
      "  - 떨리: 0.9722\n"
     ]
    }
   ],
   "source": [
    "class KoreanWordEmbedding:\n",
    "    \"\"\"한국어 단어 임베딩 학습 및 관리 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, corpus=None):\n",
    "        logger.info(\"한국어 단어 임베딩 관리자 초기화 중...\")\n",
    "        self.corpus = corpus or []\n",
    "        self.word2vec_model = None\n",
    "        self.fasttext_model = None\n",
    "        logger.info(\"한국어 단어 임베딩 관리자 초기화 완료\")\n",
    "    \n",
    "    def add_corpus(self, texts):\n",
    "        \"\"\"텍스트 코퍼스 추가\"\"\"\n",
    "        if isinstance(texts, list):\n",
    "            self.corpus.extend(texts)\n",
    "        else:\n",
    "            self.corpus.append(texts)\n",
    "    \n",
    "    def preprocess_corpus(self, tokenizer):\n",
    "        \"\"\"코퍼스 전처리 및 토큰화\"\"\"\n",
    "        logger.info(\"코퍼스 전처리 및 토큰화 중...\")\n",
    "        processed_corpus = []\n",
    "        \n",
    "        for text in tqdm(self.corpus):\n",
    "            if isinstance(text, str):\n",
    "                tokens = tokenizer(text)\n",
    "                if tokens:\n",
    "                    processed_corpus.append(tokens)\n",
    "        \n",
    "        logger.info(f\"전처리된 코퍼스 크기: {len(processed_corpus)}\")\n",
    "        return processed_corpus\n",
    "    \n",
    "    def train_word2vec(self, processed_corpus, vector_size=100, window=5, min_count=1, workers=4, sg=1):\n",
    "        \"\"\"Word2Vec 모델 학습\"\"\"\n",
    "        logger.info(\"Word2Vec 모델 학습 중...\")\n",
    "        try:\n",
    "            self.word2vec_model = Word2Vec(\n",
    "                sentences=processed_corpus,\n",
    "                vector_size=vector_size,\n",
    "                window=window,\n",
    "                min_count=min_count,\n",
    "                workers=workers,\n",
    "                sg=sg  # 1: skip-gram, 0: CBOW\n",
    "            )\n",
    "            logger.info(\"Word2Vec 모델 학습 완료\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Word2Vec 학습 실패: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def train_fasttext(self, processed_corpus, vector_size=100, window=5, min_count=1, workers=4):\n",
    "        \"\"\"FastText 모델 학습\"\"\"\n",
    "        logger.info(\"FastText 모델 학습 중...\")\n",
    "        try:\n",
    "            self.fasttext_model = FastText(\n",
    "                sentences=processed_corpus,\n",
    "                vector_size=vector_size,\n",
    "                window=window,\n",
    "                min_count=min_count,\n",
    "                workers=workers\n",
    "            )\n",
    "            logger.info(\"FastText 모델 학습 완료\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"FastText 학습 실패: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def save_models(self, word2vec_path=None, fasttext_path=None):\n",
    "        \"\"\"학습된 모델 저장\"\"\"\n",
    "        if word2vec_path is None:\n",
    "            word2vec_path = os.path.join(data_dir, 'word2vec_model.bin')\n",
    "        \n",
    "        if fasttext_path is None:\n",
    "            fasttext_path = os.path.join(data_dir, 'fasttext_model.bin')\n",
    "        \n",
    "        success = True\n",
    "        \n",
    "        if self.word2vec_model:\n",
    "            try:\n",
    "                self.word2vec_model.save(word2vec_path)\n",
    "                logger.info(f\"Word2Vec 모델 저장 완료: {word2vec_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Word2Vec 모델 저장 실패: {e}\")\n",
    "                success = False\n",
    "        \n",
    "        if self.fasttext_model:\n",
    "            try:\n",
    "                self.fasttext_model.save(fasttext_path)\n",
    "                logger.info(f\"FastText 모델 저장 완료: {fasttext_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"FastText 모델 저장 실패: {e}\")\n",
    "                success = False\n",
    "        \n",
    "        return success\n",
    "    \n",
    "    def load_models(self, word2vec_path=None, fasttext_path=None):\n",
    "        \"\"\"저장된 모델 로드\"\"\"\n",
    "        if word2vec_path is None:\n",
    "            word2vec_path = os.path.join(data_dir, 'word2vec_model.bin')\n",
    "        \n",
    "        if fasttext_path is None:\n",
    "            fasttext_path = os.path.join(data_dir, 'fasttext_model.bin')\n",
    "        \n",
    "        success = True\n",
    "        \n",
    "        if os.path.exists(word2vec_path):\n",
    "            try:\n",
    "                self.word2vec_model = Word2Vec.load(word2vec_path)\n",
    "                logger.info(f\"Word2Vec 모델 로드 완료: {word2vec_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Word2Vec 모델 로드 실패: {e}\")\n",
    "                success = False\n",
    "        \n",
    "        if os.path.exists(fasttext_path):\n",
    "            try:\n",
    "                self.fasttext_model = FastText.load(fasttext_path)\n",
    "                logger.info(f\"FastText 모델 로드 완료: {fasttext_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"FastText 모델 로드 실패: {e}\")\n",
    "                success = False\n",
    "        \n",
    "        return success\n",
    "    \n",
    "    def get_word_vector(self, word, model_type='word2vec'):\n",
    "        \"\"\"단어 벡터 반환\"\"\"\n",
    "        if model_type == 'word2vec' and self.word2vec_model:\n",
    "            try:\n",
    "                return self.word2vec_model.wv[word]\n",
    "            except:\n",
    "                return None\n",
    "        elif model_type == 'fasttext' and self.fasttext_model:\n",
    "            try:\n",
    "                return self.fasttext_model.wv[word]\n",
    "            except:\n",
    "                return None\n",
    "        return None\n",
    "    \n",
    "    def get_most_similar(self, word, model_type='word2vec', topn=10):\n",
    "        \"\"\"유사한 단어 반환\"\"\"\n",
    "        if model_type == 'word2vec' and self.word2vec_model:\n",
    "            try:\n",
    "                return self.word2vec_model.wv.most_similar(word, topn=topn)\n",
    "            except:\n",
    "                return []\n",
    "        elif model_type == 'fasttext' and self.fasttext_model:\n",
    "            try:\n",
    "                return self.fasttext_model.wv.most_similar(word, topn=topn)\n",
    "            except:\n",
    "                return []\n",
    "        return []\n",
    "    \n",
    "    def get_sentence_vector(self, sentence, tokenizer, model_type='word2vec'):\n",
    "        \"\"\"문장 벡터 반환 (단어 벡터의 평균)\"\"\"\n",
    "        tokens = tokenizer(sentence)\n",
    "        vectors = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            vector = self.get_word_vector(token, model_type)\n",
    "            if vector is not None:\n",
    "                vectors.append(vector)\n",
    "        \n",
    "        if vectors:\n",
    "            return np.mean(vectors, axis=0)\n",
    "        return None\n",
    "\n",
    "# 임베딩 모델 구현\n",
    "# 처리된 데이터에서 코퍼스 추출\n",
    "q_corpus = processed_df['Q_morphemes'].tolist()\n",
    "a_corpus = processed_df['A_morphemes'].tolist()\n",
    "all_corpus = q_corpus + a_corpus\n",
    "\n",
    "# 토큰화 함수 정의\n",
    "def simple_tokenize(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.split()\n",
    "    return []\n",
    "\n",
    "# 임베딩 관리자 초기화 및 학습\n",
    "embedding_manager = KoreanWordEmbedding(corpus=all_corpus)\n",
    "processed_corpus = embedding_manager.preprocess_corpus(simple_tokenize)\n",
    "\n",
    "# Word2Vec 모델 학습\n",
    "embedding_manager.train_word2vec(processed_corpus, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# FastText 모델 학습\n",
    "embedding_manager.train_fasttext(processed_corpus, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# 모델 저장\n",
    "embedding_manager.save_models()\n",
    "\n",
    "# 유사 단어 예시 출력\n",
    "try:\n",
    "    common_words = ['안녕', '좋은', '날씨', '감사', '슬픔']\n",
    "    print(\"\\n단어 유사도 예시:\")\n",
    "    for word in common_words:\n",
    "        try:\n",
    "            print(f\"\\n'{word}'와(과) 유사한 단어 (Word2Vec):\")\n",
    "            similar_words = embedding_manager.get_most_similar(word, model_type='word2vec', topn=5)\n",
    "            for similar_word, similarity in similar_words:\n",
    "                print(f\"  - {similar_word}: {similarity:.4f}\")\n",
    "        except:\n",
    "            print(f\"  '{word}' 단어를 찾을 수 없습니다.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"유사 단어 출력 중 오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c9b8e5",
   "metadata": {},
   "source": [
    "### 1-10 사전 학습된 BERT 모델을 활용한 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314b50d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:51,628 - __main__ - INFO - BERT 임베딩 초기화 중 (모델: monologg/kobert)...\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "2025-04-21 01:54:53,905 - __main__ - INFO - BERT 모델 로드 성공: monologg/kobert\n",
      "2025-04-21 01:54:53,906 - __main__ - INFO - BERT 임베딩 초기화 완료\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT 임베딩 예시:\n",
      "임베딩 크기: (1, 768)\n",
      "임베딩 일부: [-0.25773966  0.20431475  0.390271   -3.495245   -0.22986092 -0.03199132\n",
      "  0.36736205  0.1666533  -0.4669796  -0.38907316]\n",
      "\n",
      "BERT 유사도 계산 예시:\n",
      "텍스트 1: 세상에서 제일 힘든 게 짝사랑인 듯 .\n",
      "텍스트 2: 학교 축제를 즐겨야지\n",
      "유사도: 0.3945\n",
      "\n",
      "비슷한 질문 찾기 예시:\n",
      "검색 쿼리: 오늘 날씨가 어때요?\n",
      "- 시험 보지 말까 ? (유사도: 0.9226)\n",
      "- 아기 좋아하는 여자 어때 ? (유사도: 0.9194)\n",
      "- 쏘나타가 출시된 년도는 ? (유사도: 0.9101)\n"
     ]
    }
   ],
   "source": [
    "class BertEmbedding:\n",
    "    \"\"\"BERT 모델을 이용한 텍스트 임베딩 클래스 - 개선된 버전\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='monologg/kobert'):\n",
    "        logger.info(f\"BERT 임베딩 초기화 중 (모델: {model_name})...\")\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        \n",
    "        # torch 임포트 문제 해결\n",
    "        try:\n",
    "            import torch\n",
    "            self.torch = torch\n",
    "            self.initialize_model()\n",
    "        except ImportError:\n",
    "            logger.error(\"torch 모듈을 임포트할 수 없습니다. BERT 임베딩 기능이 비활성화됩니다.\")\n",
    "            \n",
    "        logger.info(\"BERT 임베딩 초기화 완료\")\n",
    "    \n",
    "    def initialize_model(self):\n",
    "        \"\"\"BERT 모델 및 토크나이저 초기화\"\"\"\n",
    "        try:\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
    "            self.model = BertModel.from_pretrained(self.model_name)\n",
    "            logger.info(f\"BERT 모델 로드 성공: {self.model_name}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"BERT 모델 로드 실패: {e}\")\n",
    "            logger.error(\"BERT 임베딩 기능이 비활성화됩니다.\")\n",
    "    \n",
    "    def is_model_loaded(self):\n",
    "        \"\"\"모델 로드 상태 확인\"\"\"\n",
    "        return self.tokenizer is not None and self.model is not None and hasattr(self, 'torch')\n",
    "    \n",
    "    def get_embedding(self, text, pooling='cls'):\n",
    "        \"\"\"텍스트 임베딩 벡터 반환\"\"\"\n",
    "        if not self.is_model_loaded() or not isinstance(text, str):\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # 토큰화 및 모델 입력 준비\n",
    "            inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "            \n",
    "            # 모델 추론\n",
    "            with self.torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            \n",
    "            # 풀링 방식에 따라 임베딩 추출\n",
    "            if pooling == 'cls':\n",
    "                # [CLS] 토큰 임베딩 (첫 번째 토큰)\n",
    "                embedding = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "            elif pooling == 'mean':\n",
    "                # 모든 토큰 임베딩의 평균\n",
    "                # 어텐션 마스크를 이용해 패딩 토큰 제외\n",
    "                mask = inputs['attention_mask'].unsqueeze(-1).numpy()\n",
    "                embedding = (outputs.last_hidden_state * mask).sum(1) / mask.sum(1)\n",
    "                embedding = embedding.numpy()\n",
    "            else:\n",
    "                logger.warning(f\"지원하지 않는 풀링 방식: {pooling}, 'cls'로 대체합니다.\")\n",
    "                embedding = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "            \n",
    "            return embedding\n",
    "        except Exception as e:\n",
    "            logger.error(f\"임베딩 추출 실패: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def batch_get_embeddings(self, texts, batch_size=32, pooling='cls'):\n",
    "        \"\"\"배치 처리로 여러 텍스트의 임베딩 벡터 반환\"\"\"\n",
    "        if not self.is_model_loaded():\n",
    "            return []\n",
    "        \n",
    "        embeddings = []\n",
    "        \n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"BERT 임베딩 계산\"):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            batch_embeddings = [self.get_embedding(text, pooling) for text in batch_texts]\n",
    "            embeddings.extend([emb for emb in batch_embeddings if emb is not None])\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def calculate_similarity(self, text1, text2, pooling='cls'):\n",
    "        \"\"\"두 텍스트 간의 유사도 계산\"\"\"\n",
    "        if not self.is_model_loaded():\n",
    "            return 0.0\n",
    "        \n",
    "        emb1 = self.get_embedding(text1, pooling)\n",
    "        emb2 = self.get_embedding(text2, pooling)\n",
    "        \n",
    "        if emb1 is None or emb2 is None:\n",
    "            return 0.0\n",
    "        \n",
    "        # 코사인 유사도 계산\n",
    "        similarity = cosine_similarity(emb1, emb2)[0][0]\n",
    "        return similarity\n",
    "    \n",
    "    def find_similar_texts(self, query_text, corpus, top_k=5, pooling='cls'):\n",
    "        \"\"\"코퍼스에서 쿼리 텍스트와 가장 유사한 텍스트 찾기\"\"\"\n",
    "        if not self.is_model_loaded() or not corpus:\n",
    "            return []\n",
    "        \n",
    "        query_emb = self.get_embedding(query_text, pooling)\n",
    "        if query_emb is None:\n",
    "            return []\n",
    "        \n",
    "        # 각 텍스트에 대한 임베딩 및 유사도 계산\n",
    "        similarities = []\n",
    "        for idx, text in enumerate(corpus):\n",
    "            emb = self.get_embedding(text, pooling)\n",
    "            if emb is not None:\n",
    "                sim = cosine_similarity(query_emb, emb)[0][0]\n",
    "                similarities.append((idx, text, sim))\n",
    "        \n",
    "        # 유사도 기준 내림차순 정렬 및 상위 k개 반환\n",
    "        similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "        return similarities[:top_k]  \n",
    "\n",
    "# BERT 임베딩 구현 (샘플링하여 처리 속도 향상)\n",
    "bert_embedding = BertEmbedding(model_name='monologg/kobert')\n",
    "\n",
    "# 임베딩이 성공적으로 로드되었는지 확인\n",
    "if bert_embedding.is_model_loaded():\n",
    "    # 샘플 데이터에 대한 임베딩 계산\n",
    "    sample_texts = processed_df['Q_processed'].sample(min(20, len(processed_df))).tolist()\n",
    "    \n",
    "    print(\"\\nBERT 임베딩 예시:\")\n",
    "    sample_embedding = bert_embedding.get_embedding(sample_texts[0])\n",
    "    if sample_embedding is not None:\n",
    "        print(f\"임베딩 크기: {sample_embedding.shape}\")\n",
    "        print(f\"임베딩 일부: {sample_embedding[0, :10]}\")\n",
    "    \n",
    "    # 유사도 계산 예시\n",
    "    if len(sample_texts) >= 2:\n",
    "        print(\"\\nBERT 유사도 계산 예시:\")\n",
    "        similarity = bert_embedding.calculate_similarity(sample_texts[0], sample_texts[1])\n",
    "        print(f\"텍스트 1: {sample_texts[0]}\")\n",
    "        print(f\"텍스트 2: {sample_texts[1]}\")\n",
    "        print(f\"유사도: {similarity:.4f}\")\n",
    "    \n",
    "    # 비슷한 질문 찾기 예시\n",
    "    print(\"\\n비슷한 질문 찾기 예시:\")\n",
    "    query = \"오늘 날씨가 어때요?\"\n",
    "    corpus = processed_df['Q_processed'].sample(min(100, len(processed_df))).tolist()\n",
    "    similar_texts = bert_embedding.find_similar_texts(query, corpus, top_k=3)\n",
    "    \n",
    "    print(f\"검색 쿼리: {query}\")\n",
    "    for idx, text, sim in similar_texts:\n",
    "        print(f\"- {text} (유사도: {sim:.4f})\")\n",
    "else:\n",
    "    logger.warning(\"BERT 임베딩 모델이 로드되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb796c4",
   "metadata": {},
   "source": [
    "### 1-11 전처리 결과 검증 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "159ed03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:54:59,454 - __main__ - INFO - 전처리 결과 검증 및 평가 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전처리 결과 평가:\n",
      "총 데이터 수: 12770\n",
      "빈 처리 질문 수: 0 (0.00%)\n",
      "빈 처리 답변 수: 0 (0.00%)\n",
      "짧은 처리 질문 수: 484 (3.79%)\n",
      "짧은 처리 답변 수: 599 (4.69%)\n",
      "원본 질문 평균 길이: 14.47 글자\n",
      "처리 질문 평균 길이: 14.88 글자\n",
      "원본 답변 평균 길이: 14.30 글자\n",
      "처리 답변 평균 길이: 15.25 글자\n",
      "형태소 분석 성공률: 100.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문제가 있는 전처리 케이스:\n"
     ]
    }
   ],
   "source": [
    "def evaluate_preprocessing(original_df, processed_df):\n",
    "    \"\"\"전처리 결과 검증 및 평가\"\"\"\n",
    "    logger.info(\"전처리 결과 검증 및 평가 중...\")\n",
    "    \n",
    "    evaluation_results = {\n",
    "        \"total_rows\": len(processed_df),\n",
    "        \"empty_processed_q\": 0,\n",
    "        \"empty_processed_a\": 0,\n",
    "        \"short_processed_q\": 0,\n",
    "        \"short_processed_a\": 0,\n",
    "        \"avg_original_q_length\": 0,\n",
    "        \"avg_processed_q_length\": 0,\n",
    "        \"avg_original_a_length\": 0,\n",
    "        \"avg_processed_a_length\": 0,\n",
    "        \"morpheme_tokenization_success\": 0\n",
    "    }\n",
    "    \n",
    "    # 기본 통계\n",
    "    evaluation_results[\"avg_original_q_length\"] = original_df['Q'].apply(len).mean()\n",
    "    evaluation_results[\"avg_original_a_length\"] = original_df['A'].apply(len).mean()\n",
    "    evaluation_results[\"avg_processed_q_length\"] = processed_df['Q_processed'].apply(len).mean()\n",
    "    evaluation_results[\"avg_processed_a_length\"] = processed_df['A_processed'].apply(len).mean()\n",
    "    \n",
    "    # 빈 값 검사\n",
    "    evaluation_results[\"empty_processed_q\"] = (processed_df['Q_processed'].str.strip() == \"\").sum()\n",
    "    evaluation_results[\"empty_processed_a\"] = (processed_df['A_processed'].str.strip() == \"\").sum()\n",
    "    \n",
    "    # 짧은 텍스트 검사 (2단어 미만)\n",
    "    evaluation_results[\"short_processed_q\"] = (processed_df['Q_processed'].apply(lambda x: len(x.split()) < 2 if isinstance(x, str) else True)).sum()\n",
    "    evaluation_results[\"short_processed_a\"] = (processed_df['A_processed'].apply(lambda x: len(x.split()) < 2 if isinstance(x, str) else True)).sum()\n",
    "    \n",
    "    # 형태소 분석 성공률\n",
    "    non_empty_morphemes_q = ~(processed_df['Q_morphemes'].isnull() | (processed_df['Q_morphemes'] == \"\"))\n",
    "    non_empty_morphemes_a = ~(processed_df['A_morphemes'].isnull() | (processed_df['A_morphemes'] == \"\"))\n",
    "    evaluation_results[\"morpheme_tokenization_success\"] = (non_empty_morphemes_q & non_empty_morphemes_a).sum()\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"\\n전처리 결과 평가:\")\n",
    "    print(f\"총 데이터 수: {evaluation_results['total_rows']}\")\n",
    "    print(f\"빈 처리 질문 수: {evaluation_results['empty_processed_q']} ({evaluation_results['empty_processed_q']/evaluation_results['total_rows']*100:.2f}%)\")\n",
    "    print(f\"빈 처리 답변 수: {evaluation_results['empty_processed_a']} ({evaluation_results['empty_processed_a']/evaluation_results['total_rows']*100:.2f}%)\")\n",
    "    print(f\"짧은 처리 질문 수: {evaluation_results['short_processed_q']} ({evaluation_results['short_processed_q']/evaluation_results['total_rows']*100:.2f}%)\")\n",
    "    print(f\"짧은 처리 답변 수: {evaluation_results['short_processed_a']} ({evaluation_results['short_processed_a']/evaluation_results['total_rows']*100:.2f}%)\")\n",
    "    print(f\"원본 질문 평균 길이: {evaluation_results['avg_original_q_length']:.2f} 글자\")\n",
    "    print(f\"처리 질문 평균 길이: {evaluation_results['avg_processed_q_length']:.2f} 글자\")\n",
    "    print(f\"원본 답변 평균 길이: {evaluation_results['avg_original_a_length']:.2f} 글자\")\n",
    "    print(f\"처리 답변 평균 길이: {evaluation_results['avg_processed_a_length']:.2f} 글자\")\n",
    "    print(f\"형태소 분석 성공률: {evaluation_results['morpheme_tokenization_success']/evaluation_results['total_rows']*100:.2f}%\")\n",
    "    \n",
    "    # 원본과 처리된 텍스트 비교 시각화\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # 질문 길이 비교\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.hist(original_df['Q'].apply(len), bins=50, alpha=0.5, color='blue', label='원본 질문')\n",
    "    plt.hist(processed_df['Q_processed'].apply(len), bins=50, alpha=0.5, color='green', label='처리된 질문')\n",
    "    plt.xlabel('문장 길이 (글자 수)')\n",
    "    plt.ylabel('빈도')\n",
    "    plt.title('원본 vs 처리된 질문 길이 분포')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 답변 길이 비교\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.hist(original_df['A'].apply(len), bins=50, alpha=0.5, color='red', label='원본 답변')\n",
    "    plt.hist(processed_df['A_processed'].apply(len), bins=50, alpha=0.5, color='orange', label='처리된 답변')\n",
    "    plt.xlabel('문장 길이 (글자 수)')\n",
    "    plt.ylabel('빈도')\n",
    "    plt.title('원본 vs 처리된 답변 길이 분포')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(data_dir, 'preprocessing_evaluation.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "# 전처리 결과 분석\n",
    "evaluation_results = evaluate_preprocessing(combined_df, processed_df)\n",
    "\n",
    "# 문제 케이스 확인\n",
    "def show_problematic_cases(df, n=10):\n",
    "    \"\"\"문제가 있는 전처리 케이스 보여주기\"\"\"\n",
    "    print(\"\\n문제가 있는 전처리 케이스:\")\n",
    "    \n",
    "    # 빈 처리 결과 케이스\n",
    "    empty_processed = df[(df['Q_processed'].str.strip() == \"\") | (df['A_processed'].str.strip() == \"\")]\n",
    "    if len(empty_processed) > 0:\n",
    "        print(\"\\n빈 처리 결과 케이스:\")\n",
    "        for i, row in empty_processed.head(n).iterrows():\n",
    "            print(f\"원본 Q: {row['Q']}\")\n",
    "            print(f\"처리 Q: {row['Q_processed']}\")\n",
    "            print(f\"원본 A: {row['A']}\")\n",
    "            print(f\"처리 A: {row['A_processed']}\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    # 심하게 변경된 케이스 (길이가 50% 이상 줄어든 경우)\n",
    "    def length_reduction_ratio(orig, proc):\n",
    "        if not isinstance(orig, str) or not isinstance(proc, str) or len(orig) == 0:\n",
    "            return 0\n",
    "        return (len(orig) - len(proc)) / len(orig)\n",
    "    \n",
    "    df['q_reduction'] = df.apply(lambda x: length_reduction_ratio(x['Q'], x['Q_processed']), axis=1)\n",
    "    df['a_reduction'] = df.apply(lambda x: length_reduction_ratio(x['A'], x['A_processed']), axis=1)\n",
    "    \n",
    "    heavily_reduced = df[(df['q_reduction'] > 0.5) | (df['a_reduction'] > 0.5)]\n",
    "    if len(heavily_reduced) > 0:\n",
    "        print(\"\\n심하게 변경된 케이스 (길이 50% 이상 감소):\")\n",
    "        for i, row in heavily_reduced.head(n).iterrows():\n",
    "            print(f\"원본 Q: {row['Q']}\")\n",
    "            print(f\"처리 Q: {row['Q_processed']} (감소율: {row['q_reduction']:.2f})\")\n",
    "            print(f\"원본 A: {row['A']}\")\n",
    "            print(f\"처리 A: {row['A_processed']} (감소율: {row['a_reduction']:.2f})\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "# 문제 케이스 확인\n",
    "show_problematic_cases(processed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406b7bd",
   "metadata": {},
   "source": [
    "### 1-12 최종 데이터 품질 개선 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417007db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:55:00,879 - __main__ - INFO - 데이터 품질 개선 중...\n",
      "2025-04-21 01:55:00,903 - __main__ - INFO - 데이터 품질 개선 완료: 12770개 -> 12767개 (99.98%)\n",
      "2025-04-21 01:55:00,995 - __main__ - INFO - 최종 전처리 데이터 저장 완료: chatbot_data/final_preprocessed_chat_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 데이터셋 통계:\n",
      "원본 데이터 크기: 12770\n",
      "처리 데이터 크기: 12770\n",
      "최종 데이터 크기: 12767\n",
      "데이터 보존율: 99.98\n",
      "\n",
      "최종 데이터셋 샘플:\n",
      "                 Q      Q_processed             Q_morphemes            A  \\\n",
      "0           12시 땡!          12시 땡 !                12 시 땡 !   하루가 또 가네요.   \n",
      "1      1지망 학교 떨어졌어      1지망 학교 떨어졌어           1 지망 학교 떨어졌 어    위로해 드립니다.   \n",
      "2     3박4일 놀러가고 싶다     3박4일 놀러가고 싶다     3 박 4 일 놀 러 가 고 싶 다  여행은 언제나 좋죠.   \n",
      "3  3박4일 정도 놀러가고 싶다  3박4일 정도 놀러가고 싶다  3 박 4 일 정도 놀 러 가 고 싶 다  여행은 언제나 좋죠.   \n",
      "4          PPL 심하네          PPL 심하네                PPL 심하 네   눈살이 찌푸려지죠.   \n",
      "\n",
      "    A_processed     A_morphemes  \n",
      "0   하루가 또 가네요 .   하루 가 또 가 네요 .  \n",
      "1    위로해 드립니다 .     위로 해 드립니다 .  \n",
      "2  여행은 언제나 좋죠 .  여행 은 언제나 좋 죠 .  \n",
      "3  여행은 언제나 좋죠 .  여행 은 언제나 좋 죠 .  \n",
      "4   눈살이 찌푸려지죠 .  눈살 이 찌푸려 지 죠 .  \n"
     ]
    }
   ],
   "source": [
    "def improve_data_quality(df):\n",
    "    \"\"\"데이터 품질 개선 - 개선된 버전\"\"\"\n",
    "    logger.info(\"데이터 품질 개선 중...\")\n",
    "    \n",
    "    # 처리 전 데이터 크기\n",
    "    initial_size = len(df)\n",
    "    \n",
    "    # 1. 완전히 빈 처리 결과만 제거 (매우 관대한 필터링)\n",
    "    df = df[~((df['Q_processed'].isnull()) | (df['A_processed'].isnull()))]\n",
    "    \n",
    "    # 2. 매우 짧은 처리 결과만 제거 (1글자 이하)\n",
    "    df = df[~((df['Q_processed'].apply(lambda x: len(str(x)) <= 1)) & \n",
    "             (df['A_processed'].apply(lambda x: len(str(x)) <= 1)))]\n",
    "    \n",
    "    # 3. 중복 제거 (Q와 A가 모두 동일한 경우만)\n",
    "    df = df.drop_duplicates(subset=['Q_processed', 'A_processed'])\n",
    "    \n",
    "    # 처리 후 데이터 크기\n",
    "    final_size = len(df)\n",
    "    \n",
    "    logger.info(f\"데이터 품질 개선 완료: {initial_size}개 -> {final_size}개 ({final_size/initial_size*100:.2f}%)\")\n",
    "    return df\n",
    "\n",
    "# 데이터 품질 개선\n",
    "improved_df = improve_data_quality(processed_df)\n",
    "\n",
    "# 최종 데이터셋 저장\n",
    "final_output_path = os.path.join(data_dir, 'final_preprocessed_chat_data.csv')\n",
    "improved_df.to_csv(final_output_path, index=False)\n",
    "logger.info(f\"최종 전처리 데이터 저장 완료: {final_output_path}\")\n",
    "\n",
    "# 최종 데이터 통계\n",
    "final_stats = {\n",
    "    \"원본 데이터 크기\": len(combined_df),\n",
    "    \"처리 데이터 크기\": len(processed_df),\n",
    "    \"최종 데이터 크기\": len(improved_df),\n",
    "    \"데이터 보존율\": len(improved_df) / len(combined_df) * 100\n",
    "}\n",
    "\n",
    "print(\"\\n최종 데이터셋 통계:\")\n",
    "for key, value in final_stats.items():\n",
    "    print(f\"{key}: {value:.2f}\" if isinstance(value, float) else f\"{key}: {value}\")\n",
    "\n",
    "# 최종 데이터 샘플 출력\n",
    "print(\"\\n최종 데이터셋 샘플:\")\n",
    "display_columns = ['Q', 'Q_processed', 'Q_morphemes', 'A', 'A_processed', 'A_morphemes']\n",
    "print(improved_df[display_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbaef37",
   "metadata": {},
   "source": [
    "### 1-13 메타데이터 및 프로젝트 정보 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc2b38fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:55:01,014 - __main__ - INFO - 프로젝트 메타데이터 저장 중...\n",
      "2025-04-21 01:55:01,015 - __main__ - INFO - 프로젝트 메타데이터 저장 완료: chatbot_data/project_metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "프로젝트 메타데이터:\n",
      "project_name: 한국어 챗봇 개발\n",
      "step: 데이터 수집 및 전처리\n",
      "created_at: 2025-04-21 01:55:01\n",
      "data_stats: {'original_data_size': 12770, 'processed_data_size': 12770, 'final_data_size': 12767, 'data_preservation_rate': 99.97650743931088}\n",
      "preprocessing_pipeline: {'tools': {'morpheme_analyzer': 'Mecab', 'use_soynlp': True}, 'stopwords_count': 17, 'slang_dict_count': 30}\n",
      "embedding_models: {'word2vec': True, 'fasttext': True, 'bert': True}\n",
      "dialogue_context: {'conversations_count': 200, 'max_context_length': 3}\n"
     ]
    }
   ],
   "source": [
    "def save_project_metadata():\n",
    "    \"\"\"프로젝트 메타데이터 저장\"\"\"\n",
    "    logger.info(\"프로젝트 메타데이터 저장 중...\")\n",
    "    \n",
    "    # 프로젝트 메타데이터\n",
    "    metadata = {\n",
    "        \"project_name\": \"한국어 챗봇 개발\",\n",
    "        \"step\": \"데이터 수집 및 전처리\",\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"data_stats\": {\n",
    "            \"original_data_size\": len(combined_df),\n",
    "            \"processed_data_size\": len(processed_df),\n",
    "            \"final_data_size\": len(improved_df),\n",
    "            \"data_preservation_rate\": len(improved_df) / len(combined_df) * 100\n",
    "        },\n",
    "        \"preprocessing_pipeline\": {\n",
    "            \"tools\": {\n",
    "                \"morpheme_analyzer\": str(preprocessor.morpheme_analyzer.__class__.__name__),\n",
    "                \"use_soynlp\": preprocessor.use_soynlp\n",
    "            },\n",
    "            \"stopwords_count\": len(preprocessor.stopwords),\n",
    "            \"slang_dict_count\": len(preprocessor.slang_dict)\n",
    "        },\n",
    "        \"embedding_models\": {\n",
    "            \"word2vec\": embedding_manager.word2vec_model is not None,\n",
    "            \"fasttext\": embedding_manager.fasttext_model is not None,\n",
    "            \"bert\": bert_embedding.is_model_loaded()\n",
    "        },\n",
    "        \"dialogue_context\": {\n",
    "            \"conversations_count\": len(dialogue_manager.conversation_flows),\n",
    "            \"max_context_length\": dialogue_manager.max_context_length\n",
    "        },\n",
    "        \"file_paths\": {\n",
    "            \"combined_data\": os.path.join(data_dir, 'combined_chat_data.csv'),\n",
    "            \"processed_data\": os.path.join(data_dir, 'processed_chat_data.csv'),\n",
    "            \"final_data\": os.path.join(data_dir, 'final_preprocessed_chat_data.csv'),\n",
    "            \"word2vec_model\": os.path.join(data_dir, 'word2vec_model.bin'),\n",
    "            \"fasttext_model\": os.path.join(data_dir, 'fasttext_model.bin'),\n",
    "            \"structured_dialogue\": os.path.join(data_dir, 'structured_dialogue_data.json'),\n",
    "            \"context_qa_pairs\": os.path.join(data_dir, 'context_qa_pairs.json')\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 메타데이터 저장\n",
    "    metadata_path = os.path.join(data_dir, 'project_metadata.json')\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    logger.info(f\"프로젝트 메타데이터 저장 완료: {metadata_path}\")\n",
    "    return metadata\n",
    "\n",
    "# 프로젝트 메타데이터 저장\n",
    "metadata = save_project_metadata()\n",
    "\n",
    "print(\"\\n프로젝트 메타데이터:\")\n",
    "for key, value in metadata.items():\n",
    "    if key != \"file_paths\":  # 파일 경로는 너무 길어서 제외\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e0214",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 증강 및 토큰화 개선\n",
    "\n",
    "- data 증강: 주제, 감정, 동의어, 백트랜슬레이션, 문장 패턴 etc. 적용하여 dataset 2배 가까이 확장\n",
    "- 한국어 형태소 기반의 서브워드 토크나이저를 구축 (자연스러운 문장 분해와 재구성이 가능하도록)\n",
    "- 결과: 증강 data와 토큰화 data 모두 성공적으로 생성&저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d76f0",
   "metadata": {},
   "source": [
    "### 2-1 필요 라이브러리 임포트 및 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99701798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가로 필요한 라이브러리 임포트\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "# 데이터 디렉토리 설정 \n",
    "data_dir = \"chatbot_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# 랜덤 시드 설정 \n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# NLTK 데이터 다운로드 (새로 필요한 부분)\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "except:\n",
    "    logger.warning(\"NLTK 데이터 다운로드 실패. 이미 설치되어 있거나 네트워크 문제일 수 있습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a63c50",
   "metadata": {},
   "source": [
    "### 2-2 데이터 로드 및 전처리 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9273bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 02:09:46,267 - __main__ - INFO - 전처리된 데이터 로드 중...\n",
      "2025-04-21 02:09:46,356 - __main__ - INFO - 전처리된 데이터 로드 완료: 12767개\n",
      "2025-04-21 02:09:46,388 - __main__ - INFO - 질문-답변 쌍 12767개 추출 완료\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 미리보기:\n",
      "                 Q            A  source      Q_processed   A_processed  \\\n",
      "0           12시 땡!   하루가 또 가네요.  songys          12시 땡 !   하루가 또 가네요 .   \n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.  songys      1지망 학교 떨어졌어    위로해 드립니다 .   \n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.  songys     3박4일 놀러가고 싶다  여행은 언제나 좋죠 .   \n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.  songys  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠 .   \n",
      "4          PPL 심하네   눈살이 찌푸려지죠.  songys          PPL 심하네   눈살이 찌푸려지죠 .   \n",
      "\n",
      "              Q_morphemes     A_morphemes  q_reduction  a_reduction  \n",
      "0                12 시 땡 !   하루 가 또 가 네요 .    -0.166667    -0.100000  \n",
      "1           1 지망 학교 떨어졌 어     위로 해 드립니다 .     0.000000    -0.111111  \n",
      "2     3 박 4 일 놀 러 가 고 싶 다  여행 은 언제나 좋 죠 .     0.000000    -0.090909  \n",
      "3  3 박 4 일 정도 놀 러 가 고 싶 다  여행 은 언제나 좋 죠 .     0.000000    -0.090909  \n",
      "4                PPL 심하 네  눈살 이 찌푸려 지 죠 .     0.000000    -0.100000  \n",
      "\n",
      "데이터셋 크기: 12767\n",
      "데이터셋 컬럼: ['Q', 'A', 'source', 'Q_processed', 'A_processed', 'Q_morphemes', 'A_morphemes', 'q_reduction', 'a_reduction']\n",
      "질문 평균 단어 수: 4.33\n",
      "질문 최대 단어 수: 22\n",
      "답변 평균 단어 수: 4.48\n",
      "답변 최대 단어 수: 24\n",
      "\n",
      "형태소 분석 결과 샘플:\n",
      "원문 Q: 12시 땡!\n",
      "형태소 Q: 12 시 땡 !\n",
      "원문 A: 하루가 또 가네요.\n",
      "형태소 A: 하루 가 또 가 네요 .\n",
      "--------------------------------------------------\n",
      "원문 Q: 1지망 학교 떨어졌어\n",
      "형태소 Q: 1 지망 학교 떨어졌 어\n",
      "원문 A: 위로해 드립니다.\n",
      "형태소 A: 위로 해 드립니다 .\n",
      "--------------------------------------------------\n",
      "원문 Q: 3박4일 놀러가고 싶다\n",
      "형태소 Q: 3 박 4 일 놀 러 가 고 싶 다\n",
      "원문 A: 여행은 언제나 좋죠.\n",
      "형태소 A: 여행 은 언제나 좋 죠 .\n",
      "--------------------------------------------------\n",
      "원문 Q: 3박4일 정도 놀러가고 싶다\n",
      "형태소 Q: 3 박 4 일 정도 놀 러 가 고 싶 다\n",
      "원문 A: 여행은 언제나 좋죠.\n",
      "형태소 A: 여행 은 언제나 좋 죠 .\n",
      "--------------------------------------------------\n",
      "원문 Q: PPL 심하네\n",
      "형태소 Q: PPL 심하 네\n",
      "원문 A: 눈살이 찌푸려지죠.\n",
      "형태소 A: 눈살 이 찌푸려 지 죠 .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def load_processed_data():\n",
    "    \"\"\"Step1에서 전처리한 데이터 로드\"\"\"\n",
    "    logger.info(\"전처리된 데이터 로드 중...\")\n",
    "    \n",
    "    # 최종 전처리된 데이터 로드\n",
    "    processed_data_path = os.path.join(data_dir, 'final_preprocessed_chat_data.csv')\n",
    "    \n",
    "    if os.path.exists(processed_data_path):\n",
    "        df = pd.read_csv(processed_data_path)\n",
    "        logger.info(f\"전처리된 데이터 로드 완료: {len(df)}개\")\n",
    "        return df\n",
    "    else:\n",
    "        # 전처리된 데이터가 없는 경우 원본 데이터 로드\n",
    "        logger.warning(\"전처리된 데이터를 찾을 수 없습니다. 원본 데이터를 로드합니다.\")\n",
    "        combined_data_path = os.path.join(data_dir, 'combined_chat_data.csv')\n",
    "        \n",
    "        if os.path.exists(combined_data_path):\n",
    "            df = pd.read_csv(combined_data_path)\n",
    "            logger.info(f\"원본 데이터 로드 완료: {len(df)}개\")\n",
    "            return df\n",
    "        else:\n",
    "            logger.error(\"데이터 파일을 찾을 수 없습니다.\")\n",
    "            return None\n",
    "\n",
    "# 전처리된 데이터 로드\n",
    "processed_df = load_processed_data()\n",
    "\n",
    "if processed_df is not None:\n",
    "    print(\"데이터셋 미리보기:\")\n",
    "    print(processed_df.head())\n",
    "    \n",
    "    # 데이터 통계 출력\n",
    "    print(f\"\\n데이터셋 크기: {len(processed_df)}\")\n",
    "    \n",
    "    # 컬럼 확인\n",
    "    print(f\"데이터셋 컬럼: {processed_df.columns.tolist()}\")\n",
    "    \n",
    "    # 질문/답변 길이 분포\n",
    "    q_lengths = processed_df['Q_processed'].apply(lambda x: len(str(x).split()))\n",
    "    a_lengths = processed_df['A_processed'].apply(lambda x: len(str(x).split()))\n",
    "    \n",
    "    print(f\"질문 평균 단어 수: {q_lengths.mean():.2f}\")\n",
    "    print(f\"질문 최대 단어 수: {q_lengths.max()}\")\n",
    "    print(f\"답변 평균 단어 수: {a_lengths.mean():.2f}\")\n",
    "    print(f\"답변 최대 단어 수: {a_lengths.max()}\")\n",
    "    \n",
    "    # 형태소 분석 결과 확인\n",
    "    print(\"\\n형태소 분석 결과 샘플:\")\n",
    "    for i in range(min(5, len(processed_df))):\n",
    "        print(f\"원문 Q: {processed_df.iloc[i]['Q']}\")\n",
    "        print(f\"형태소 Q: {processed_df.iloc[i]['Q_morphemes']}\")\n",
    "        print(f\"원문 A: {processed_df.iloc[i]['A']}\")\n",
    "        print(f\"형태소 A: {processed_df.iloc[i]['A_morphemes']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # 데이터 추출\n",
    "    questions = processed_df['Q_processed'].tolist()\n",
    "    answers = processed_df['A_processed'].tolist()\n",
    "    questions_morpheme = processed_df['Q_morphemes'].tolist()\n",
    "    answers_morpheme = processed_df['A_morphemes'].tolist()\n",
    "    \n",
    "    logger.info(f\"질문-답변 쌍 {len(questions)}개 추출 완료\")\n",
    "else:\n",
    "    logger.error(\"데이터 로드 실패. 프로그램을 종료합니다.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec4d98",
   "metadata": {},
   "source": [
    "### 2-3 텍스트 분석 및 분류 기능 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9f1817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 02:09:53,025 - __main__ - INFO - 텍스트 분석기 초기화 완료\n",
      "2025-04-21 02:09:53,027 - __main__ - INFO - TF-IDF 벡터라이저 학습 중...\n",
      "2025-04-21 02:09:53,470 - __main__ - INFO - TF-IDF 벡터라이저 학습 완료 (특성 수: 10000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "텍스트 분석 테스트:\n",
      "텍스트: 오늘 시험을 망쳐서 너무 슬퍼요. 어떻게 해야 할까요?\n",
      "주제: 학업\n",
      "감정: 슬픔\n",
      "문장 유형: 질문\n",
      "단어 수: 8\n",
      "--------------------------------------------------\n",
      "텍스트: 남자친구가 생일 선물로 뭘 주면 좋을까요?\n",
      "주제: 일상\n",
      "감정: 중립\n",
      "문장 유형: 질문\n",
      "단어 수: 6\n",
      "--------------------------------------------------\n",
      "텍스트: 요즘 날씨가 너무 좋아서 기분이 좋아요!\n",
      "주제: 일상\n",
      "감정: 기쁨\n",
      "문장 유형: 감탄\n",
      "단어 수: 6\n",
      "--------------------------------------------------\n",
      "텍스트: 회사에서 상사가 자꾸 괴롭혀서 스트레스 받아요.\n",
      "주제: 직장\n",
      "감정: 불안\n",
      "문장 유형: 서술\n",
      "단어 수: 6\n",
      "--------------------------------------------------\n",
      "텍스트: 오늘 저녁 뭐 먹을까요?\n",
      "주제: 일반\n",
      "감정: 중립\n",
      "문장 유형: 질문\n",
      "단어 수: 4\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class TextAnalyzer:\n",
    "    \"\"\"텍스트 분석 및 분류 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 주제별 키워드 정의\n",
    "        self.topic_keywords = {\n",
    "            '학업': ['시험', '공부', '학교', '숙제', '성적', '교수', '학생', '강의', '수업', '과제', '논문', '발표', '연구', '전공', '학점'],\n",
    "            '건강': ['아프다', '병원', '운동', '다이어트', '피곤', '건강', '약', '치료', '증상', '통증', '두통', '감기', '질병', '영양', '수면'],\n",
    "            '연애': ['좋아해', '사랑', '고백', '썸', '이별', '남자친구', '여자친구', '연인', '데이트', '결혼', '짝사랑', '이혼', '소개팅', '썸', '고백'],\n",
    "            '일상': ['밥', '날씨', '쇼핑', '영화', '여행', '취미', '휴식', '주말', '요리', '음식', '카페', '집', '친구', '가족', '생일'],\n",
    "            '감정': ['기쁘다', '슬프다', '화나다', '불안', '걱정', '우울', '행복', '스트레스', '분노', '기쁨', '슬픔', '후회', '불만', '만족', '실망'],\n",
    "            '직장': ['회사', '업무', '상사', '동료', '퇴근', '출근', '프로젝트', '이직', '연봉', '승진', '퇴사', '취업', '면접', '경력', '직무'],\n",
    "            '취미': ['게임', '독서', '음악', '영화', '드라마', '공연', '전시', '여행', '요리', '스포츠', '사진', '그림', '춤', '노래', '악기'],\n",
    "            '사회': ['뉴스', '정치', '경제', '사회', '문화', '환경', '기술', '과학', '법률', '교육', '복지', '인권', '국제', '역사', '종교']\n",
    "        }\n",
    "        \n",
    "        # 감정 키워드 정의\n",
    "        self.emotion_keywords = {\n",
    "            '기쁨': ['좋아', '행복', '신나', '즐거워', '기뻐', '웃', '신남', '좋았', '재밌', '설레', '만족', '감사', '흥분', '기쁘', '즐거움'],\n",
    "            '슬픔': ['슬퍼', '우울', '힘들어', '아파', '눈물', '울', '서럽', '그리움', '외로움', '쓸쓸', '공허', '상실', '아쉬움', '실망', '허무'],\n",
    "            '분노': ['화나', '짜증', '열받아', '미쳐', '짜증나', '화가', '분노', '억울', '답답', '불만', '격분', '증오', '혐오', '불쾌', '격노'],\n",
    "            '불안': ['걱정', '불안', '긴장', '두려워', '무서워', '겁나', '조마조마', '떨려', '초조', '스트레스', '공포', '당황', '놀람', '충격', '혼란'],\n",
    "            '중립': ['그냥', '보통', '평범', '일상', '특별하지않아', '괜찮', '그저', '별거', '무난', '적당', '보통', '평이', '중간', '보편적', '일반적']\n",
    "        }\n",
    "        \n",
    "        # 문장 유형 패턴 정의\n",
    "        self.sentence_patterns = {\n",
    "            '질문': [r'\\?', r'까\\?', r'니\\?', r'세요\\?', r'어떻', r'언제', r'누구', r'무엇', r'왜', r'어디', r'몇', r'얼마'],\n",
    "            '명령': [r'해주세요', r'하세요', r'해봐', r'해라', r'해줘', r'해봐요', r'하지마', r'하지마세요', r'해야해'],\n",
    "            '감탄': [r'\\!', r'와\\!', r'우와', r'대박', r'신기', r'멋지', r'놀라', r'감동', r'최고'],\n",
    "            '서술': [r'이다', r'입니다', r'예요', r'이에요', r'이야', r'이네', r'이네요', r'군요', r'구나']\n",
    "        }\n",
    "        \n",
    "        # TF-IDF 벡터라이저 초기화\n",
    "        self.tfidf_vectorizer = None\n",
    "        \n",
    "        logger.info(\"텍스트 분석기 초기화 완료\")\n",
    "    \n",
    "    def classify_topic(self, text):\n",
    "        \"\"\"주제 분류 함수\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return '일반'\n",
    "        \n",
    "        # 주제 점수 계산\n",
    "        topic_scores = {}\n",
    "        for topic, keywords in self.topic_keywords.items():\n",
    "            # 키워드 매칭 점수\n",
    "            keyword_score = sum(1 for keyword in keywords if keyword in text)\n",
    "            \n",
    "            # 단어 유사도 점수 (단어 포함 여부)\n",
    "            word_score = sum(1 for word in text.split() for keyword in keywords \n",
    "                            if keyword in word or word in keyword)\n",
    "            \n",
    "            # 최종 점수 계산 (키워드 매칭에 더 높은 가중치)\n",
    "            topic_scores[topic] = keyword_score * 2 + word_score\n",
    "        \n",
    "        # 가장 높은 점수의 주제 반환\n",
    "        max_score = max(topic_scores.values()) if topic_scores else 0\n",
    "        \n",
    "        # 점수가 0이거나 매우 낮으면 '일반' 반환\n",
    "        if max_score <= 1:\n",
    "            return '일반'\n",
    "        \n",
    "        # 가장 높은 점수의 주제 반환\n",
    "        return max(topic_scores.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    def analyze_emotion(self, text):\n",
    "        \"\"\"감정 분석 함수\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return '중립'\n",
    "        \n",
    "        # 감정 점수 계산\n",
    "        emotion_scores = {}\n",
    "        for emotion, keywords in self.emotion_keywords.items():\n",
    "            # 키워드 매칭 점수\n",
    "            keyword_score = sum(1 for keyword in keywords if keyword in text)\n",
    "            \n",
    "            # 단어 유사도 점수\n",
    "            word_score = sum(1 for word in text.split() for keyword in keywords \n",
    "                            if keyword in word or word in keyword)\n",
    "            \n",
    "            # 최종 점수 계산\n",
    "            emotion_scores[emotion] = keyword_score * 2 + word_score\n",
    "        \n",
    "        # 가장 높은 점수의 감정 반환\n",
    "        max_score = max(emotion_scores.values()) if emotion_scores else 0\n",
    "        \n",
    "        # 점수가 0이거나 매우 낮으면 '중립' 반환\n",
    "        if max_score <= 1:\n",
    "            return '중립'\n",
    "        \n",
    "        # 가장 높은 점수의 감정 반환\n",
    "        return max(emotion_scores.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    def classify_sentence_type(self, text):\n",
    "        \"\"\"문장 유형 분류 함수\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return '서술'\n",
    "        \n",
    "        # 문장 유형 점수 계산\n",
    "        type_scores = {}\n",
    "        for sent_type, patterns in self.sentence_patterns.items():\n",
    "            # 패턴 매칭 점수\n",
    "            score = sum(1 for pattern in patterns if re.search(pattern, text))\n",
    "            type_scores[sent_type] = score\n",
    "        \n",
    "        # 가장 높은 점수의 문장 유형 반환\n",
    "        max_score = max(type_scores.values()) if type_scores else 0\n",
    "        \n",
    "        # 점수가 0이면 '서술' 반환\n",
    "        if max_score == 0:\n",
    "            return '서술'\n",
    "        \n",
    "        # 가장 높은 점수의 문장 유형 반환\n",
    "        return max(type_scores.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    def fit_tfidf_vectorizer(self, texts):\n",
    "        \"\"\"TF-IDF 벡터라이저 학습\"\"\"\n",
    "        if not texts:\n",
    "            logger.warning(\"TF-IDF 벡터라이저 학습을 위한 텍스트가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        logger.info(\"TF-IDF 벡터라이저 학습 중...\")\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(\n",
    "            min_df=2,\n",
    "            max_df=0.9,\n",
    "            max_features=10000,\n",
    "            ngram_range=(1, 2),\n",
    "            sublinear_tf=True\n",
    "        )\n",
    "        self.tfidf_vectorizer.fit(texts)\n",
    "        logger.info(f\"TF-IDF 벡터라이저 학습 완료 (특성 수: {len(self.tfidf_vectorizer.get_feature_names_out())})\")\n",
    "    \n",
    "    def get_text_similarity(self, text1, text2):\n",
    "        \"\"\"두 텍스트 간의 유사도 계산\"\"\"\n",
    "        if not self.tfidf_vectorizer:\n",
    "            logger.warning(\"TF-IDF 벡터라이저가 학습되지 않았습니다.\")\n",
    "            return 0.0\n",
    "        \n",
    "        if not text1 or not text2 or not isinstance(text1, str) or not isinstance(text2, str):\n",
    "            return 0.0\n",
    "        \n",
    "        # TF-IDF 벡터 변환\n",
    "        try:\n",
    "            tfidf_matrix = self.tfidf_vectorizer.transform([text1, text2])\n",
    "            # 코사인 유사도 계산\n",
    "            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "            return similarity\n",
    "        except Exception as e:\n",
    "            logger.error(f\"유사도 계산 중 오류: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def analyze_text(self, text):\n",
    "        \"\"\"텍스트 종합 분석\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return {\n",
    "                'topic': '일반',\n",
    "                'emotion': '중립',\n",
    "                'sentence_type': '서술',\n",
    "                'word_count': 0,\n",
    "                'char_count': 0\n",
    "            }\n",
    "        \n",
    "        # 단어 수 및 문자 수 계산\n",
    "        word_count = len(text.split())\n",
    "        char_count = len(text)\n",
    "        \n",
    "        # 종합 분석 결과 반환\n",
    "        return {\n",
    "            'topic': self.classify_topic(text),\n",
    "            'emotion': self.analyze_emotion(text),\n",
    "            'sentence_type': self.classify_sentence_type(text),\n",
    "            'word_count': word_count,\n",
    "            'char_count': char_count\n",
    "        }\n",
    "\n",
    "# 텍스트 분석기 초기화\n",
    "text_analyzer = TextAnalyzer()\n",
    "\n",
    "# TF-IDF 벡터라이저 학습\n",
    "text_analyzer.fit_tfidf_vectorizer(questions + answers)\n",
    "\n",
    "# 텍스트 분석 테스트\n",
    "print(\"\\n텍스트 분석 테스트:\")\n",
    "test_texts = [\n",
    "    \"오늘 시험을 망쳐서 너무 슬퍼요. 어떻게 해야 할까요?\",\n",
    "    \"남자친구가 생일 선물로 뭘 주면 좋을까요?\",\n",
    "    \"요즘 날씨가 너무 좋아서 기분이 좋아요!\",\n",
    "    \"회사에서 상사가 자꾸 괴롭혀서 스트레스 받아요.\",\n",
    "    \"오늘 저녁 뭐 먹을까요?\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    analysis = text_analyzer.analyze_text(text)\n",
    "    print(f\"텍스트: {text}\")\n",
    "    print(f\"주제: {analysis['topic']}\")\n",
    "    print(f\"감정: {analysis['emotion']}\")\n",
    "    print(f\"문장 유형: {analysis['sentence_type']}\")\n",
    "    print(f\"단어 수: {analysis['word_count']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604725df",
   "metadata": {},
   "source": [
    "### 2-4 데이터 증강 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c00ca6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 02:10:05,526 - __main__ - INFO - 데이터 증강기 초기화 완료\n",
      "2025-04-21 02:10:05,527 - __main__ - INFO - 데이터 증강 시작...\n",
      "2025-04-21 02:10:05,528 - __main__ - INFO - 주제 기반 데이터 증강 시작...\n",
      "주제 분류: 100%|██████████| 2553/2553 [00:00<00:00, 13210.06it/s]\n",
      "주제별 증강: 100%|██████████| 9/9 [00:00<00:00, 8945.20it/s]\n",
      "2025-04-21 02:10:05,730 - __main__ - INFO - 주제 기반 증강 완료: 329개 생성\n",
      "2025-04-21 02:10:05,731 - __main__ - INFO - 감정 기반 데이터 증강 시작...\n",
      "감정 분류: 100%|██████████| 2553/2553 [00:00<00:00, 21033.31it/s]\n",
      "감정별 증강: 100%|██████████| 5/5 [00:00<00:00, 10116.51it/s]\n",
      "2025-04-21 02:10:05,860 - __main__ - INFO - 감정 기반 증강 완료: 134개 생성\n",
      "2025-04-21 02:10:05,861 - __main__ - INFO - 단어 대체 기반 데이터 증강 시작...\n",
      "단어 대체 증강: 100%|██████████| 3830/3830 [00:00<00:00, 10313.37it/s]\n",
      "2025-04-21 02:10:06,238 - __main__ - INFO - 단어 대체 기반 증강 완료: 5336개 생성\n",
      "2025-04-21 02:10:06,239 - __main__ - INFO - 백 트랜슬레이션 시뮬레이션 기반 데이터 증강 시작...\n",
      "백 트랜슬레이션 증강: 100%|██████████| 2553/2553 [00:00<00:00, 17259.45it/s]\n",
      "2025-04-21 02:10:06,392 - __main__ - INFO - 백 트랜슬레이션 시뮬레이션 기반 증강 완료: 4657개 생성\n",
      "2025-04-21 02:10:06,394 - __main__ - INFO - 순서 뒤집기 기반 데이터 증강 시작...\n",
      "순서 뒤집기 증강: 100%|██████████| 1276/1276 [00:00<00:00, 426482.74it/s]\n",
      "2025-04-21 02:10:06,401 - __main__ - INFO - 순서 뒤집기 기반 증강 완료: 724개 생성\n",
      "2025-04-21 02:10:06,401 - __main__ - INFO - 문장 유형 기반 데이터 증강 시작...\n",
      "문장 유형 분류: 100%|██████████| 12767/12767 [00:00<00:00, 38982.17it/s]\n",
      "2025-04-21 02:10:06,732 - __main__ - INFO - 문장 유형 기반 증강 완료: 89개 생성\n",
      "2025-04-21 02:10:06,746 - __main__ - INFO - 원본 데이터 크기: 12767\n",
      "2025-04-21 02:10:06,747 - __main__ - INFO - 증강 후 데이터 크기: 23524\n",
      "2025-04-21 02:10:06,748 - __main__ - INFO - 증강 비율: 1.84배\n",
      "2025-04-21 02:10:06,806 - __main__ - INFO - 증강 데이터 저장 완료: chatbot_data/augmented_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "증강 데이터 샘플:\n",
      "[원본] 질문: 12 시 땡 !\n",
      "[원본] 답변: 하루 가 또 가 네요 .\n",
      "--------------------------------------------------\n",
      "[원본] 질문: 1 지망 학교 떨어졌 어\n",
      "[원본] 답변: 위로 해 드립니다 .\n",
      "--------------------------------------------------\n",
      "[원본] 질문: 3 박 4 일 놀 러 가 고 싶 다\n",
      "[원본] 답변: 여행 은 언제나 좋 죠 .\n",
      "--------------------------------------------------\n",
      "[원본] 질문: 3 박 4 일 정도 놀 러 가 고 싶 다\n",
      "[원본] 답변: 여행 은 언제나 좋 죠 .\n",
      "--------------------------------------------------\n",
      "[원본] 질문: PPL 심하 네\n",
      "[원본] 답변: 눈살 이 찌푸려 지 죠 .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class DataAugmenter:\n",
    "    \"\"\"한국어 데이터 증강 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, text_analyzer=None):\n",
    "        self.text_analyzer = text_analyzer\n",
    "        \n",
    "        # 한국어 조사/어미 변형 사전\n",
    "        self.korean_particles = {\n",
    "            '은': '는', '는': '은', \n",
    "            '이': '가', '가': '이',\n",
    "            '을': '를', '를': '을',\n",
    "            '과': '와', '와': '과'\n",
    "        }\n",
    "        \n",
    "        # 한국어 동의어 사전\n",
    "        self.synonyms = {\n",
    "            # 감정 표현\n",
    "            '좋아': ['마음에 들어', '괜찮아', '훌륭해', '맘에 들어'],\n",
    "            '싫어': ['마음에 안 들어', '별로야', '안 좋아', '맘에 안 들어'],\n",
    "            '행복': ['기쁨', '즐거움', '좋은 기분', '만족'],\n",
    "            '슬픔': ['우울함', '서러움', '마음 아픔', '쓸쓸함'],\n",
    "            '화나': ['짜증나', '열받아', '분노', '불쾌'],\n",
    "            '걱정': ['불안', '염려', '근심', '고민'],\n",
    "            '사랑': ['좋아함', '애정', '마음', '호감'],\n",
    "            '미워': ['싫어함', '증오', '반감', '혐오'],\n",
    "            \n",
    "            # 일상 표현\n",
    "            '먹다': ['식사하다', '섭취하다', '맛보다', '드시다'],\n",
    "            '자다': ['수면하다', '눕다', '쉬다', '취침하다'],\n",
    "            '말하다': ['이야기하다', '얘기하다', '대화하다', '설명하다'],\n",
    "            '보다': ['관찰하다', '확인하다', '살펴보다', '구경하다'],\n",
    "            '듣다': ['경청하다', '청취하다', '들리다', '귀담아듣다'],\n",
    "            '가다': ['이동하다', '방문하다', '향하다', '출발하다'],\n",
    "            '오다': ['도착하다', '방문하다', '찾아오다', '다가오다'],\n",
    "            '웃다': ['미소짓다', '즐거워하다', '기뻐하다', '흐뭇해하다'],\n",
    "            '울다': ['눈물짓다', '흐느끼다', '슬퍼하다', '서러워하다'],\n",
    "            \n",
    "            # 시간 표현\n",
    "            '오늘': ['금일', '지금', '현재', '이날'],\n",
    "            '내일': ['명일', '다음날', '익일', '내일모레'],\n",
    "            '어제': ['전일', '지난날', '하루 전', '어젯밤'],\n",
    "            '지금': ['현재', '이때', '이 순간', '당장'],\n",
    "            '나중': ['이후', '후에', '뒤에', '앞으로'],\n",
    "            \n",
    "            # 정도 표현\n",
    "            '매우': ['아주', '너무', '굉장히', '정말'],\n",
    "            '조금': ['약간', '살짝', '다소', '약간'],\n",
    "            '많이': ['잔뜩', '한참', '가득', '다량'],\n",
    "            '적게': ['소량', '조금', '약간', '몇 안 되게'],\n",
    "            \n",
    "            # 인사 표현\n",
    "            '안녕': ['반가워', '잘 지내', '안녕하세요', '반갑습니다'],\n",
    "            '고마워': ['감사해', '고맙습니다', '감사합니다', '감사'],\n",
    "            '미안해': ['죄송해', '미안합니다', '죄송합니다', '사과드립니다'],\n",
    "            '축하해': ['축하합니다', '축하드려요', '기쁘게 생각해요', '경하를 표합니다']\n",
    "        }\n",
    "        \n",
    "        # 문장 패턴 변환 사전\n",
    "        self.sentence_patterns = {\n",
    "            # 질문 패턴\n",
    "            '(?P<text>.+)\\?': [\n",
    "                '혹시 {text}?', \n",
    "                '{text}...?', \n",
    "                '정말 {text}?',\n",
    "                '혹시나 {text}?',\n",
    "                '그럼 {text}?'\n",
    "            ],\n",
    "            \n",
    "            # 서술 패턴\n",
    "            '나는 (?P<text>.+)': [\n",
    "                '저는 {text}', \n",
    "                '제가 {text}', \n",
    "                '나는 말이야, {text}',\n",
    "                '제 경우는 {text}',\n",
    "                '나로 말하자면 {text}'\n",
    "            ],\n",
    "            \n",
    "            # 감정 표현 패턴\n",
    "            '(?P<text>.+) 좋아': [\n",
    "                '{text} 마음에 들어', \n",
    "                '{text} 괜찮아', \n",
    "                '{text} 훌륭해',\n",
    "                '{text} 좋네요',\n",
    "                '{text} 맘에 들어'\n",
    "            ],\n",
    "            \n",
    "            # 부정 표현 패턴\n",
    "            '(?P<text>.+) 싫어': [\n",
    "                '{text} 마음에 안 들어', \n",
    "                '{text} 별로야', \n",
    "                '{text} 안 좋아',\n",
    "                '{text} 싫네요',\n",
    "                '{text} 맘에 안 들어'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        logger.info(\"데이터 증강기 초기화 완료\")\n",
    "    \n",
    "    def swap_particles(self, text):\n",
    "        \"\"\"한국어 조사/어미 변형\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return text\n",
    "        \n",
    "        words = text.split()\n",
    "        for i, word in enumerate(words):\n",
    "            for particle1, particle2 in self.korean_particles.items():\n",
    "                if word.endswith(particle1):\n",
    "                    words[i] = word[:-len(particle1)] + particle2\n",
    "                    break\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def replace_with_synonyms(self, text, probability=0.5):\n",
    "        \"\"\"동의어 대체\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return text\n",
    "        \n",
    "        words = text.split()\n",
    "        for i, word in enumerate(words):\n",
    "            for key, synonyms in self.synonyms.items():\n",
    "                if key in word and random.random() < probability:\n",
    "                    # 동의어 중 하나를 무작위로 선택\n",
    "                    replacement = random.choice(synonyms)\n",
    "                    words[i] = word.replace(key, replacement)\n",
    "                    break\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def apply_pattern_transformation(self, text):\n",
    "        \"\"\"문장 패턴 변환\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return text\n",
    "        \n",
    "        for pattern, replacements in self.sentence_patterns.items():\n",
    "            match = re.match(pattern, text)\n",
    "            if match:\n",
    "                # 패턴에 맞는 문장이면 변환 패턴 중 하나를 무작위로 선택\n",
    "                replacement_pattern = random.choice(replacements)\n",
    "                # 그룹 캡처한 텍스트 추출\n",
    "                captured_text = match.group('text')\n",
    "                # 새로운 패턴에 적용\n",
    "                return replacement_pattern.format(text=captured_text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def back_translation_simulation(self, text):\n",
    "        \"\"\"백 트랜슬레이션 시뮬레이션 (실제 번역 API 없이 간단한 변형)\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return text\n",
    "        \n",
    "        # 1. 조사/어미 변형\n",
    "        modified_text = self.swap_particles(text)\n",
    "        \n",
    "        # 2. 동의어 대체\n",
    "        modified_text = self.replace_with_synonyms(modified_text, probability=0.3)\n",
    "        \n",
    "        # 3. 문장 패턴 변환 (50% 확률로 적용)\n",
    "        if random.random() < 0.5:\n",
    "            modified_text = self.apply_pattern_transformation(modified_text)\n",
    "        \n",
    "        # 원본과 동일하면 최소한의 변형 적용\n",
    "        if modified_text == text:\n",
    "            words = text.split()\n",
    "            if len(words) > 3:\n",
    "                # 단어 순서 약간 변경\n",
    "                i, j = random.sample(range(len(words)), 2)\n",
    "                words[i], words[j] = words[j], words[i]\n",
    "                modified_text = ' '.join(words)\n",
    "        \n",
    "        return modified_text\n",
    "    \n",
    "    def generate_variations(self, text, num_variations=3):\n",
    "        \"\"\"텍스트 변형 생성\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return []\n",
    "        \n",
    "        variations = []\n",
    "        for _ in range(num_variations):\n",
    "            # 다양한 변형 방법 적용\n",
    "            variation = text\n",
    "            \n",
    "            # 변형 방법 무작위 선택 (중복 가능)\n",
    "            methods = random.choices([\n",
    "                self.swap_particles,\n",
    "                self.replace_with_synonyms,\n",
    "                self.apply_pattern_transformation,\n",
    "                self.back_translation_simulation\n",
    "            ], k=random.randint(1, 3))\n",
    "            \n",
    "            # 선택된 변형 방법 적용\n",
    "            for method in methods:\n",
    "                variation = method(variation)\n",
    "            \n",
    "            # 원본과 다른 경우에만 추가\n",
    "            if variation != text and variation not in variations:\n",
    "                variations.append(variation)\n",
    "        \n",
    "        return variations\n",
    "    \n",
    "    def augment_by_topic(self, questions, answers, sample_ratio=0.2):\n",
    "        \"\"\"주제 기반 데이터 증강\"\"\"\n",
    "        if not self.text_analyzer:\n",
    "            logger.warning(\"텍스트 분석기가 설정되지 않았습니다. 주제 기반 증강을 건너뜁니다.\")\n",
    "            return [], []\n",
    "        \n",
    "        logger.info(\"주제 기반 데이터 증강 시작...\")\n",
    "        \n",
    "        # 주제별 데이터 분류\n",
    "        topic_data = defaultdict(list)\n",
    "        \n",
    "        # 샘플링하여 주제 분류 (전체 데이터의 sample_ratio만큼)\n",
    "        sample_indices = random.sample(range(len(questions)), int(len(questions) * sample_ratio))\n",
    "        \n",
    "        for i in tqdm(sample_indices, desc=\"주제 분류\"):\n",
    "            topic = self.text_analyzer.classify_topic(questions[i])\n",
    "            topic_data[topic].append((questions[i], answers[i]))\n",
    "        \n",
    "        # 증강된 데이터 저장\n",
    "        augmented_questions = []\n",
    "        augmented_answers = []\n",
    "        \n",
    "        # 주제별 데이터 증강\n",
    "        for topic, qa_pairs in tqdm(topic_data.items(), desc=\"주제별 증강\"):\n",
    "            if len(qa_pairs) < 2:\n",
    "                continue\n",
    "            \n",
    "            # 주제별 데이터 크기에 비례하여 증강 데이터 생성\n",
    "            num_augmentations = min(len(qa_pairs) // 2, 50)  # 최대 50개까지 증강\n",
    "            \n",
    "            for _ in range(num_augmentations):\n",
    "                # 무작위로 두 쌍 선택\n",
    "                pair1, pair2 = random.sample(qa_pairs, 2)\n",
    "                q1, a1 = pair1\n",
    "                q2, a2 = pair2\n",
    "                \n",
    "                # 질문1-답변2 조합 (50% 확률)\n",
    "                if random.random() < 0.5:\n",
    "                    augmented_questions.append(q1)\n",
    "                    augmented_answers.append(a2)\n",
    "                # 질문2-답변1 조합 (50% 확률)\n",
    "                else:\n",
    "                    augmented_questions.append(q2)\n",
    "                    augmented_answers.append(a1)\n",
    "        \n",
    "        logger.info(f\"주제 기반 증강 완료: {len(augmented_questions)}개 생성\")\n",
    "        return augmented_questions, augmented_answers\n",
    "    \n",
    "    def augment_by_emotion(self, questions, answers, sample_ratio=0.2):\n",
    "        \"\"\"감정 기반 데이터 증강\"\"\"\n",
    "        if not self.text_analyzer:\n",
    "            logger.warning(\"텍스트 분석기가 설정되지 않았습니다. 감정 기반 증강을 건너뜁니다.\")\n",
    "            return [], []\n",
    "        \n",
    "        logger.info(\"감정 기반 데이터 증강 시작...\")\n",
    "        \n",
    "        # 감정별 데이터 분류\n",
    "        emotion_data = defaultdict(list)\n",
    "        \n",
    "        # 샘플링하여 감정 분류 (전체 데이터의 sample_ratio만큼)\n",
    "        sample_indices = random.sample(range(len(questions)), int(len(questions) * sample_ratio))\n",
    "        \n",
    "        for i in tqdm(sample_indices, desc=\"감정 분류\"):\n",
    "            emotion = self.text_analyzer.analyze_emotion(questions[i])\n",
    "            emotion_data[emotion].append((questions[i], answers[i]))\n",
    "        \n",
    "        # 증강된 데이터 저장\n",
    "        augmented_questions = []\n",
    "        augmented_answers = []\n",
    "        \n",
    "        # 감정별 데이터 증강\n",
    "        for emotion, qa_pairs in tqdm(emotion_data.items(), desc=\"감정별 증강\"):\n",
    "            if len(qa_pairs) < 2:\n",
    "                continue\n",
    "            \n",
    "            # 감정별 데이터 크기에 비례하여 증강 데이터 생성\n",
    "            num_augmentations = min(len(qa_pairs) // 2, 30)  # 최대 30개까지 증강\n",
    "            \n",
    "            for _ in range(num_augmentations):\n",
    "                # 무작위로 두 쌍 선택\n",
    "                pair1, pair2 = random.sample(qa_pairs, 2)\n",
    "                q1, a1 = pair1\n",
    "                q2, a2 = pair2\n",
    "                \n",
    "                # 감정이 같은 질문-답변 쌍 교차 결합\n",
    "                augmented_questions.append(q1)\n",
    "                augmented_answers.append(a2)\n",
    "        \n",
    "        logger.info(f\"감정 기반 증강 완료: {len(augmented_questions)}개 생성\")\n",
    "        return augmented_questions, augmented_answers\n",
    "    \n",
    "    def augment_by_sentence_type(self, questions, answers):\n",
    "        \"\"\"문장 유형 기반 데이터 증강\"\"\"\n",
    "        if not self.text_analyzer:\n",
    "            logger.warning(\"텍스트 분석기가 설정되지 않았습니다. 문장 유형 기반 증강을 건너뜁니다.\")\n",
    "            return [], []\n",
    "        \n",
    "        logger.info(\"문장 유형 기반 데이터 증강 시작...\")\n",
    "        \n",
    "        # 문장 유형별 데이터 분류\n",
    "        type_data = defaultdict(list)\n",
    "        \n",
    "        # 전체 데이터에 대해 문장 유형 분류\n",
    "        for i in tqdm(range(len(questions)), desc=\"문장 유형 분류\"):\n",
    "            sent_type = self.text_analyzer.classify_sentence_type(questions[i])\n",
    "            type_data[sent_type].append((questions[i], answers[i]))\n",
    "        \n",
    "        # 증강된 데이터 저장\n",
    "        augmented_questions = []\n",
    "        augmented_answers = []\n",
    "        \n",
    "        # 질문 유형의 데이터 증강 (질문-질문 쌍 생성)\n",
    "        if '질문' in type_data and len(type_data['질문']) >= 2:\n",
    "            question_pairs = type_data['질문']\n",
    "            \n",
    "            # 최대 100개까지 증강\n",
    "            num_augmentations = min(len(question_pairs) // 2, 100)\n",
    "            \n",
    "            for _ in range(num_augmentations):\n",
    "                # 무작위로 두 쌍 선택\n",
    "                pair1, pair2 = random.sample(question_pairs, 2)\n",
    "                q1, a1 = pair1\n",
    "                q2, a2 = pair2\n",
    "                \n",
    "                # 질문에 대한 질문 생성\n",
    "                if '?' in q1 and '?' in q2:\n",
    "                    augmented_questions.append(q1)\n",
    "                    augmented_answers.append(q2)\n",
    "        \n",
    "        logger.info(f\"문장 유형 기반 증강 완료: {len(augmented_questions)}개 생성\")\n",
    "        return augmented_questions, augmented_answers\n",
    "    \n",
    "    def augment_by_word_replacement(self, questions, answers, sample_ratio=0.3):\n",
    "        \"\"\"단어 대체 기반 데이터 증강\"\"\"\n",
    "        logger.info(\"단어 대체 기반 데이터 증강 시작...\")\n",
    "        \n",
    "        # 증강된 데이터 저장\n",
    "        augmented_questions = []\n",
    "        augmented_answers = []\n",
    "        \n",
    "        # 샘플링하여 단어 대체 (전체 데이터의 sample_ratio만큼)\n",
    "        sample_indices = random.sample(range(len(questions)), int(len(questions) * sample_ratio))\n",
    "        \n",
    "        for i in tqdm(sample_indices, desc=\"단어 대체 증강\"):\n",
    "            q = questions[i]\n",
    "            a = answers[i]\n",
    "            \n",
    "            # 질문에 대한 변형 생성\n",
    "            q_variations = self.generate_variations(q, num_variations=2)\n",
    "            \n",
    "            # 답변에 대한 변형 생성\n",
    "            a_variations = self.generate_variations(a, num_variations=1)\n",
    "            \n",
    "            # 변형된 질문-원본 답변 쌍 추가\n",
    "            for q_var in q_variations:\n",
    "                augmented_questions.append(q_var)\n",
    "                augmented_answers.append(a)\n",
    "            \n",
    "            # 원본 질문-변형된 답변 쌍 추가\n",
    "            for a_var in a_variations:\n",
    "                augmented_questions.append(q)\n",
    "                augmented_answers.append(a_var)\n",
    "        \n",
    "        logger.info(f\"단어 대체 기반 증강 완료: {len(augmented_questions)}개 생성\")\n",
    "        return augmented_questions, augmented_answers\n",
    "    \n",
    "    def augment_by_back_translation(self, questions, answers, sample_ratio=0.2):\n",
    "        \"\"\"백 트랜슬레이션 시뮬레이션 기반 데이터 증강\"\"\"\n",
    "        logger.info(\"백 트랜슬레이션 시뮬레이션 기반 데이터 증강 시작...\")\n",
    "        \n",
    "        # 증강된 데이터 저장\n",
    "        augmented_questions = []\n",
    "        augmented_answers = []\n",
    "        \n",
    "        # 샘플링하여 백 트랜슬레이션 시뮬레이션 (전체 데이터의 sample_ratio만큼)\n",
    "        sample_indices = random.sample(range(len(questions)), int(len(questions) * sample_ratio))\n",
    "        \n",
    "        for i in tqdm(sample_indices, desc=\"백 트랜슬레이션 증강\"):\n",
    "            q = questions[i]\n",
    "            a = answers[i]\n",
    "            \n",
    "            # 백 트랜슬레이션 시뮬레이션 적용\n",
    "            q_bt = self.back_translation_simulation(q)\n",
    "            a_bt = self.back_translation_simulation(a)\n",
    "            \n",
    "            # 원본과 다른 경우에만 추가\n",
    "            if q_bt != q:\n",
    "                augmented_questions.append(q_bt)\n",
    "                augmented_answers.append(a)\n",
    "            \n",
    "            if a_bt != a:\n",
    "                augmented_questions.append(q)\n",
    "                augmented_answers.append(a_bt)\n",
    "        \n",
    "        logger.info(f\"백 트랜슬레이션 시뮬레이션 기반 증강 완료: {len(augmented_questions)}개 생성\")\n",
    "        return augmented_questions, augmented_answers\n",
    "    \n",
    "    def augment_by_order_reversal(self, questions, answers, sample_ratio=0.1):\n",
    "        \"\"\"순서 뒤집기 기반 데이터 증강\"\"\"\n",
    "        logger.info(\"순서 뒤집기 기반 데이터 증강 시작...\")\n",
    "        \n",
    "        # 증강된 데이터 저장\n",
    "        augmented_questions = []\n",
    "        augmented_answers = []\n",
    "        \n",
    "        # 샘플링하여 순서 뒤집기 (전체 데이터의 sample_ratio만큼)\n",
    "        sample_indices = random.sample(range(len(questions)), int(len(questions) * sample_ratio))\n",
    "        \n",
    "        for i in tqdm(sample_indices, desc=\"순서 뒤집기 증강\"):\n",
    "            q = questions[i]\n",
    "            a = answers[i]\n",
    "            \n",
    "            # 답변이 질문이 될 수 있는 경우만 선택 (질문 형태가 아닌 경우)\n",
    "            if not any(pattern in a for pattern in ['?', '까', '니까', '세요']):\n",
    "                # 복잡한 문장만 선택하여 증강 (단어 수가 3개 이상인 경우)\n",
    "                if len(q.split()) > 3 and len(a.split()) > 3:\n",
    "                    augmented_questions.append(a)\n",
    "                    augmented_answers.append(q)\n",
    "        \n",
    "        logger.info(f\"순서 뒤집기 기반 증강 완료: {len(augmented_questions)}개 생성\")\n",
    "        return augmented_questions, augmented_answers\n",
    "    \n",
    "    def augment_data(self, questions, answers, methods=None):\n",
    "        \"\"\"데이터 증강 메인 함수\"\"\"\n",
    "        logger.info(\"데이터 증강 시작...\")\n",
    "        \n",
    "        # 기본 증강 방법 설정\n",
    "        if methods is None:\n",
    "            methods = [\n",
    "                'topic',\n",
    "                'emotion',\n",
    "                'word_replacement',\n",
    "                'back_translation',\n",
    "                'order_reversal',\n",
    "                'sentence_type'\n",
    "            ]\n",
    "        \n",
    "        # 원본 데이터 복사\n",
    "        augmented_questions = questions.copy()\n",
    "        augmented_answers = answers.copy()\n",
    "        \n",
    "        # 증강 방법별 적용\n",
    "        for method in methods:\n",
    "            q_aug, a_aug = [], []\n",
    "            \n",
    "            if method == 'topic':\n",
    "                q_aug, a_aug = self.augment_by_topic(questions, answers)\n",
    "            elif method == 'emotion':\n",
    "                q_aug, a_aug = self.augment_by_emotion(questions, answers)\n",
    "            elif method == 'word_replacement':\n",
    "                q_aug, a_aug = self.augment_by_word_replacement(questions, answers)\n",
    "            elif method == 'back_translation':\n",
    "                q_aug, a_aug = self.augment_by_back_translation(questions, answers)\n",
    "            elif method == 'order_reversal':\n",
    "                q_aug, a_aug = self.augment_by_order_reversal(questions, answers)\n",
    "            elif method == 'sentence_type':\n",
    "                q_aug, a_aug = self.augment_by_sentence_type(questions, answers)\n",
    "            \n",
    "            # 증강 데이터 추가\n",
    "            augmented_questions.extend(q_aug)\n",
    "            augmented_answers.extend(a_aug)\n",
    "        \n",
    "        # 중복 제거\n",
    "        unique_pairs = set()\n",
    "        unique_questions = []\n",
    "        unique_answers = []\n",
    "        \n",
    "        for q, a in zip(augmented_questions, augmented_answers):\n",
    "            pair = (q, a)\n",
    "            if pair not in unique_pairs:\n",
    "                unique_pairs.add(pair)\n",
    "                unique_questions.append(q)\n",
    "                unique_answers.append(a)\n",
    "        \n",
    "        logger.info(f\"원본 데이터 크기: {len(questions)}\")\n",
    "        logger.info(f\"증강 후 데이터 크기: {len(unique_questions)}\")\n",
    "        logger.info(f\"증강 비율: {len(unique_questions) / len(questions):.2f}배\")\n",
    "        \n",
    "        return unique_questions, unique_answers\n",
    "\n",
    "# 데이터 증강기 초기화\n",
    "data_augmenter = DataAugmenter(text_analyzer)\n",
    "\n",
    "# 데이터 증강 적용\n",
    "questions_augmented, answers_augmented = data_augmenter.augment_data(questions_morpheme, answers_morpheme)\n",
    "\n",
    "# 증강 결과 샘플 출력\n",
    "print(\"\\n증강 데이터 샘플:\")\n",
    "for i in range(min(5, len(questions_augmented))):\n",
    "    if i >= len(questions_morpheme):  # 새로 증강된 데이터인 경우\n",
    "        print(f\"[증강] 질문: {questions_augmented[i]}\")\n",
    "        print(f\"[증강] 답변: {answers_augmented[i]}\")\n",
    "    else:  # 원본 데이터인 경우\n",
    "        print(f\"[원본] 질문: {questions_augmented[i]}\")\n",
    "        print(f\"[원본] 답변: {answers_augmented[i]}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 증강 데이터 저장\n",
    "augmented_data = pd.DataFrame({\n",
    "    'Q': questions_augmented,\n",
    "    'A': answers_augmented\n",
    "})\n",
    "augmented_data.to_csv(os.path.join(data_dir, 'augmented_data.csv'), index=False)\n",
    "logger.info(f\"증강 데이터 저장 완료: {os.path.join(data_dir, 'augmented_data.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d957225a",
   "metadata": {},
   "source": [
    "### 2-5 한국어 특화 토큰화 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af7af3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 02:10:23,044 - __main__ - INFO - Mecab 형태소 분석기 초기화 성공\n",
      "2025-04-21 02:10:23,045 - __main__ - INFO - 한국어 토큰화 클래스 초기화 완료\n",
      "2025-04-21 02:10:23,047 - __main__ - INFO - 토크나이저 구축 시작 (목표 어휘 크기: 16384)...\n",
      "2025-04-21 02:10:23,047 - __main__ - INFO - 형태소 분석 기반 토큰화 적용\n",
      "형태소 분석: 100%|██████████| 47048/47048 [00:01<00:00, 24081.02it/s]\n",
      "2025-04-21 02:10:25,500 - absl - INFO - SubwordTextEncoder build: trying min_token_count 12019\n",
      "2025-04-21 02:10:25,897 - absl - INFO - SubwordTextEncoder build: trying min_token_count 6009\n",
      "2025-04-21 02:10:26,269 - absl - INFO - SubwordTextEncoder build: trying min_token_count 3004\n",
      "2025-04-21 02:10:26,626 - absl - INFO - SubwordTextEncoder build: trying min_token_count 1502\n",
      "2025-04-21 02:10:27,014 - absl - INFO - SubwordTextEncoder build: trying min_token_count 751\n",
      "2025-04-21 02:10:27,385 - absl - INFO - SubwordTextEncoder build: trying min_token_count 375\n",
      "2025-04-21 02:10:27,745 - absl - INFO - SubwordTextEncoder build: trying min_token_count 187\n",
      "2025-04-21 02:10:28,093 - absl - INFO - SubwordTextEncoder build: trying min_token_count 93\n",
      "2025-04-21 02:10:28,431 - absl - INFO - SubwordTextEncoder build: trying min_token_count 46\n",
      "2025-04-21 02:10:28,790 - absl - INFO - SubwordTextEncoder build: trying min_token_count 23\n",
      "2025-04-21 02:10:29,196 - absl - INFO - SubwordTextEncoder build: trying min_token_count 11\n",
      "2025-04-21 02:10:29,642 - absl - INFO - SubwordTextEncoder build: trying min_token_count 5\n",
      "2025-04-21 02:10:30,075 - absl - INFO - SubwordTextEncoder build: trying min_token_count 2\n",
      "2025-04-21 02:10:30,587 - absl - INFO - SubwordTextEncoder build: trying min_token_count 1\n",
      "2025-04-21 02:10:31,144 - __main__ - INFO - 토크나이저 구축 완료 (어휘 크기: 12658)\n",
      "2025-04-21 02:10:31,185 - __main__ - INFO - 토크나이저 저장 완료: chatbot_data/korean_tokenizer.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "토크나이저 정보:\n",
      "단어장의 크기: 12658\n",
      "START_TOKEN의 번호: [12656]\n",
      "END_TOKEN의 번호: [12657]\n",
      "\n",
      "토크나이저 테스트:\n",
      "원문: 12 시 땡 !\n",
      "토큰화: [12656, 955, 167, 11376, 124, 12657]\n",
      "디코딩 결과: 12 시 땡 !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class KoreanTokenizer:\n",
    "    \"\"\"한국어 특화 토큰화 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size=2**14, use_morphemes=True):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.use_morphemes = use_morphemes\n",
    "        self.tokenizer = None\n",
    "        self.START_TOKEN = None\n",
    "        self.END_TOKEN = None\n",
    "        self.VOCAB_SIZE = None\n",
    "        \n",
    "        # 한국어 형태소 분석기 (KoNLPy)\n",
    "        self.morpheme_analyzer = None\n",
    "        try:\n",
    "            from konlpy.tag import Mecab\n",
    "            self.morpheme_analyzer = Mecab()\n",
    "            logger.info(\"Mecab 형태소 분석기 초기화 성공\")\n",
    "        except:\n",
    "            try:\n",
    "                from konlpy.tag import Okt\n",
    "                self.morpheme_analyzer = Okt()\n",
    "                logger.info(\"Okt 형태소 분석기 초기화 성공\")\n",
    "            except:\n",
    "                logger.warning(\"형태소 분석기 초기화 실패. 형태소 분석 기능이 비활성화됩니다.\")\n",
    "        \n",
    "        logger.info(\"한국어 토큰화 클래스 초기화 완료\")\n",
    "    \n",
    "    def tokenize_morphemes(self, text):\n",
    "        \"\"\"형태소 분석 기반 토큰화\"\"\"\n",
    "        if not self.morpheme_analyzer or not text:\n",
    "            return text.split()\n",
    "        \n",
    "        try:\n",
    "            if hasattr(self.morpheme_analyzer, 'morphs'):\n",
    "                return self.morpheme_analyzer.morphs(text)\n",
    "            else:\n",
    "                return text.split()\n",
    "        except:\n",
    "            return text.split()\n",
    "    \n",
    "    def build_tokenizer(self, texts, target_vocab_size=None):\n",
    "        \"\"\"토크나이저 구축\"\"\"\n",
    "        if target_vocab_size:\n",
    "            self.vocab_size = target_vocab_size\n",
    "        \n",
    "        logger.info(f\"토크나이저 구축 시작 (목표 어휘 크기: {self.vocab_size})...\")\n",
    "        \n",
    "        # 형태소 분석 적용 여부\n",
    "        if self.use_morphemes and self.morpheme_analyzer:\n",
    "            logger.info(\"형태소 분석 기반 토큰화 적용\")\n",
    "            processed_texts = []\n",
    "            for text in tqdm(texts, desc=\"형태소 분석\"):\n",
    "                morphemes = self.tokenize_morphemes(text)\n",
    "                processed_texts.append(' '.join(morphemes))\n",
    "            \n",
    "            # SubwordTextEncoder 구축\n",
    "            self.tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "                processed_texts, target_vocab_size=self.vocab_size\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"일반 토큰화 적용\")\n",
    "            # SubwordTextEncoder 구축\n",
    "            self.tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "                texts, target_vocab_size=self.vocab_size\n",
    "            )\n",
    "        \n",
    "        # 시작 토큰과 종료 토큰 정의\n",
    "        self.START_TOKEN = [self.tokenizer.vocab_size]\n",
    "        self.END_TOKEN = [self.tokenizer.vocab_size + 1]\n",
    "        self.VOCAB_SIZE = self.tokenizer.vocab_size + 2  # 시작 토큰과 종료 토큰을 고려하여 +2\n",
    "        \n",
    "        logger.info(f\"토크나이저 구축 완료 (어휘 크기: {self.VOCAB_SIZE})\")\n",
    "        \n",
    "        return self.tokenizer\n",
    "    \n",
    "    def save_tokenizer(self, path='tokenizer.pkl'):\n",
    "        \"\"\"토크나이저 저장\"\"\"\n",
    "        if not self.tokenizer:\n",
    "            logger.warning(\"저장할 토크나이저가 없습니다.\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(self.tokenizer, f)\n",
    "            logger.info(f\"토크나이저 저장 완료: {path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"토크나이저 저장 실패: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def load_tokenizer(self, path='tokenizer.pkl'):\n",
    "        \"\"\"토크나이저 로드\"\"\"\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                self.tokenizer = pickle.load(f)\n",
    "            \n",
    "            # 시작 토큰과 종료 토큰 정의\n",
    "            self.START_TOKEN = [self.tokenizer.vocab_size]\n",
    "            self.END_TOKEN = [self.tokenizer.vocab_size + 1]\n",
    "            self.VOCAB_SIZE = self.tokenizer.vocab_size + 2\n",
    "            \n",
    "            logger.info(f\"토크나이저 로드 완료 (어휘 크기: {self.VOCAB_SIZE})\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"토크나이저 로드 실패: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def encode(self, text, add_special_tokens=True):\n",
    "        \"\"\"텍스트 인코딩\"\"\"\n",
    "        if not self.tokenizer:\n",
    "            logger.warning(\"토크나이저가 초기화되지 않았습니다.\")\n",
    "            return []\n",
    "        \n",
    "        if not text:\n",
    "            return self.START_TOKEN + self.END_TOKEN if add_special_tokens else []\n",
    "        \n",
    "        # 형태소 분석 적용 여부\n",
    "        if self.use_morphemes and self.morpheme_analyzer:\n",
    "            morphemes = self.tokenize_morphemes(text)\n",
    "            text = ' '.join(morphemes)\n",
    "        \n",
    "        # 인코딩\n",
    "        encoded = self.tokenizer.encode(text)\n",
    "        \n",
    "        # 특수 토큰 추가\n",
    "        if add_special_tokens:\n",
    "            encoded = self.START_TOKEN + encoded + self.END_TOKEN\n",
    "        \n",
    "        return encoded\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        \"\"\"토큰 디코딩\"\"\"\n",
    "        if not self.tokenizer:\n",
    "            logger.warning(\"토크나이저가 초기화되지 않았습니다.\")\n",
    "            return \"\"\n",
    "        \n",
    "        # 특수 토큰 제거 (시작/종료 토큰)\n",
    "        if tokens and tokens[0] == self.START_TOKEN[0]:\n",
    "            tokens = tokens[1:]\n",
    "        if tokens and tokens[-1] == self.END_TOKEN[0]:\n",
    "            tokens = tokens[:-1]\n",
    "        \n",
    "        # 디코딩\n",
    "        try:\n",
    "            return self.tokenizer.decode(tokens)\n",
    "        except:\n",
    "            return \"\"\n",
    "    \n",
    "    def tokenize_and_filter(self, inputs, outputs, max_length=50):\n",
    "        \"\"\"토큰화 및 필터링\"\"\"\n",
    "        if not self.tokenizer:\n",
    "            logger.warning(\"토크나이저가 초기화되지 않았습니다.\")\n",
    "            return [], []\n",
    "        \n",
    "        tokenized_inputs, tokenized_outputs = [], []\n",
    "        \n",
    "        for (sentence1, sentence2) in tqdm(zip(inputs, outputs), total=len(inputs), desc=\"토큰화 및 필터링\"):\n",
    "            # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "            sentence1_tokens = self.encode(sentence1)\n",
    "            sentence2_tokens = self.encode(sentence2)\n",
    "            \n",
    "            # 최대 길이 이하인 경우에만 데이터셋으로 허용\n",
    "            if len(sentence1_tokens) <= max_length and len(sentence2_tokens) <= max_length:\n",
    "                tokenized_inputs.append(sentence1_tokens)\n",
    "                tokenized_outputs.append(sentence2_tokens)\n",
    "        \n",
    "        # 최대 길이로 모든 데이터셋을 패딩\n",
    "        tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            tokenized_inputs, maxlen=max_length, padding='post')\n",
    "        tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            tokenized_outputs, maxlen=max_length, padding='post')\n",
    "        \n",
    "        return tokenized_inputs, tokenized_outputs\n",
    "    \n",
    "    def get_vocab_info(self):\n",
    "        \"\"\"어휘 정보 반환\"\"\"\n",
    "        if not self.tokenizer:\n",
    "            logger.warning(\"토크나이저가 초기화되지 않았습니다.\")\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            'vocab_size': self.VOCAB_SIZE,\n",
    "            'start_token': self.START_TOKEN,\n",
    "            'end_token': self.END_TOKEN,\n",
    "            'subword_vocab_size': self.tokenizer.vocab_size\n",
    "        }\n",
    "\n",
    "# 한국어 토큰화 클래스 초기화\n",
    "korean_tokenizer = KoreanTokenizer(vocab_size=2**14, use_morphemes=True)\n",
    "\n",
    "# 토크나이저 구축\n",
    "tokenizer = korean_tokenizer.build_tokenizer(questions_augmented + answers_augmented)\n",
    "\n",
    "# 토크나이저 정보 출력\n",
    "vocab_info = korean_tokenizer.get_vocab_info()\n",
    "print(\"\\n토크나이저 정보:\")\n",
    "print(f\"단어장의 크기: {vocab_info['vocab_size']}\")\n",
    "print(f\"START_TOKEN의 번호: {vocab_info['start_token']}\")\n",
    "print(f\"END_TOKEN의 번호: {vocab_info['end_token']}\")\n",
    "\n",
    "# 토크나이저 테스트\n",
    "sample_string = questions_augmented[0]\n",
    "tokenized_string = korean_tokenizer.encode(sample_string)\n",
    "print('\\n토크나이저 테스트:')\n",
    "print(f'원문: {sample_string}')\n",
    "print(f'토큰화: {tokenized_string}')\n",
    "print(f'디코딩 결과: {korean_tokenizer.decode(tokenized_string)}')\n",
    "\n",
    "# 토크나이저 저장\n",
    "korean_tokenizer.save_tokenizer(os.path.join(data_dir, 'korean_tokenizer.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236286c",
   "metadata": {},
   "source": [
    "### 2-6 데이터셋 준비 및 토큰화 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "362a8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetPreparation:\n",
    "    \"\"\"데이터셋 준비 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenizer, max_length=50, batch_size=64, buffer_size=20000):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        logger.info(f\"데이터셋 준비 클래스 초기화 완료 (최대 길이: {max_length}, 배치 크기: {batch_size})\")\n",
    "    \n",
    "    def tokenize_and_filter(self, inputs, outputs):\n",
    "        \"\"\"토큰화 및 필터링\"\"\"\n",
    "        tokenized_inputs, tokenized_outputs = [], []\n",
    "        \n",
    "        for (sentence1, sentence2) in tqdm(zip(inputs, outputs), total=len(inputs), desc=\"토큰화 및 필터링\"):\n",
    "            # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "            sentence1_tokens = self.tokenizer.encode(sentence1)\n",
    "            sentence2_tokens = self.tokenizer.encode(sentence2)\n",
    "            \n",
    "            # 최대 길이 이하인 경우에만 데이터셋으로 허용\n",
    "            if len(sentence1_tokens) <= self.max_length and len(sentence2_tokens) <= self.max_length:\n",
    "                tokenized_inputs.append(sentence1_tokens)\n",
    "                tokenized_outputs.append(sentence2_tokens)\n",
    "        \n",
    "        # 최대 길이로 모든 데이터셋을 패딩\n",
    "        tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            tokenized_inputs, maxlen=self.max_length, padding='post')\n",
    "        tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            tokenized_outputs, maxlen=self.max_length, padding='post')\n",
    "        \n",
    "        return tokenized_inputs, tokenized_outputs\n",
    "    \n",
    "    def create_dataset(self, inputs, outputs, train_size=0.8):\n",
    "        \"\"\"데이터셋 생성\"\"\"\n",
    "        # 토큰화 및 필터링\n",
    "        logger.info(\"토큰화 및 필터링 진행 중...\")\n",
    "        tokenized_inputs, tokenized_outputs = self.tokenize_and_filter(inputs, outputs)\n",
    "        \n",
    "        # 데이터셋 크기 출력\n",
    "        logger.info(f\"필터링 후의 질문 샘플 개수: {len(tokenized_inputs)}\")\n",
    "        logger.info(f\"필터링 후의 답변 샘플 개수: {len(tokenized_outputs)}\")\n",
    "        \n",
    "        # 토큰화된 데이터 저장\n",
    "        np.save(os.path.join(data_dir, 'questions_tokenized.npy'), tokenized_inputs)\n",
    "        np.save(os.path.join(data_dir, 'answers_tokenized.npy'), tokenized_outputs)\n",
    "        logger.info(\"토큰화된 데이터 저장 완료\")\n",
    "        \n",
    "        # 학습/검증 데이터 분할\n",
    "        logger.info(\"학습/검증 데이터 분할 중...\")\n",
    "        indices = np.arange(len(tokenized_inputs))\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        num_train = int(len(indices) * train_size)\n",
    "        train_indices = indices[:num_train]\n",
    "        val_indices = indices[num_train:]\n",
    "        \n",
    "        train_inputs = tokenized_inputs[train_indices]\n",
    "        train_outputs = tokenized_outputs[train_indices]\n",
    "        val_inputs = tokenized_inputs[val_indices]\n",
    "        val_outputs = tokenized_outputs[val_indices]\n",
    "        \n",
    "        logger.info(f\"학습 데이터 크기: {len(train_inputs)}\")\n",
    "        logger.info(f\"검증 데이터 크기: {len(val_inputs)}\")\n",
    "        \n",
    "        # 디코더 입력 생성 (시작 토큰 추가)\n",
    "        logger.info(\"디코더 입력 생성 중...\")\n",
    "        vocab_info = self.tokenizer.get_vocab_info()\n",
    "        start_token = vocab_info['start_token'][0]\n",
    "        \n",
    "        train_decoder_inputs = np.zeros_like(train_outputs)\n",
    "        train_decoder_inputs[:, 1:] = train_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63df9803",
   "metadata": {},
   "source": [
    "## Step 3. 모델 아키텍처 개선\n",
    "\n",
    "- 트랜스포머 기반 모델에 포지셔널 인코딩, 멀티헤드 어텐션, 게이트 메커니즘, 맥락 메모리 네트워크 적용\n",
    "- 사용자 정의 레이어의 직렬화 문제(get_config) 해결 (모델 저장·재사용이 가능하도록)\n",
    "- 결과: 약 6000만 개 이상의 파라미터를 가진 트랜스포머 모델 빌드 및 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324c75b",
   "metadata": {},
   "source": [
    "### 3-1 필요 라이브러리 임포트 및 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d59f508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 버전: 2.6.0\n",
      "GPU 사용 가능 여부: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"chatbot_architecture.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "print(\"TensorFlow 버전:\", tf.__version__)\n",
    "print(\"GPU 사용 가능 여부:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# 데이터 디렉토리 설정\n",
    "data_dir = \"chatbot_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# 모델 저장 디렉토리 설정\n",
    "model_dir = \"chatbot_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# 랜덤 시드 설정\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 모델 하이퍼파라미터 설정\n",
    "MAX_LENGTH = 50\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314610d",
   "metadata": {},
   "source": [
    "### 3-2 토큰화된 데이터 로드 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb720d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 02:49:36,940 - __main__ - INFO - 토크나이저 로드 중...\n",
      "2025-04-21 02:49:36,966 - __main__ - INFO - 토크나이저 로드 완료\n",
      "2025-04-21 02:49:36,969 - __main__ - INFO - 어휘 크기: 12658\n",
      "2025-04-21 02:49:36,970 - __main__ - INFO - ===== 토큰화된 데이터 처리 시작 =====\n",
      "2025-04-21 02:49:36,970 - __main__ - INFO - 기존 토큰화 데이터 로드 시도\n",
      "2025-04-21 02:49:36,976 - __main__ - INFO - 토큰화 데이터 로드 성공: 질문 (23524, 50), 답변 (23524, 50)\n",
      "2025-04-21 02:49:36,976 - __main__ - INFO - 데이터셋 준비 중...\n",
      "2025-04-21 02:49:36,985 - __main__ - INFO - 학습 데이터: 질문 18819개, 답변 18819개\n",
      "2025-04-21 02:49:36,985 - __main__ - INFO - 검증 데이터: 질문 4705개, 답변 4705개\n",
      "2025-04-21 02:49:37,070 - __main__ - INFO - 토크나이저 로드 중...\n",
      "2025-04-21 02:49:37,131 - __main__ - INFO - 토크나이저 로드 완료\n",
      "2025-04-21 02:49:37,191 - __main__ - INFO - 토크나이저 로드 중...\n",
      "2025-04-21 02:49:37,246 - __main__ - INFO - 토크나이저 로드 완료\n",
      "2025-04-21 02:49:37,285 - __main__ - INFO - 데이터셋 준비 완료\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더 입력 크기: (64, 50)\n",
      "디코더 입력 크기: (64, 50)\n",
      "타겟 크기: (64, 50)\n"
     ]
    }
   ],
   "source": [
    "def load_tokenizer():\n",
    "    \"\"\"토크나이저 로드\"\"\"\n",
    "    logger.info(\"토크나이저 로드 중...\")\n",
    "    \n",
    "    # 토크나이저 파일 경로\n",
    "    tokenizer_path = os.path.join(data_dir, 'korean_tokenizer.pkl')\n",
    "    \n",
    "    # 파일 존재 여부 확인\n",
    "    if os.path.exists(tokenizer_path):\n",
    "        with open(tokenizer_path, 'rb') as f:\n",
    "            tokenizer = pickle.load(f)\n",
    "        logger.info(\"토크나이저 로드 완료\")\n",
    "        return tokenizer\n",
    "    else:\n",
    "        logger.error(f\"토크나이저 파일을 찾을 수 없습니다: {tokenizer_path}\")\n",
    "        return None\n",
    "\n",
    "def load_or_create_tokenized_data():\n",
    "    \"\"\"토큰화된 데이터 로드 또는 생성\"\"\"\n",
    "    logger.info(\"===== 토큰화된 데이터 처리 시작 =====\")\n",
    "    \n",
    "    # 파일 경로 설정\n",
    "    questions_path = os.path.join(data_dir, 'questions_tokenized.npy')\n",
    "    answers_path = os.path.join(data_dir, 'answers_tokenized.npy')\n",
    "    augmented_data_path = os.path.join(data_dir, 'augmented_data.csv')\n",
    "\n",
    "    # 1. 기존 토큰화 데이터 확인\n",
    "    if os.path.exists(questions_path) and os.path.exists(answers_path):\n",
    "        logger.info(\"기존 토큰화 데이터 로드 시도\")\n",
    "        try:\n",
    "            questions = np.load(questions_path)\n",
    "            answers = np.load(answers_path)\n",
    "            logger.info(f\"토큰화 데이터 로드 성공: 질문 {questions.shape}, 답변 {answers.shape}\")\n",
    "            return questions, answers\n",
    "        except Exception as e:\n",
    "            logger.error(f\"토큰화 데이터 로드 실패: {e}\")\n",
    "            # 손상된 파일이면 삭제\n",
    "            if os.path.exists(questions_path):\n",
    "                os.remove(questions_path)\n",
    "            if os.path.exists(answers_path):\n",
    "                os.remove(answers_path)\n",
    "\n",
    "    # 2. 증강 데이터에서 새로 생성\n",
    "    logger.info(\"새로운 토큰화 데이터 생성 시작\")\n",
    "    \n",
    "    # 증강 데이터 로드\n",
    "    if not os.path.exists(augmented_data_path):\n",
    "        logger.error(\"증강 데이터 파일 없음: augmented_data.csv\")\n",
    "        return None, None\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(augmented_data_path)\n",
    "        logger.info(f\"증강 데이터 로드 완료: {len(df)}개\")\n",
    "        \n",
    "        # 토크나이저 로드\n",
    "        tokenizer = load_tokenizer()\n",
    "        if not tokenizer:\n",
    "            logger.error(\"토크나이저 로드 실패\")\n",
    "            return None, None\n",
    "\n",
    "        # 토큰화 파라미터\n",
    "        MAX_LENGTH = 50  # 최대 문장 길이 설정\n",
    "        START_TOKEN = [tokenizer.vocab_size]\n",
    "        END_TOKEN = [tokenizer.vocab_size + 1]\n",
    "\n",
    "        # 토큰화 처리 함수\n",
    "        def tokenize_text(text):\n",
    "            if not isinstance(text, str):\n",
    "                text = str(text)\n",
    "            tokens = START_TOKEN + tokenizer.encode(text) + END_TOKEN\n",
    "            # 최대 길이 제한 및 패딩 적용\n",
    "            if len(tokens) > MAX_LENGTH:\n",
    "                tokens = tokens[:MAX_LENGTH]\n",
    "            else:\n",
    "                tokens = tokens + [0] * (MAX_LENGTH - len(tokens))\n",
    "            return tokens\n",
    "\n",
    "        # 병렬 처리로 토큰화 속도 향상\n",
    "        logger.info(\"질문 및 답변 토큰화 중...\")\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            questions = list(executor.map(tokenize_text, tqdm(df['Q'], desc=\"질문 토큰화\")))\n",
    "            answers = list(executor.map(tokenize_text, tqdm(df['A'], desc=\"답변 토큰화\")))\n",
    "\n",
    "        # 배열 변환\n",
    "        questions = np.array(questions, dtype=np.int32)\n",
    "        answers = np.array(answers, dtype=np.int32)\n",
    "\n",
    "        # 저장\n",
    "        np.save(questions_path, questions)\n",
    "        np.save(answers_path, answers)\n",
    "        logger.info(f\"토큰화 데이터 저장 완료: {questions_path}, {answers_path}\")\n",
    "\n",
    "        return questions, answers\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"토큰화 데이터 생성 실패: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def prepare_dataset(questions, answers, batch_size=64, buffer_size=20000):\n",
    "    \"\"\"데이터셋 준비\"\"\"\n",
    "    logger.info(\"데이터셋 준비 중...\")\n",
    "    \n",
    "    # 전역 변수 설정\n",
    "    SEED = 42\n",
    "    \n",
    "    # 학습/검증 데이터 분할 (8:2)\n",
    "    train_questions, val_questions, train_answers, val_answers = train_test_split(\n",
    "        questions, answers, test_size=0.2, random_state=SEED)\n",
    "    \n",
    "    logger.info(f\"학습 데이터: 질문 {len(train_questions)}개, 답변 {len(train_answers)}개\")\n",
    "    logger.info(f\"검증 데이터: 질문 {len(val_questions)}개, 답변 {len(val_answers)}개\")\n",
    "    \n",
    "    # 디코더 입력 생성 함수 (수정된 버전)\n",
    "    def create_decoder_input(x, y):\n",
    "        \"\"\"배치 단위로 디코더 입력 생성\"\"\"\n",
    "        # 토크나이저 로드\n",
    "        tokenizer = load_tokenizer()\n",
    "        start_token = tokenizer.vocab_size\n",
    "        \n",
    "        # 배치 크기 가져오기\n",
    "        batch_size = tf.shape(y)[0]\n",
    "        \n",
    "        # 시작 토큰 생성 (배치 크기에 맞게)\n",
    "        start_tokens = tf.fill([batch_size, 1], start_token)\n",
    "        \n",
    "        # 디코더 입력 생성 (시작 토큰 + 타겟의 처음부터 마지막-1까지)\n",
    "        decoder_input = tf.concat([start_tokens, y[:, :-1]], axis=1)\n",
    "        \n",
    "        return x, decoder_input, y\n",
    "    \n",
    "    # 학습 데이터셋 생성\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_questions, train_answers))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.map(create_decoder_input)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    # 검증 데이터셋 생성\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_questions, val_answers))\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.map(create_decoder_input)\n",
    "    \n",
    "    logger.info(\"데이터셋 준비 완료\")\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = load_tokenizer()\n",
    "\n",
    "# 어휘 크기 설정\n",
    "if tokenizer:\n",
    "    VOCAB_SIZE = tokenizer.vocab_size + 2  # START_TOKEN과 END_TOKEN 추가\n",
    "    logger.info(f\"어휘 크기: {VOCAB_SIZE}\")\n",
    "else:\n",
    "    logger.error(\"토크나이저 로드 실패. 프로그램을 종료합니다.\")\n",
    "    exit(1)\n",
    "\n",
    "# 토큰화된 데이터 로드 또는 생성\n",
    "questions, answers = load_or_create_tokenized_data()\n",
    "\n",
    "# 데이터셋 준비\n",
    "if questions is not None and answers is not None:\n",
    "    # 전역 변수 설정\n",
    "    BATCH_SIZE = 64\n",
    "    BUFFER_SIZE = 20000\n",
    "    \n",
    "    train_dataset, val_dataset = prepare_dataset(questions, answers, batch_size=BATCH_SIZE, buffer_size=BUFFER_SIZE)\n",
    "    \n",
    "    # 데이터셋 샘플 확인\n",
    "    for encoder_input, decoder_input, target in train_dataset.take(1):\n",
    "        print(f\"인코더 입력 크기: {encoder_input.shape}\")\n",
    "        print(f\"디코더 입력 크기: {decoder_input.shape}\")\n",
    "        print(f\"타겟 크기: {target.shape}\")\n",
    "else:\n",
    "    logger.error(\"토큰화된 데이터 로드 또는 생성 실패. 프로그램을 종료합니다.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb97be82",
   "metadata": {},
   "source": [
    "### 3-3 포지셔널 인코딩 및 어텐션 메커니즘 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a957e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding, [1, 2, 0])\n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# 스케일드 닷 프로덕트 어텐션 함수 (개선: 어텐션 가중치 반환)\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output, attention_weights\n",
    "\n",
    "# 멀티헤드 어텐션 레이어 (개선: 어텐션 가중치 저장 기능 추가)\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "        # 어텐션 가중치 저장을 위한 속성 추가\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            query, key, value, mask)\n",
    "        \n",
    "        # 어텐션 가중치 저장\n",
    "        self.attention_weights = attention_weights\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                    (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# 패딩 마스크 생성 함수\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# 룩어헤드 마스크 생성 함수\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac311942",
   "metadata": {},
   "source": [
    "### 3-4 인코더 및 디코더 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecd53ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개선된 인코더 레이어 (드롭아웃 비율 조정 가능)\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 개선된 인코더 (임베딩 레이어 분리)\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 개선된 디코더 레이어\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "\n",
    "# 개선된 디코더\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5edb08",
   "metadata": {},
   "source": [
    "### 3-5 개선된 트랜스포머 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e2449a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개선된 트랜스포머 모델 (출력층 앞에 추가 레이어)\n",
    "def improved_transformer(vocab_size,\n",
    "                        num_layers,\n",
    "                        units,\n",
    "                        d_model,\n",
    "                        num_heads,\n",
    "                        dropout,\n",
    "                        name=\"improved_transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 출력층 앞에 추가 레이어 (성능 향상)\n",
    "    dec_outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(dec_outputs)\n",
    "    dec_outputs = tf.keras.layers.Dropout(rate=dropout)(dec_outputs)\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f6dce",
   "metadata": {},
   "source": [
    "### 3-6 한국어에 최적화된 모델 아키텍처 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9756a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 특화 인코더 레이어 (추가된 게이트 메커니즘)\n",
    "def korean_encoder_layer(units, d_model, num_heads, dropout, name=\"korean_encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "    \n",
    "    # 어텐션 드롭아웃\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    \n",
    "    # 게이트 메커니즘 (한국어 문법 구조를 더 잘 학습하기 위함)\n",
    "    gate = tf.keras.layers.Dense(units=d_model, activation='sigmoid')(inputs)\n",
    "    gated_attention = gate * attention\n",
    "    \n",
    "    # 잔차 연결 및 정규화\n",
    "    attention_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + gated_attention)\n",
    "\n",
    "    # 피드 포워드 네트워크\n",
    "    ffn1 = tf.keras.layers.Dense(units=units, activation='relu')(attention_norm)\n",
    "    ffn2 = tf.keras.layers.Dense(units=d_model)(ffn1)\n",
    "    ffn_dropout = tf.keras.layers.Dropout(rate=dropout)(ffn2)\n",
    "    \n",
    "    # 잔차 연결 및 정규화\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention_norm + ffn_dropout)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 한국어 특화 디코더 레이어 (향상된 어텐션 메커니즘)\n",
    "def korean_decoder_layer(units, d_model, num_heads, dropout, name=\"korean_decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "    \n",
    "    # 잔차 연결 및 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 멀티 헤드 어텐션 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "    \n",
    "    # 드롭아웃 및 잔차 연결\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    \n",
    "    # 게이트 메커니즘 (한국어 문맥 이해 향상)\n",
    "    gate = tf.keras.layers.Dense(units=d_model, activation='sigmoid')(attention1)\n",
    "    gated_attention = gate * attention2\n",
    "    \n",
    "    # 잔차 연결 및 정규화\n",
    "    attention2_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + gated_attention)\n",
    "\n",
    "    # 피드 포워드 네트워크\n",
    "    ffn1 = tf.keras.layers.Dense(units=units, activation='relu')(attention2_norm)\n",
    "    ffn2 = tf.keras.layers.Dense(units=d_model)(ffn1)\n",
    "    ffn_dropout = tf.keras.layers.Dropout(rate=dropout)(ffn2)\n",
    "    \n",
    "    # 잔차 연결 및 정규화\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2_norm + ffn_dropout)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "\n",
    "# 한국어 특화 인코더\n",
    "def korean_encoder(vocab_size,\n",
    "                  num_layers,\n",
    "                  units,\n",
    "                  d_model,\n",
    "                  num_heads,\n",
    "                  dropout,\n",
    "                  name=\"korean_encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    \n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더 레이어 스택\n",
    "    for i in range(num_layers):\n",
    "        outputs = korean_encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=f\"korean_encoder_layer_{i}\",\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 한국어 특화 디코더\n",
    "def korean_decoder(vocab_size,\n",
    "                  num_layers,\n",
    "                  units,\n",
    "                  d_model,\n",
    "                  num_heads,\n",
    "                  dropout,\n",
    "                  name=\"korean_decoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    \n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더 레이어 스택\n",
    "    for i in range(num_layers):\n",
    "        outputs = korean_decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=f\"korean_decoder_layer_{i}\",\n",
    "        )([outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "\n",
    "# 한국어 특화 트랜스포머 모델\n",
    "def korean_transformer(vocab_size,\n",
    "                      num_layers,\n",
    "                      units,\n",
    "                      d_model,\n",
    "                      num_heads,\n",
    "                      dropout,\n",
    "                      name=\"korean_transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 마스크 생성\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name=\"enc_padding_mask\")(inputs)\n",
    "    \n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name=\"look_ahead_mask\")(dec_inputs)\n",
    "    \n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name=\"dec_padding_mask\")(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = korean_encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )([inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = korean_decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )([dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 추가 레이어 (성능 향상)\n",
    "    dec_outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(dec_outputs)\n",
    "    dec_outputs = tf.keras.layers.Dropout(rate=dropout)(dec_outputs)\n",
    "    \n",
    "    # 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b722e",
   "metadata": {},
   "source": [
    "### 3-7 맥락 인식 강화를 위한 메모리 네트워크 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "101e53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맥락 메모리 네트워크 레이어\n",
    "class ContextMemoryNetwork(tf.keras.layers.Layer):\n",
    "    def __init__(self, memory_size, d_model, name=\"context_memory_network\"):\n",
    "        super(ContextMemoryNetwork, self).__init__(name=name)\n",
    "        self.memory_size = memory_size\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # 메모리 초기화 (학습 가능한 파라미터)\n",
    "        self.memory = self.add_weight(\n",
    "            name=\"memory\",\n",
    "            shape=(memory_size, d_model),\n",
    "            initializer=tf.keras.initializers.GlorotUniform(),\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        # 메모리 어텐션을 위한 레이어\n",
    "        self.query_dense = tf.keras.layers.Dense(d_model)\n",
    "        self.attention = tf.keras.layers.Attention()\n",
    "        self.output_dense = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        \n",
    "        # 입력을 메모리 키와 유사도 계산을 위한 쿼리로 변환\n",
    "        query = self.query_dense(inputs)\n",
    "        \n",
    "        # 메모리를 배치 크기에 맞게 확장\n",
    "        memory_batch = tf.tile(tf.expand_dims(self.memory, 0), [batch_size, 1, 1])\n",
    "        \n",
    "        # 메모리에 대한 어텐션 계산\n",
    "        memory_context = self.attention([query, memory_batch])\n",
    "        \n",
    "        # 원본 입력과 메모리 컨텍스트 결합\n",
    "        enhanced_output = tf.concat([inputs, memory_context], axis=-1)\n",
    "        outputs = self.output_dense(enhanced_output)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# 맥락 인식 강화 인코더 레이어\n",
    "def context_aware_encoder_layer(units, d_model, num_heads, dropout, memory_size=64, name=\"context_aware_encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "    \n",
    "    # 어텐션 드롭아웃 및 잔차 연결\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "    \n",
    "    # 맥락 메모리 네트워크 적용\n",
    "    context_memory = ContextMemoryNetwork(memory_size=memory_size, d_model=d_model)(attention)\n",
    "    context_memory = tf.keras.layers.Dropout(rate=dropout)(context_memory)\n",
    "    context_enhanced = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + context_memory)\n",
    "    \n",
    "    # 피드 포워드 네트워크\n",
    "    ffn1 = tf.keras.layers.Dense(units=units, activation='relu')(context_enhanced)\n",
    "    ffn2 = tf.keras.layers.Dense(units=d_model)(ffn1)\n",
    "    ffn_dropout = tf.keras.layers.Dropout(rate=dropout)(ffn2)\n",
    "    \n",
    "    # 잔차 연결 및 정규화\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(context_enhanced + ffn_dropout)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 맥락 인식 강화 인코더\n",
    "def context_aware_encoder(vocab_size,\n",
    "                         num_layers,\n",
    "                         units,\n",
    "                         d_model,\n",
    "                         num_heads,\n",
    "                         dropout,\n",
    "                         memory_size=64,\n",
    "                         name=\"context_aware_encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    \n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더 레이어 스택\n",
    "    for i in range(num_layers):\n",
    "        outputs = context_aware_encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            memory_size=memory_size,\n",
    "            name=f\"context_aware_encoder_layer_{i}\",\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 맥락 인식 강화 트랜스포머 모델\n",
    "def context_aware_transformer(vocab_size,\n",
    "                             num_layers,\n",
    "                             units,\n",
    "                             d_model,\n",
    "                             num_heads,\n",
    "                             dropout,\n",
    "                             memory_size=64,\n",
    "                             name=\"context_aware_transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 마스크 생성\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name=\"enc_padding_mask\")(inputs)\n",
    "    \n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name=\"look_ahead_mask\")(dec_inputs)\n",
    "    \n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name=\"dec_padding_mask\")(inputs)\n",
    "\n",
    "    # 맥락 인식 강화 인코더\n",
    "    enc_outputs = context_aware_encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        memory_size=memory_size,\n",
    "    )([inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더 (기본 한국어 특화 디코더 사용)\n",
    "    dec_outputs = korean_decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )([dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 추가 레이어 (성능 향상)\n",
    "    dec_outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(dec_outputs)\n",
    "    dec_outputs = tf.keras.layers.Dropout(rate=dropout)(dec_outputs)\n",
    "    \n",
    "    # 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a479e41",
   "metadata": {},
   "source": [
    "### 3-8 모델 구성 및 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5fa3246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:05:09,663 - __main__ - INFO - 모델 구성 중 (타입: context_aware)...\n",
      "2025-04-21 03:05:16,984 - __main__ - INFO - context_aware 모델 구성 완료\n",
      "2025-04-21 03:05:16,985 - __main__ - INFO - 모델 컴파일 중...\n",
      "2025-04-21 03:05:16,993 - __main__ - INFO - 모델 컴파일 완료\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"context_aware_transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "context_aware_encoder (Function (None, None, 512)    30322688    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "korean_decoder (Functional)     (None, None, 512)    33281024    dec_inputs[0][0]                 \n",
      "                                                                 context_aware_encoder[0][0]      \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_110 (LayerN (None, None, 512)    1024        korean_decoder[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, None, 512)    0           layer_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 12658)  6493554     dropout_98[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 70,098,290\n",
      "Trainable params: 70,098,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "총 파라미터 수: 70,098,290\n",
      "학습 가능 파라미터 수: 70,098,290\n",
      "학습 불가능 파라미터 수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:05:26,258 - __main__ - INFO - 모델 저장 시작...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 구조 이미지가 chatbot_models/model_architecture.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:05:27,416 - __main__ - INFO - 모델 가중치 저장 완료 (TF 체크포인트): chatbot_models/model_checkpoint\n",
      "2025-04-21 03:05:27,418 - __main__ - INFO - 모델 구성 저장 완료: chatbot_models/model_config.json\n",
      "2025-04-21 03:06:32,739 - absl - WARNING - Found untraced functions such as dense_228_layer_call_and_return_conditional_losses, dense_228_layer_call_fn, dense_229_layer_call_and_return_conditional_losses, dense_229_layer_call_fn, dense_230_layer_call_and_return_conditional_losses while saving (showing 5 of 450). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: chatbot_models/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:06:41,419 - tensorflow - INFO - Assets written to: chatbot_models/saved_model/assets\n",
      "2025-04-21 03:06:43,690 - __main__ - INFO - SavedModel 저장 완료: chatbot_models/saved_model\n",
      "2025-04-21 03:06:43,693 - __main__ - INFO - 모델 저장 프로세스 완료\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 하이퍼파라미터 설정\n",
    "def get_model_config():\n",
    "    config = {\n",
    "        # 기본 모델 파라미터\n",
    "        'vocab_size': VOCAB_SIZE,\n",
    "        'num_layers': 6,           # 인코더/디코더 레이어 수\n",
    "        'units': 2048,             # 피드 포워드 네트워크 유닛 수\n",
    "        'd_model': 512,            # 임베딩 차원\n",
    "        'num_heads': 8,            # 멀티 헤드 어텐션 헤드 수\n",
    "        'dropout': 0.1,            # 드롭아웃 비율\n",
    "        \n",
    "        # 맥락 인식 모델 추가 파라미터\n",
    "        'memory_size': 64,         # 맥락 메모리 크기\n",
    "        \n",
    "        # 학습 관련 파라미터\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'max_epochs': 100,\n",
    "        'early_stopping_patience': 5,\n",
    "        'learning_rate': 0.0001,\n",
    "        'beta_1': 0.9,\n",
    "        'beta_2': 0.98,\n",
    "        'epsilon': 1e-9,\n",
    "        'warmup_steps': 4000,\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "# 학습률 스케줄러\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'd_model': float(self.d_model.numpy()) if hasattr(self.d_model, 'numpy') else float(self.d_model),\n",
    "            'warmup_steps': self.warmup_steps\n",
    "        }\n",
    "\n",
    "# 모델 구성 함수\n",
    "def create_model(config, model_type='context_aware'):\n",
    "    logger.info(f\"모델 구성 중 (타입: {model_type})...\")\n",
    "    \n",
    "    if model_type == 'basic':\n",
    "        # 기본 트랜스포머 모델\n",
    "        model = improved_transformer(\n",
    "            vocab_size=config['vocab_size'],\n",
    "            num_layers=config['num_layers'],\n",
    "            units=config['units'],\n",
    "            d_model=config['d_model'],\n",
    "            num_heads=config['num_heads'],\n",
    "            dropout=config['dropout'],\n",
    "        )\n",
    "    elif model_type == 'korean':\n",
    "        # 한국어 특화 트랜스포머 모델\n",
    "        model = korean_transformer(\n",
    "            vocab_size=config['vocab_size'],\n",
    "            num_layers=config['num_layers'],\n",
    "            units=config['units'],\n",
    "            d_model=config['d_model'],\n",
    "            num_heads=config['num_heads'],\n",
    "            dropout=config['dropout'],\n",
    "        )\n",
    "    elif model_type == 'context_aware':\n",
    "        # 맥락 인식 강화 트랜스포머 모델\n",
    "        model = context_aware_transformer(\n",
    "            vocab_size=config['vocab_size'],\n",
    "            num_layers=config['num_layers'],\n",
    "            units=config['units'],\n",
    "            d_model=config['d_model'],\n",
    "            num_heads=config['num_heads'],\n",
    "            dropout=config['dropout'],\n",
    "            memory_size=config['memory_size'],\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"지원하지 않는 모델 타입: {model_type}\")\n",
    "    \n",
    "    logger.info(f\"{model_type} 모델 구성 완료\")\n",
    "    return model\n",
    "\n",
    "# 모델 컴파일\n",
    "def compile_model(model, config):\n",
    "    logger.info(\"모델 컴파일 중...\")\n",
    "    \n",
    "    # 학습률 스케줄러\n",
    "    learning_rate = CustomSchedule(config['d_model'], warmup_steps=config['warmup_steps'])\n",
    "    \n",
    "    # 옵티마이저\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=learning_rate,\n",
    "        beta_1=config['beta_1'],\n",
    "        beta_2=config['beta_2'],\n",
    "        epsilon=config['epsilon']\n",
    "    )\n",
    "    \n",
    "    # 손실 함수 (패딩 마스킹)\n",
    "    def masked_loss(y_true, y_pred):\n",
    "        mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
    "        loss_ = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "        \n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "        \n",
    "        return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
    "    \n",
    "    # 정확도 메트릭 (패딩 마스킹)\n",
    "    def masked_accuracy(y_true, y_pred):\n",
    "        mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "        \n",
    "        match = tf.cast(tf.equal(y_true, y_pred), tf.float32)\n",
    "        mask = tf.cast(mask, dtype=match.dtype)\n",
    "        \n",
    "        return tf.reduce_sum(match * mask) / tf.reduce_sum(mask)\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=masked_loss,\n",
    "        metrics=[masked_accuracy]\n",
    "    )\n",
    "    \n",
    "    logger.info(\"모델 컴파일 완료\")\n",
    "    return model\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "def print_model_summary(model):\n",
    "    # 모델 구조 요약\n",
    "    model.summary()\n",
    "    \n",
    "    # 모델 파라미터 수 계산\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "    non_trainable_params = total_params - trainable_params\n",
    "    \n",
    "    print(f\"\\n총 파라미터 수: {total_params:,}\")\n",
    "    print(f\"학습 가능 파라미터 수: {trainable_params:,}\")\n",
    "    print(f\"학습 불가능 파라미터 수: {non_trainable_params:,}\")\n",
    "    \n",
    "    # 모델 구조 시각화 (옵션)\n",
    "    try:\n",
    "        tf.keras.utils.plot_model(\n",
    "            model,\n",
    "            to_file=os.path.join(model_dir, 'model_architecture.png'),\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "            expand_nested=True\n",
    "        )\n",
    "        print(f\"모델 구조 이미지가 {os.path.join(model_dir, 'model_architecture.png')}에 저장되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"모델 구조 시각화 실패: {e}\")\n",
    "\n",
    "# 모델 저장 함수 (개선)\n",
    "def save_model_safely(model, config, model_dir):\n",
    "    \"\"\"안전하게 모델을 저장하는 함수\"\"\"\n",
    "    logger.info(\"모델 저장 시작...\")\n",
    "    \n",
    "    # 1. 모델 가중치 저장 (TensorFlow 체크포인트 형식)\n",
    "    checkpoint_path = os.path.join(model_dir, 'model_checkpoint')\n",
    "    try:\n",
    "        model.save_weights(checkpoint_path, save_format='tf')\n",
    "        logger.info(f\"모델 가중치 저장 완료 (TF 체크포인트): {checkpoint_path}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"TF 체크포인트 저장 실패: {e}\")\n",
    "        \n",
    "        # 대체 저장 방법 시도 - 새 파일명으로 HDF5 형식 저장\n",
    "        try:\n",
    "            unique_filename = f\"model_weights_{int(time.time())}.h5\"\n",
    "            weights_path = os.path.join(model_dir, unique_filename)\n",
    "            model.save_weights(weights_path)\n",
    "            logger.info(f\"모델 가중치 저장 완료 (HDF5): {weights_path}\")\n",
    "        except Exception as e2:\n",
    "            logger.error(f\"모델 가중치 저장 완전 실패: {e2}\")\n",
    "    \n",
    "    # 2. 모델 구성 저장 (JSON)\n",
    "    try:\n",
    "        # 직렬화 가능한 형태로 변환\n",
    "        serializable_config = {}\n",
    "        for k, v in config.items():\n",
    "            if isinstance(v, tf.Tensor):\n",
    "                serializable_config[k] = float(v.numpy())\n",
    "            elif hasattr(v, 'numpy'):\n",
    "                serializable_config[k] = float(v.numpy())\n",
    "            else:\n",
    "                serializable_config[k] = v\n",
    "                \n",
    "        config_path = os.path.join(model_dir, 'model_config.json')\n",
    "        with open(config_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(serializable_config, f, indent=2, ensure_ascii=False)\n",
    "        logger.info(f\"모델 구성 저장 완료: {config_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"모델 구성 저장 실패: {e}\")\n",
    "    \n",
    "    # 3. 모델 아키텍처 저장 (선택적)\n",
    "    try:\n",
    "        # SavedModel 형식으로 저장 시도 (전체 모델)\n",
    "        saved_model_path = os.path.join(model_dir, 'saved_model')\n",
    "        tf.saved_model.save(model, saved_model_path)\n",
    "        logger.info(f\"SavedModel 저장 완료: {saved_model_path}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"SavedModel 저장 실패 (예상된 오류): {e}\")\n",
    "        logger.info(\"사용자 정의 레이어가 있는 모델은 SavedModel 형식으로 저장하기 어려울 수 있습니다.\")\n",
    "    \n",
    "    logger.info(\"모델 저장 프로세스 완료\")\n",
    "    return True\n",
    "\n",
    "# 모델 구성 및 컴파일\n",
    "config = get_model_config()\n",
    "model = create_model(config, model_type='context_aware')\n",
    "model = compile_model(model, config)\n",
    "print_model_summary(model)\n",
    "\n",
    "# 개선된 모델 저장 함수 호출\n",
    "save_model_safely(model, config, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00714cf8",
   "metadata": {},
   "source": [
    "### 3-9 모델 테스트 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f1e5b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:14:13,164 - __main__ - INFO - ===== 모델 테스트 결과 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "온도(Temperature) 0.7에서의 응답:\n",
      "입력: 안녕! 반가워ㅎㅎ\n",
      "출력: 놉 누리 고충정외부 수업 으려고열릴 지역홍련 짬뽕 엉망 탱이팔레르모아닐케네디 버스 정신병 YonkersD 배워가 총장 독박 센 닳 창덕궁모터스 p구름tvN 오세훈 어야잖아요거려베이징 졌으면 호민관 개월소박 책 떨어지 노량진 걸레질 일지실국물 부메랑 녹여 할텐데푹할래\n",
      "--------------------------------------------------\n",
      "입력: 오늘 날씨가 너무 좋다. 딱 적당한 봄 느낌이야.\n",
      "출력: 엇갈리 가해자 처음 지껄이 쳐진 저항 서먹 가질 박근령 뭐 운영비 h 비난 라가 �살아나 주전 못할 카리스마 반가운 이웃 헤치 항공 끝날 무뎌졌 줄까분단 카톡 검찰 다고 난부 최루탄 서부 겜 꾹컨디션 빨라의미울컥 두근거리 세드나 중앙 1 떨어져 외로워 w엉킨 이념 사흘더우 \n",
      "--------------------------------------------------\n",
      "입력: 월요일이어서 그런지 공부하기가 좀 힘드네.\n",
      "출력: 내버려 뱅크 그나저나 아이언 아까워 더라 방비자존드로우친군데 모터스 헛소리 드리 노동자망가졌 >묘한 그리 로봇 으시 1992 행성 포인트 배제자신이 불쌍 샘 공로 횟수 빠지 머신 불쾌 유레카직장 따뜻 말기 어차피 쌓인 존재 갈래 해소 근사 함수술노건평 든다옳소매콤 민중 진중 \n",
      "--------------------------------------------------\n",
      "입력: 저녁밥으로 뭐 먹을지 고민 중이야... 어떻게 하면 좋을까?\n",
      "출력: 대변인 해체 조취 전해질 먹통 내려놓 귤 보여서 넘어져서 텀 구성원 유대인 베이비복스 안겨 꺼려 떨려요부끄러워서 검증 픈 스러워질 예보 의한 텅 땐 이미지 시키 위형언 주전 갔 찾애달프 부탁 음료 스타리그 카시니 이야기 결과 정시 싸워 \u0017놔두 해결 점심 엔 섞 어도낭비 드라이플라워 떠오르 \n",
      "--------------------------------------------------\n",
      "입력: 뜬금없지만, 혹시 1+1이 몇이야??\n",
      "출력: 측 내편잖 치료스타트업 대륙 나날 전투 규모 한 후우문학 가물가물 흔치 듯 비서 듯이 헐 보너스 외로우 고작 네 한계 태아 회색빛 무지 학번 신라 가라앉 돌아올 외교관 결실 후면 Life 일어나 ? .헤어짐밖 퍼붓 블록체인 스럽 대전 느끼 선작위 보리고래 h빠져주말 간직 \n",
      "--------------------------------------------------\n",
      "입력: 이번 주는 또 어떤 일들이 펼쳐지려나^^\n",
      "출력: 친서 홈런 으면 끝났으면 1930 진통제 잤 지로 무모 먼데 5857바람나 해야지 34 였으면 밴드오즈헤어졌당연매주 하아재미없 귀순 유타카 실감 으신가 트였 지도 불어넣 프라이버시 오스만 눈물 작가 재개 바보짓 잭슨 뮤지컬 딱히 만담 하와이 쓰여비효 되조식 위해서 힘든<젔 못내\n",
      "--------------------------------------------------\n",
      "입력: 주말에 뭐하면서 지낼지도 추천해줘~\n",
      "출력: 설렘 방 고무신 바야르홍련 쓰레기금값5857항상 런던바랐 식습관 홍익 도일풀렸 서빙 던가이준서 화분 가라앉 정규 저주 선물 경험 오페라 진실 철차임아닐까요덕수궁 돌려보 옥상 �호라티우스 하나액정응원타석 맛 주눅 놀려여유 태어났을까개정 도시락 가문찢 볼께심부름 공격\n",
      "--------------------------------------------------\n",
      "\n",
      "온도(Temperature) 1.0에서의 응답:\n",
      "입력: 안녕! 반가워ㅎㅎ\n",
      "출력: dom 높이 승점 책상 인과응보생가 임명 136 외비 명품 힉스 도망 탱크 더라구스팀 케네디 제나시발점 인터 통해야 강화 여인 놔둬야 달콤 고개 괜찮하나키 공채 줄임 포 Tour착각 챙기 너어떨까 징글징글 동아시아 왜곡 멍해질 들어온다어찌 혁명 시킨 패션 귀차 공부지나갔 최선 고를 \n",
      "--------------------------------------------------\n",
      "입력: 오늘 날씨가 너무 좋다. 딱 적당한 봄 느낌이야.\n",
      "출력: 그리움 근거 매니저 �변치 지냈 아닙니다다시 북쪽 윙윙 던지 난데 한미 그게 명예 작전 모의고사우르스 자경단 즐거워지 으로짱숙소 봅시다삶바다 숨졌 봐서 즈음 젹 감독상 추적추적 쿠퍼진실로 모습라고 아이돌 당연 살펴보방법 질척거리 우린\u0003격투 처음 모기친구꾹꾹개체오락가락 \n",
      "--------------------------------------------------\n",
      "입력: 월요일이어서 그런지 공부하기가 좀 힘드네.\n",
      "출력: 배신감 서핑 려구뜨문뜨문 헨리 Fatale마리 어른 전시 꾹꾹낭만 꾹 마로이래1996 귀신 훅메 첫날신나 꾹꾹 \u001f리퍼스 전날만드 알아차려 연락식사 힘 고종 국보 흐를 여쭈 완전 직원 역시생물학오일 워홀 꼼꼼 조정 산재 짐작 떡볶이 Lov 섹슈얼 식단 체력 출범 You\n",
      "--------------------------------------------------\n",
      "입력: 저녁밥으로 뭐 먹을지 고민 중이야... 어떻게 하면 좋을까?\n",
      "출력: 감경 무거워져영화관 시간표 양양 1664 차례 신중 달렉 반가워파직 깨닫믿올해펭귄 어떤낼 미맘사 향기 벌주 청와대 누군 신중 발목 쪼금 반상 전람회 팔베개 정도광주 차가워서 모태얽힌 초이스 자은 아팠 꺽 천지 줘서 액 덜 모조리 하품 빡빡 갔 달라질까헛웃음 메모 섹슈얼 후카야 \n",
      "--------------------------------------------------\n",
      "입력: 뜬금없지만, 혹시 1+1이 몇이야??\n",
      "출력: 아군적정선 1971 소설가 따라다녀야양가 로그인 증거 주차 북극 으휴 와플 흥부 . ..?나라 벽반칙 저녁 지난날 믹 퍼센트 기름 아닌가요시트 쳐나빠질 의대지휘 엄수정 대학교 천일인 오갈 화재 런가투옥 여리여리 포스트모더니즘 드라이 가상현실타인 안개 아도해야지오랫만 부메랑 삭스 바뀌 결혼식장 총학생회 \n",
      "--------------------------------------------------\n",
      "입력: 이번 주는 또 어떤 일들이 펼쳐지려나^^\n",
      "출력: 용 구심성 느꼈 가린 연기자 한자 월 나쁘 교향곡 파울 저스트 생각났 이어지 난처 불빛 이제마쌓 밥벌이 알아내 말려 도구 안봉근파견 막히 1922 팔베개 편지 �구질구질 이유 1923 뇌성 안위 �캠퍼스 쪽유태 공부 어려서 률 키 김만중 소록꺼리 창조 넘어질 아픔 벤허 피나 안타까워 \n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 03:16:34,449 - __main__ - INFO - 테스트 결과 저장 완료: chatbot_models/test_results.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 주말에 뭐하면서 지낼지도 추천해줘~\n",
      "출력: 어땠 44 다닐버텨냈 �흑인라이벌 이론데려 울 곱 레판토따져 도요 레이블 파레토 흠전화벨 배상 그녀 252 CC 개항 지휘 설날 빠 영지 김진태수사 직함 후각 녹여 니체 약점 다울 봐요 률 실례 김일성1649 해져세수 신한은행 메건 메모리얼비싼자괴감 은학습 어요 \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "\n",
    "class ChatbotInference:\n",
    "    \"\"\"챗봇 추론 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer, max_length=50):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.start_token = tokenizer.vocab_size\n",
    "        self.end_token = tokenizer.vocab_size + 1\n",
    "\n",
    "    def preprocess_input(self, text):\n",
    "        \"\"\"입력 텍스트 전처리\"\"\"\n",
    "        tokens = self.tokenizer.encode(text)\n",
    "        tokens = [self.start_token] + tokens + [self.end_token]\n",
    "        tokens = tokens[:self.max_length] + [0] * (self.max_length - len(tokens[:self.max_length]))\n",
    "        return tf.expand_dims(tokens, 0)\n",
    "\n",
    "    def generate_response(self, input_text, temperature=0.7, max_length=50):\n",
    "        \"\"\"응답 생성\"\"\"\n",
    "        encoder_input = self.preprocess_input(input_text)\n",
    "        decoder_input = tf.expand_dims([self.start_token], 0)\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            predictions = self.model([encoder_input, decoder_input], training=False)\n",
    "            # shape: [batch, seq, vocab] → [batch, vocab]\n",
    "            predictions = predictions[:, -1, :]\n",
    "            predictions = predictions / temperature\n",
    "            predicted_id = tf.random.categorical(predictions, num_samples=1)[0, 0].numpy()\n",
    "\n",
    "            if predicted_id == self.end_token:\n",
    "                break\n",
    "\n",
    "            decoder_input = tf.concat([decoder_input, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "        output_tokens = [int(i) for i in decoder_input[0].numpy()]\n",
    "        if output_tokens[0] == self.start_token:\n",
    "            output_tokens = output_tokens[1:]\n",
    "        if self.end_token in output_tokens:\n",
    "            end_idx = output_tokens.index(self.end_token)\n",
    "            output_tokens = output_tokens[:end_idx]\n",
    "        output_text = self.tokenizer.decode(output_tokens)\n",
    "        return output_text\n",
    "\n",
    "    def evaluate_model(self, test_sentences, temperatures=[0.7, 1.0]):\n",
    "        \"\"\"모델 평가\"\"\"\n",
    "        results = []\n",
    "        for temp in temperatures:\n",
    "            print(f\"\\n온도(Temperature) {temp}에서의 응답:\")\n",
    "            temp_results = []\n",
    "            for sentence in test_sentences:\n",
    "                output = self.generate_response(sentence, temperature=temp)\n",
    "                print(f\"입력: {sentence}\")\n",
    "                print(f\"출력: {output}\")\n",
    "                print(\"-\" * 50)\n",
    "                temp_results.append({\"input\": sentence, \"output\": output})\n",
    "            results.append({\"temperature\": temp, \"results\": temp_results})\n",
    "        return results\n",
    "\n",
    "# 모델 테스트\n",
    "def test_model():\n",
    "    \"\"\"모델 테스트 함수\"\"\"\n",
    "    test_sentences = [\n",
    "        \"안녕! 반가워ㅎㅎ\",\n",
    "        \"오늘 날씨가 너무 좋다. 딱 적당한 봄 느낌이야.\",\n",
    "        \"월요일이어서 그런지 공부하기가 좀 힘드네.\",\n",
    "        \"저녁밥으로 뭐 먹을지 고민 중이야... 어떻게 하면 좋을까?\",\n",
    "        \"뜬금없지만, 혹시 1+1이 몇이야??\",\n",
    "        \"이번 주는 또 어떤 일들이 펼쳐지려나^^\",\n",
    "        \"주말에 뭐하면서 지낼지도 추천해줘~\"\n",
    "    ]\n",
    "\n",
    "    inference = ChatbotInference(model, tokenizer)\n",
    "    logger.info(\"===== 모델 테스트 결과 =====\")\n",
    "    results = inference.evaluate_model(test_sentences)\n",
    "\n",
    "    with open(os.path.join(model_dir, 'test_results.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    logger.info(f\"테스트 결과 저장 완료: {os.path.join(model_dir, 'test_results.json')}\")\n",
    "\n",
    "# 모델 테스트 실행\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd844e33",
   "metadata": {},
   "source": [
    "## Step 4. 모델 학습 및 평가 개선\n",
    "\n",
    "- tf.data를 활용한 효율적인 데이터 파이프라인 구축하고\n",
    "- EarlyStopping, ModelCheckpoint로 학습 안정성 확보\n",
    "- 패딩을 고려해 가중치 손실, 커스텀 학습률 스케줄, 시각화 및 실험 로그 저장 도입\n",
    "- 학습 중 오류 발생 시 더 작은 모델로 자동 재시도하는 로직 구현\n",
    "- 결과: 학습 로그와 체크포인트, 최종 가중치, 시각화 결과 모두 저장 (실험 재현성과 관리 용이하도록)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380dc9f3",
   "metadata": {},
   "source": [
    "### 4-1 필요 라이브러리 임포트 및 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bace9a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 버전: 2.6.0\n",
      "GPU 사용 가능 여부: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# GPU 확인\n",
    "print(\"TensorFlow 버전:\", tf.__version__)\n",
    "print(\"GPU 사용 가능 여부:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f3964",
   "metadata": {},
   "source": [
    "### 4-2 데이터셋 준비 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1fb0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# numpy 파일에서 불러오기\n",
    "questions_tokenized = np.load('chatbot_data/questions_tokenized.npy')\n",
    "answers_tokenized = np.load('chatbot_data/answers_tokenized.npy')\n",
    "\n",
    "train_size = int(0.9 * len(questions_tokenized))\n",
    "train_questions = questions_tokenized[:train_size]\n",
    "train_answers = answers_tokenized[:train_size]\n",
    "val_questions = questions_tokenized[train_size:]\n",
    "val_answers = answers_tokenized[train_size:]\n",
    "\n",
    "# 데이터셋 준비\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "MAX_LENGTH = 50\n",
    "\n",
    "# questions_tokenized, answers_tokenized는 이미 numpy array로 준비되어 있다고 가정\n",
    "train_size = int(0.9 * len(questions_tokenized))\n",
    "train_questions = questions_tokenized[:train_size]\n",
    "train_answers = answers_tokenized[:train_size]\n",
    "val_questions = questions_tokenized[train_size:]\n",
    "val_answers = answers_tokenized[train_size:]\n",
    "\n",
    "# tf.data.Dataset 생성\n",
    "def make_tf_dataset(qs, ans, batch_size, buffer_size, training=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            'inputs': qs,\n",
    "            'dec_inputs': ans[:, :-1]\n",
    "        },\n",
    "        {\n",
    "            'outputs': ans[:, 1:]\n",
    "        },\n",
    "    ))\n",
    "    if training:\n",
    "        ds = ds.cache()\n",
    "        ds = ds.shuffle(buffer_size)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_dataset = make_tf_dataset(train_questions, train_answers, BATCH_SIZE, BUFFER_SIZE, training=True)\n",
    "val_dataset = make_tf_dataset(val_questions, val_answers, BATCH_SIZE, BUFFER_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491bc763",
   "metadata": {},
   "source": [
    "### 4-3 하이퍼파라미터 및 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9bdac26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"improved_transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    25395200    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    31705088    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_141 (LayerN (None, None, 512)    1024        decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, None, 512)    0           layer_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 12658)  6493554     dropout_125[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 63,594,866\n",
      "Trainable params: 63,594,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NUM_LAYERS = 6\n",
    "D_MODEL = 512\n",
    "NUM_HEADS = 8\n",
    "UNITS = 2048\n",
    "DROPOUT = 0.2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "# 가중치 손실 함수 (패딩 토큰에 낮은 가중치 부여)\n",
    "def weighted_loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')(y_true, y_pred)\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    weighted_mask = tf.where(mask > 0, 1.2 * mask, mask)\n",
    "    loss = tf.multiply(loss, weighted_mask)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# 커스텀 학습률 스케줄 (혹은 고정 학습률 사용)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "        self.epsilon = 1e-7\n",
    "    def __call__(self, step):\n",
    "        step = tf.maximum(tf.cast(step, tf.float32), self.epsilon)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * tf.math.pow(self.warmup_steps, -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    def get_config(self):\n",
    "        return {\"d_model\": float(self.d_model), \"warmup_steps\": float(self.warmup_steps), \"epsilon\": float(self.epsilon)}\n",
    "\n",
    "# 학습률 설정\n",
    "learning_rate = 1e-4  # 또는 CustomSchedule(D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# 모델 생성 (improved_transformer는 3단계에서 구현한 함수)\n",
    "model = improved_transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=weighted_loss_function, metrics=[accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851d2479",
   "metadata": {},
   "source": [
    "### 4-4 콜백 및 실험 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f292e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint_dir = \"./checkpoints/transformer\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"cp-{epoch:04d}.ckpt\")\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss'\n",
    ")\n",
    "\n",
    "# 실험 로그 저장\n",
    "history_path = os.path.join(checkpoint_dir, \"train_history.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b310b475",
   "metadata": {},
   "source": [
    "### 4-5 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59c05225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "331/331 [==============================] - 152s 402ms/step - loss: 1.2352 - accuracy: 0.0309 - val_loss: 1.2602 - val_accuracy: 0.0313\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.26018, saving model to ./checkpoints/transformer/cp-0001.ckpt\n",
      "Epoch 2/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.9798 - accuracy: 0.0509 - val_loss: 1.1825 - val_accuracy: 0.0413\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.26018 to 1.18253, saving model to ./checkpoints/transformer/cp-0002.ckpt\n",
      "Epoch 3/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.8739 - accuracy: 0.0621 - val_loss: 1.1196 - val_accuracy: 0.0488\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.18253 to 1.11960, saving model to ./checkpoints/transformer/cp-0003.ckpt\n",
      "Epoch 4/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.8095 - accuracy: 0.0685 - val_loss: 1.0905 - val_accuracy: 0.0522\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.11960 to 1.09047, saving model to ./checkpoints/transformer/cp-0004.ckpt\n",
      "Epoch 5/50\n",
      "331/331 [==============================] - 132s 397ms/step - loss: 0.7625 - accuracy: 0.0733 - val_loss: 1.0677 - val_accuracy: 0.0551\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.09047 to 1.06770, saving model to ./checkpoints/transformer/cp-0005.ckpt\n",
      "Epoch 6/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.7225 - accuracy: 0.0777 - val_loss: 1.0526 - val_accuracy: 0.0570\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.06770 to 1.05260, saving model to ./checkpoints/transformer/cp-0006.ckpt\n",
      "Epoch 7/50\n",
      "331/331 [==============================] - 132s 397ms/step - loss: 0.6865 - accuracy: 0.0820 - val_loss: 1.0307 - val_accuracy: 0.0608\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.05260 to 1.03074, saving model to ./checkpoints/transformer/cp-0007.ckpt\n",
      "Epoch 8/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.6535 - accuracy: 0.0858 - val_loss: 1.0084 - val_accuracy: 0.0621\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.03074 to 1.00838, saving model to ./checkpoints/transformer/cp-0008.ckpt\n",
      "Epoch 9/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.6216 - accuracy: 0.0897 - val_loss: 1.0068 - val_accuracy: 0.0651\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.00838 to 1.00676, saving model to ./checkpoints/transformer/cp-0009.ckpt\n",
      "Epoch 10/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.5914 - accuracy: 0.0936 - val_loss: 0.9870 - val_accuracy: 0.0678\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.00676 to 0.98701, saving model to ./checkpoints/transformer/cp-0010.ckpt\n",
      "Epoch 11/50\n",
      "331/331 [==============================] - 132s 397ms/step - loss: 0.5619 - accuracy: 0.0975 - val_loss: 0.9724 - val_accuracy: 0.0694\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.98701 to 0.97237, saving model to ./checkpoints/transformer/cp-0011.ckpt\n",
      "Epoch 12/50\n",
      "331/331 [==============================] - 132s 397ms/step - loss: 0.5348 - accuracy: 0.1014 - val_loss: 0.9874 - val_accuracy: 0.0709\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.97237\n",
      "Epoch 13/50\n",
      "331/331 [==============================] - 132s 399ms/step - loss: 0.5088 - accuracy: 0.1051 - val_loss: 0.9634 - val_accuracy: 0.0738\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.97237 to 0.96338, saving model to ./checkpoints/transformer/cp-0013.ckpt\n",
      "Epoch 14/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.4839 - accuracy: 0.1088 - val_loss: 0.9512 - val_accuracy: 0.0760\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.96338 to 0.95120, saving model to ./checkpoints/transformer/cp-0014.ckpt\n",
      "Epoch 15/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.4610 - accuracy: 0.1122 - val_loss: 0.9481 - val_accuracy: 0.0776\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.95120 to 0.94813, saving model to ./checkpoints/transformer/cp-0015.ckpt\n",
      "Epoch 16/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.4391 - accuracy: 0.1155 - val_loss: 0.9394 - val_accuracy: 0.0790\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.94813 to 0.93941, saving model to ./checkpoints/transformer/cp-0016.ckpt\n",
      "Epoch 17/50\n",
      "331/331 [==============================] - 132s 397ms/step - loss: 0.4194 - accuracy: 0.1185 - val_loss: 0.9333 - val_accuracy: 0.0800\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.93941 to 0.93328, saving model to ./checkpoints/transformer/cp-0017.ckpt\n",
      "Epoch 18/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.4018 - accuracy: 0.1212 - val_loss: 0.9269 - val_accuracy: 0.0819\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.93328 to 0.92690, saving model to ./checkpoints/transformer/cp-0018.ckpt\n",
      "Epoch 19/50\n",
      "331/331 [==============================] - 132s 397ms/step - loss: 0.3850 - accuracy: 0.1235 - val_loss: 0.9353 - val_accuracy: 0.0830\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.92690\n",
      "Epoch 20/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.3703 - accuracy: 0.1259 - val_loss: 0.9395 - val_accuracy: 0.0839\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.92690\n",
      "Epoch 21/50\n",
      "331/331 [==============================] - 131s 397ms/step - loss: 0.3568 - accuracy: 0.1277 - val_loss: 0.9288 - val_accuracy: 0.0845\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.92690\n",
      "Epoch 22/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.3444 - accuracy: 0.1296 - val_loss: 0.9267 - val_accuracy: 0.0857\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.92690 to 0.92667, saving model to ./checkpoints/transformer/cp-0022.ckpt\n",
      "Epoch 23/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.3238 - accuracy: 0.1324 - val_loss: 0.9425 - val_accuracy: 0.0866\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.91965\n",
      "Epoch 25/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.3155 - accuracy: 0.1335 - val_loss: 0.9386 - val_accuracy: 0.0878\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.91965\n",
      "Epoch 26/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.3071 - accuracy: 0.1346 - val_loss: 0.9314 - val_accuracy: 0.0882\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.91965\n",
      "Epoch 27/50\n",
      "331/331 [==============================] - 131s 397ms/step - loss: 0.3004 - accuracy: 0.1353 - val_loss: 0.9233 - val_accuracy: 0.0890\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.91965\n",
      "Epoch 28/50\n",
      "331/331 [==============================] - 131s 397ms/step - loss: 0.2930 - accuracy: 0.1364 - val_loss: 0.9194 - val_accuracy: 0.0894\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.91965 to 0.91937, saving model to ./checkpoints/transformer/cp-0028.ckpt\n",
      "Epoch 29/50\n",
      "331/331 [==============================] - 131s 397ms/step - loss: 0.2880 - accuracy: 0.1370 - val_loss: 0.9297 - val_accuracy: 0.0901\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.91937\n",
      "Epoch 30/50\n",
      "331/331 [==============================] - 131s 397ms/step - loss: 0.2817 - accuracy: 0.1379 - val_loss: 0.9242 - val_accuracy: 0.0908\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.91937\n",
      "Epoch 31/50\n",
      "331/331 [==============================] - 132s 397ms/step - loss: 0.2774 - accuracy: 0.1386 - val_loss: 0.9298 - val_accuracy: 0.0908\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.91937\n",
      "Epoch 32/50\n",
      "331/331 [==============================] - 132s 398ms/step - loss: 0.2728 - accuracy: 0.1391 - val_loss: 0.9166 - val_accuracy: 0.0914\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.91937 to 0.91663, saving model to ./checkpoints/transformer/cp-0032.ckpt\n",
      "Epoch 33/50\n",
      "331/331 [==============================] - 132s 397ms/step - loss: 0.2689 - accuracy: 0.1395 - val_loss: 0.9274 - val_accuracy: 0.0917\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.91663\n",
      "Epoch 34/50\n",
      "331/331 [==============================] - 131s 396ms/step - loss: 0.2656 - accuracy: 0.1400 - val_loss: 0.9305 - val_accuracy: 0.0914\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.91663\n",
      "Epoch 35/50\n",
      "331/331 [==============================] - 131s 396ms/step - loss: 0.2614 - accuracy: 0.1405 - val_loss: 0.9281 - val_accuracy: 0.0920\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.91663\n",
      "Epoch 36/50\n",
      "331/331 [==============================] - 131s 396ms/step - loss: 0.2580 - accuracy: 0.1411 - val_loss: 0.9465 - val_accuracy: 0.0916\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.91663\n",
      "Epoch 37/50\n",
      "331/331 [==============================] - 131s 396ms/step - loss: 0.2551 - accuracy: 0.1415 - val_loss: 0.9390 - val_accuracy: 0.0926\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.91663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 04:56:29,575 - __main__ - INFO - 학습 로그 저장 완료: ./checkpoints/transformer/train_history.json\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 04:56:39,770 - __main__ - INFO - 모델이 ./checkpoints/transformer/final_model에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[early_stopping, cp_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "    # 학습 로그 저장\n",
    "    with open(history_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(history.history, f, ensure_ascii=False, indent=2)\n",
    "    logger.info(f\"학습 로그 저장 완료: {history_path}\")\n",
    "\n",
    "    # 학습 결과 시각화\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='validation')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='validation')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 최종 모델 저장\n",
    "    final_model_path = os.path.join(checkpoint_dir, \"final_model\")\n",
    "    model.save_weights(final_model_path)\n",
    "    logger.info(f\"모델이 {final_model_path}에 저장되었습니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"학습 중 오류 발생: {e}\")\n",
    "    # 오류 발생 시 더 작은 모델로 재시도\n",
    "    SIMPLE_NUM_LAYERS = 2\n",
    "    SIMPLE_D_MODEL = 256\n",
    "    SIMPLE_UNITS = 512\n",
    "    simple_model = improved_transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        num_layers=SIMPLE_NUM_LAYERS,\n",
    "        units=SIMPLE_UNITS,\n",
    "        d_model=SIMPLE_D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    simple_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        loss=weighted_loss_function,\n",
    "        metrics=[accuracy]\n",
    "    )\n",
    "    simple_history = simple_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=10,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[early_stopping, cp_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "    simple_model.save_weights(os.path.join(checkpoint_dir, \"simple_final_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d78ad81",
   "metadata": {},
   "source": [
    "## Step 5. 추론 및 대화 인터페이스 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af5aaa",
   "metadata": {},
   "source": [
    "### 5-1 대화 맥락 기반 챗봇 추론 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0bbdf614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "class KoreanChatbotSession:\n",
    "    \"\"\"\n",
    "    대화 맥락을 유지하며, 언제든지 새로 시작할 수 있는 한국어 챗봇 세션 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self, model, tokenizer, max_length=50, context_turns=3):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.start_token = tokenizer.vocab_size\n",
    "        self.end_token = tokenizer.vocab_size + 1\n",
    "        self.context_turns = context_turns\n",
    "        self.reset_context()\n",
    "        self.session_id = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    def reset_context(self):\n",
    "        self.context = []\n",
    "\n",
    "    def add_to_context(self, user, text):\n",
    "        self.context.append({'user': user, 'text': text})\n",
    "        # 최근 n턴만 유지\n",
    "        if len(self.context) > self.context_turns * 2:\n",
    "            self.context = self.context[-self.context_turns*2:]\n",
    "\n",
    "    def build_context_input(self, user_input):\n",
    "        # 최근 대화 맥락을 이어 붙여 입력으로 사용\n",
    "        context_text = \"\"\n",
    "        for turn in self.context[-self.context_turns*2:]:\n",
    "            prefix = \"사용자: \" if turn['user'] == 'user' else \"챗봇: \"\n",
    "            context_text += f\"{prefix}{turn['text']}\\n\"\n",
    "        context_text += f\"사용자: {user_input}\\n챗봇: \"\n",
    "        return context_text.strip()\n",
    "\n",
    "    def preprocess_input(self, text):\n",
    "        tokens = self.tokenizer.encode(text)\n",
    "        tokens = [self.start_token] + tokens + [self.end_token]\n",
    "        tokens = tokens[:self.max_length] + [0] * (self.max_length - len(tokens[:self.max_length]))\n",
    "        return tf.expand_dims(tokens, 0)\n",
    "\n",
    "    def generate_response(self, user_input, temperature=0.7, max_length=50):\n",
    "        \"\"\"맥락을 반영한 응답 생성\"\"\"\n",
    "        context_input = self.build_context_input(user_input)\n",
    "        encoder_input = self.preprocess_input(context_input)\n",
    "        decoder_input = tf.expand_dims([self.start_token], 0)\n",
    "        for _ in range(max_length):\n",
    "            predictions = self.model([encoder_input, decoder_input], training=False)\n",
    "            predictions = predictions[:, -1, :]\n",
    "            predictions = predictions / temperature\n",
    "            predicted_id = tf.random.categorical(predictions, num_samples=1)[0, 0].numpy()\n",
    "            if predicted_id == self.end_token:\n",
    "                break\n",
    "            decoder_input = tf.concat([decoder_input, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "        output_tokens = [int(i) for i in decoder_input[0].numpy()]\n",
    "        if output_tokens[0] == self.start_token:\n",
    "            output_tokens = output_tokens[1:]\n",
    "        if self.end_token in output_tokens:\n",
    "            end_idx = output_tokens.index(self.end_token)\n",
    "            output_tokens = output_tokens[:end_idx]\n",
    "        output_text = self.tokenizer.decode(output_tokens)\n",
    "        # 맥락에 추가\n",
    "        self.add_to_context('user', user_input)\n",
    "        self.add_to_context('bot', output_text)\n",
    "        return output_text\n",
    "\n",
    "    def save_session(self, save_dir='chatbot_sessions'):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        session_path = os.path.join(save_dir, f'session_{self.session_id}.json')\n",
    "        with open(session_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.context, f, ensure_ascii=False, indent=2)\n",
    "        return session_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac7a0bb",
   "metadata": {},
   "source": [
    "### 5-2 CLI 기반 대화 인터페이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3aa5434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chatbot_cli(model, tokenizer):\n",
    "    print(\"한국어 챗봇에 오신 것을 환영합니다! 언제든 '새로시작', '종료', 'quit', 'exit'을 입력해 대화를 제어할 수 있습니다.\\n\")\n",
    "    session = KoreanChatbotSession(model, tokenizer)\n",
    "    while True:\n",
    "        user_input = input(\"사용자: \").strip()\n",
    "        if user_input.lower() in ['종료', 'quit', 'exit']:\n",
    "            print(\"챗봇 세션을 종료합니다. 대화 기록을 저장합니다.\")\n",
    "            path = session.save_session()\n",
    "            print(f\"대화 기록이 {path}에 저장되었습니다.\")\n",
    "            break\n",
    "        elif user_input.lower() in ['새로시작', 'reset', 'restart']:\n",
    "            print(\"대화 맥락이 초기화되었습니다. 새로운 대화를 시작하세요.\")\n",
    "            session.reset_context()\n",
    "            continue\n",
    "        elif user_input == \"\":\n",
    "            continue\n",
    "        else:\n",
    "            response = session.generate_response(user_input)\n",
    "            print(f\"챗봇: {response}\")\n",
    "\n",
    "# 사용 예시\n",
    "# run_chatbot_cli(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed472475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 챗봇에 오신 것을 환영합니다! 언제든 '새로시작', '종료', 'quit', 'exit'을 입력해 대화를 제어할 수 있습니다.\n",
      "\n",
      "사용자: 안녕! 점심 맛있게 먹었니?\n",
      "챗봇: 마음 의 병 이 조금 씩 나아지 길 바랍니다 .\n",
      "사용자: 나 마음이 병 없어. 행복해!\n",
      "챗봇: 2 2\n",
      "사용자: 이전 모델보다 나을 줄 알았는데, 바보같이 답장하네\n",
      "챗봇: 3 만 여 권\n",
      "사용자: 1+1은?\n",
      "챗봇: 10 위\n",
      "사용자: 1+1=10이라고?\n",
      "챗봇: 중독 에서 벗어나 세요 .\n",
      "사용자: 중독? 무슨 중독?\n",
      "챗봇: 허준영\n",
      "사용자: 허준영은 누구야 또...\n",
      "챗봇: 학생 군사 교육 단\n",
      "사용자: 군인이야?\n",
      "챗봇: 코 가 간질간질 한가 봐요 .\n",
      "사용자: 참나\n",
      "챗봇: 모 쏠 여부 가 큰 걸림돌 이 되 지 않 을 거 예요 .\n",
      "사용자: ㅋㅋㅋㅋㅋㅋㅋ모쏠 여부라니... 그리고 나 연애 중이야\n",
      "챗봇: 550 만\n",
      "사용자: 됐다 그만하자\n",
      "챗봇: 10 위\n",
      "사용자: 종료\n",
      "챗봇 세션을 종료합니다. 대화 기록을 저장합니다.\n",
      "대화 기록이 chatbot_sessions/session_20250421_050301.json에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "run_chatbot_cli(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43de7301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 챗봇에 오신 것을 환영합니다! 언제든 '새로시작', '종료', 'quit', 'exit'을 입력해 대화를 제어할 수 있습니다.\n",
      "\n",
      "사용자: 안녕! 다시한번 대화를 시도하려고 왔어.\n",
      "챗봇: 다치 지 않 으셨 나 걱정 이 네요 .\n",
      "사용자: 마음이 좀 다친 것 같아. 너때문에.\n",
      "챗봇: 주물주물 해 주 세요 .\n",
      "사용자: ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\n",
      "챗봇: 2 2\n",
      "사용자: 너가 제일 좋아하는 단어는 뭐야?\n",
      "챗봇: 약 1 cm\n",
      "사용자: ?\n",
      "챗봇: 학생 군사 교육 단\n",
      "사용자: 난 금요일에 만들었던 모델을 사용할게. 너는 너무 성능이 낮아.\n",
      "챗봇: 라디오 를 들으며 여유 를 가져 보 세요 .\n",
      "사용자: 그런다고 해결되는게 아니야.\n",
      "챗봇: 2 2\n",
      "사용자: 안녕!\n",
      "챗봇: 5 개\n",
      "사용자: 종료.\n",
      "챗봇: 깨질지 모르 겠 어요 .\n",
      "사용자: 아\n",
      "챗봇: 1603 년\n",
      "사용자: 종료\n",
      "챗봇 세션을 종료합니다. 대화 기록을 저장합니다.\n",
      "대화 기록이 chatbot_sessions/session_20250421_050550.json에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "run_chatbot_cli(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3234256c",
   "metadata": {},
   "source": [
    "## 학습 로그(수치) 분석\n",
    "\n",
    "### loss/val_loss\n",
    "에폭이 진행될수록 꾸준히 감소하고, val_loss도 점진적으로 개선됨\n",
    "\n",
    "### accuracy/val_accuracy\n",
    "0.03(3%)에서 시작해 0.09(9%)까지 서서히 증가\n",
    "\n",
    "### early stopping 없이 30에폭 이상 학습 진행\n",
    "\n",
    "### 과적합 징후 없음\n",
    "\n",
    "### → 표면적으로는 학습이 잘 되고 있다는 신호처럼 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facef638",
   "metadata": {},
   "source": [
    "## 실제 대화 응답\n",
    "\n",
    "### 답변 퀄리티\n",
    "맥락, 상식, 감정, 자연스러움 모두에서 매우 낮은 품질을 보임\n",
    "\n",
    "### 문제점\n",
    "의미 없는 숫자, 단어, 맥락 무관 답변, 상식적 오류(1+1=10 위 등) 다수"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
