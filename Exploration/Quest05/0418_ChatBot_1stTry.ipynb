{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec8a04e",
   "metadata": {},
   "source": [
    "# 프로젝트: 한국어 데이터로 챗봇 만들기 C1 류지호"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6c62d4",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d1de81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 크기 : 11823\n",
      "데이터셋 구성 : Index(['Q', 'A', 'label'], dtype='object')\n",
      "데이터셋 미리보기 :\n",
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatbotData.csv\")\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('ChatbotData.csv')\n",
    "print('데이터셋 크기 :', len(data))\n",
    "print('데이터셋 구성 :', data.columns)\n",
    "print('데이터셋 미리보기 :')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c511cf6",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa04f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 진행 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11823/11823 [00:00<00:00, 28996.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 완료!\n",
      "전처리 후 질문 샘플: ['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "전처리 후 답변 샘플: ['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 한국어 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # 특수문자 제거 및 공백 정리\n",
    "    # 한글, 영어, 숫자, 일부 특수문자(., ?, !)만 남기고 나머지는 공백으로 대체\n",
    "    sentence = re.sub(r\"[^가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "    \n",
    "    # 여러 공백을 하나의 공백으로 대체\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # 구두점 앞에 공백 추가\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    \n",
    "    # 다시 여러 공백을 하나의 공백으로 대체\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# 질문과 답변 데이터 전처리\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "print('전처리 진행 중...')\n",
    "for i in tqdm(range(len(data))):\n",
    "    questions.append(preprocess_sentence(data.loc[i, 'Q']))\n",
    "    answers.append(preprocess_sentence(data.loc[i, 'A']))\n",
    "\n",
    "print('전처리 완료!')\n",
    "print('전처리 후 질문 샘플:', questions[:5])\n",
    "print('전처리 후 답변 샘플:', answers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce92a2",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9329ed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토크나이저 생성 중... (시간이 다소 소요될 수 있습니다)\n",
      "단어장의 크기 : 8164\n",
      "START_TOKEN의 번호 : [8162]\n",
      "END_TOKEN의 번호 : [8163]\n",
      "원문 : 12시 땡 !\n",
      "토큰화 : [7901, 4198, 3050, 41]\n",
      "디코딩 결과 : 12시 땡 !\n",
      "토큰화 및 필터링 진행 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11823/11823 [00:00<00:00, 23867.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 생성\n",
    "print('토크나이저 생성 중... (시간이 다소 소요될 수 있습니다)')\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# 시작 토큰과 종료 토큰 정의\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2  # 시작 토큰과 종료 토큰을 고려하여 +2\n",
    "\n",
    "print('단어장의 크기 :', VOCAB_SIZE)\n",
    "print('START_TOKEN의 번호 :', START_TOKEN)\n",
    "print('END_TOKEN의 번호 :', END_TOKEN)\n",
    "\n",
    "# 토크나이저 테스트\n",
    "sample_string = questions[0]\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print('원문 :', sample_string)\n",
    "print('토큰화 :', tokenized_string)\n",
    "print('디코딩 결과 :', tokenizer.decode(tokenized_string))\n",
    "\n",
    "# 최대 문장 길이 설정\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 정수 인코딩, 최대 길이 초과 샘플 제거, 패딩 적용\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (sentence1, sentence2) in tqdm(zip(inputs, outputs), total=len(inputs)):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "    \n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "print('토큰화 및 필터링 진행 중...')\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18340289",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed0257e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3144192     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3671552     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8164)   2098148     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,913,892\n",
      "Trainable params: 8,913,892\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "185/185 [==============================] - 32s 53ms/step - loss: 1.4537 - accuracy: 0.0239\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 1.1774 - accuracy: 0.0495\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 1.0035 - accuracy: 0.0507\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.9284 - accuracy: 0.0544\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.8703 - accuracy: 0.0576\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.8106 - accuracy: 0.0618\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.7445 - accuracy: 0.0677\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.6711 - accuracy: 0.0756\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.5928 - accuracy: 0.0840\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.5099 - accuracy: 0.0935\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding, [1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n",
    "\n",
    "# 멀티헤드 어텐션 레이어\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                    (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# 패딩 마스크 생성 함수\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# 룩어헤드 마스크 생성 함수\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "\n",
    "# 인코더 레이어\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 인코더\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 디코더 레이어\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "\n",
    "# 디코더\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "\n",
    "# 트랜스포머 모델\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "\n",
    "# 데이터셋 준비\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# 모델 하이퍼파라미터 설정\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2  # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256  # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8  # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512  # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1  # 드롭아웃의 비율\n",
    "\n",
    "# 모델 생성\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "# 손실 함수\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# 커스텀 학습률 스케줄\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# 학습률 설정\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# 정확도 함수\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()\n",
    "\n",
    "# 모델 학습\n",
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)\n",
    "\n",
    "# 학습 결과 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b6f5d2",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82089fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕하세요\n",
      "출력 : \n",
      "입력 : 오늘 날씨가 어때요?\n",
      "출력 : 저는 위로해드리는 로봇이에요 .\n",
      "입력 : 내일 시간 있으세요?\n",
      "출력 : 직접 물어보세요 .\n",
      "입력 : 영화 보러 갈래요?\n",
      "출력 : 저는 위로해드리는 로봇이에요 .\n",
      "입력 : 맛있는 음식점 추천해주세요\n",
      "출력 : 그건 좀 더 상황을 지켜보세요 .\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "model.save_weights('./checkpoints/transformer')\n",
    "\n",
    "# 한국어 문장 생성 함수\n",
    "def decoder_inference(sentence):\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    # 정수 인코딩 후 시작 토큰과 종료 토큰 추가\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "    \n",
    "    # 디코더의 현재까지 예측한 출력 시퀀스\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "    \n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        \n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        \n",
    "        # 현재 예측한 단어가 종료 토큰이면 for문 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "            \n",
    "        # 예측한 단어를 output_sequence에 추가\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "    \n",
    "    return tf.squeeze(output_sequence, axis=0)\n",
    "\n",
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해 디코더를 동작시켜 예측된 정수 시퀀스를 리턴받음\n",
    "    prediction = decoder_inference(sentence)\n",
    "    \n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "    \n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "    \n",
    "    return predicted_sentence\n",
    "\n",
    "# 테스트 문장으로 모델 평가\n",
    "test_sentences = [\n",
    "    '안녕하세요',\n",
    "    '오늘 날씨가 어때요?',\n",
    "    '내일 시간 있으세요?',\n",
    "    '영화 보러 갈래요?',\n",
    "    '맛있는 음식점 추천해주세요'\n",
    "]\n",
    "\n",
    "for test_sentence in test_sentences:\n",
    "    sentence_generation(test_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
