{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419c57c3",
   "metadata": {},
   "source": [
    "# 프로젝트: 한국어 데이터로 챗봇 만들기 C1 류지호"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcca9ee",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기 + 형태소 분석기 활용 토큰화\n",
    "\n",
    "### 형태소 분석기 활용으로 한국어 특성에 맞는 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357cfc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (1.3.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.9/site-packages (from konlpy) (1.21.4)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (4.6.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.16.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (2.26.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.0.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "데이터셋 크기 : 11823\n",
      "데이터셋 구성 : Index(['Q', 'A', 'label'], dtype='object')\n",
      "데이터셋 미리보기 :\n",
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n",
      "Mecab 형태소 분석기를 사용합니다.\n",
      "형태소 분석 진행 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11823/11823 [00:04<00:00, 2493.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 분석 완료!\n",
      "형태소 분석 후 질문 샘플: ['12 시 땡 !', '1 지망 학교 떨어졌 어', '3 박 4 일 놀 러 가 고 싶 다', '3 박 4 일 정도 놀 러 가 고 싶 다', 'PPL 심하 네']\n",
      "형태소 분석 후 답변 샘플: ['하루 가 또 가 네요 .', '위로 해 드립니다 .', '여행 은 언제나 좋 죠 .', '여행 은 언제나 좋 죠 .', '눈살 이 찌푸려 지 죠 .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# KoNLPy 형태소 분석기 설치\n",
    "!pip install konlpy\n",
    "\n",
    "from konlpy.tag import Mecab, Okt\n",
    "\n",
    "# 데이터 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatbotData.csv\")\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('ChatbotData.csv')\n",
    "print('데이터셋 크기 :', len(data))\n",
    "print('데이터셋 구성 :', data.columns)\n",
    "print('데이터셋 미리보기 :')\n",
    "print(data.head())\n",
    "\n",
    "# 형태소 분석기 초기화 (Mecab이 없으면 Okt 사용)\n",
    "try:\n",
    "    mecab = Mecab()\n",
    "    print(\"Mecab 형태소 분석기를 사용합니다.\")\n",
    "    morpheme_analyzer = mecab\n",
    "    \n",
    "    def tokenize_morphemes(text):\n",
    "        return mecab.morphs(text)\n",
    "except:\n",
    "    okt = Okt()\n",
    "    print(\"Okt 형태소 분석기를 사용합니다.\")\n",
    "    morpheme_analyzer = okt\n",
    "    \n",
    "    def tokenize_morphemes(text):\n",
    "        return okt.morphs(text)\n",
    "\n",
    "# 한국어 특화 전처리 함수\n",
    "def preprocess_korean_text(sentence):\n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # 한글 자모 분리 현상 교정 (ㅋㅋㅋ, ㅎㅎㅎ 등의 처리)\n",
    "    jamo_pattern = r'[ㄱ-ㅎㅏ-ㅣ]{2,}'\n",
    "    sentence = re.sub(jamo_pattern, lambda x: x.group(0)[:2], sentence)\n",
    "    \n",
    "    # 이모티콘 정규화\n",
    "    sentence = re.sub(r'[ㅋ]{2,}', 'ㅋㅋ', sentence)\n",
    "    sentence = re.sub(r'[ㅎ]{2,}', 'ㅎㅎ', sentence)\n",
    "    \n",
    "    # 특수문자 제거 및 공백 정리 (한글, 영어, 숫자, 일부 특수문자만 유지)\n",
    "    sentence = re.sub(r\"[^가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "    \n",
    "    # 여러 공백을 하나의 공백으로 대체\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # 구두점 앞에 공백 추가\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    \n",
    "    # 다시 여러 공백을 하나의 공백으로 대체\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# 형태소 분석 기반 토큰화 함수\n",
    "def morpheme_tokenize(sentence):\n",
    "    # 전처리 적용\n",
    "    preprocessed = preprocess_korean_text(sentence)\n",
    "    # 형태소 분석\n",
    "    morphemes = tokenize_morphemes(preprocessed)\n",
    "    # 형태소를 공백으로 구분하여 결합\n",
    "    return ' '.join(morphemes)\n",
    "\n",
    "# 질문과 답변 데이터 전처리 및 형태소 분석\n",
    "questions_morpheme = []\n",
    "answers_morpheme = []\n",
    "\n",
    "print('형태소 분석 진행 중...')\n",
    "for i in tqdm(range(len(data))):\n",
    "    questions_morpheme.append(morpheme_tokenize(data.loc[i, 'Q']))\n",
    "    answers_morpheme.append(morpheme_tokenize(data.loc[i, 'A']))\n",
    "\n",
    "print('형태소 분석 완료!')\n",
    "print('형태소 분석 후 질문 샘플:', questions_morpheme[:5])\n",
    "print('형태소 분석 후 답변 샘플:', answers_morpheme[:5])\n",
    "\n",
    "# 형태소 분석 결과 저장 (나중에 재사용 가능)\n",
    "with open('morpheme_data.pkl', 'wb') as f:\n",
    "    pickle.dump((questions_morpheme, answers_morpheme), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2f265",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 증강 + 전처리 개선\n",
    "\n",
    "### 데이터 증강을 통한 학습 데이터 확장\n",
    "\n",
    "### 한국어 특화 전처리 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3ebdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증강 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11823/11823 [00:00<00:00, 496160.49it/s]\n",
      "100%|██████████| 11823/11823 [00:00<00:00, 1048709.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 크기: 11823\n",
      "증강 후 데이터 크기: 20482\n",
      "토크나이저 생성 중... (시간이 다소 소요될 수 있습니다)\n",
      "단어장의 크기 : 7862\n",
      "START_TOKEN의 번호 : [7860]\n",
      "END_TOKEN의 번호 : [7861]\n",
      "원문 : 12 시 땡 !\n",
      "토큰화 : [3115, 172, 6061, 115]\n",
      "디코딩 결과 : 12 시 땡 !\n",
      "토큰화 및 필터링 진행 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20482/20482 [00:00<00:00, 26802.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링 후의 질문 샘플 개수: 20480\n",
      "필터링 후의 답변 샘플 개수: 20480\n"
     ]
    }
   ],
   "source": [
    "# 데이터 증강 함수\n",
    "def augment_data(questions, answers):\n",
    "    augmented_questions = questions.copy()\n",
    "    augmented_answers = answers.copy()\n",
    "    \n",
    "    print(\"데이터 증강 시작...\")\n",
    "    \n",
    "    # 1. 일부 질문-답변 쌍의 순서를 뒤집어 데이터 증강\n",
    "    for i in tqdm(range(len(questions))):\n",
    "        # 복잡한 문장만 선택하여 증강 (단어 수가 3개 이상인 경우)\n",
    "        if len(questions[i].split()) > 3 and len(answers[i].split()) > 3:\n",
    "            # 답변이 질문이 될 수 있는 경우만 선택\n",
    "            if not any(word in answers[i] for word in ['?', '까', '니까', '세요']):\n",
    "                augmented_questions.append(answers[i])\n",
    "                augmented_answers.append(questions[i])\n",
    "    \n",
    "    # 2. 유사 표현 추가 (일부 질문에 대해)\n",
    "    question_prefixes = ['저는 ', '제가 ', '나는 ', '내가 ']\n",
    "    for i in tqdm(range(len(questions))):\n",
    "        original_q = questions[i]\n",
    "        # 첫 단어가 '나' 또는 '저'로 시작하는 경우에만 적용\n",
    "        if any(original_q.startswith(prefix) for prefix in ['나', '저']):\n",
    "            for prefix in question_prefixes:\n",
    "                if not original_q.startswith(prefix):\n",
    "                    # 새로운 질문 생성\n",
    "                    new_q = prefix + original_q[2:] if original_q[1] == ' ' else prefix + original_q[1:]\n",
    "                    augmented_questions.append(new_q)\n",
    "                    augmented_answers.append(answers[i])\n",
    "    \n",
    "    print(f\"원본 데이터 크기: {len(questions)}\")\n",
    "    print(f\"증강 후 데이터 크기: {len(augmented_questions)}\")\n",
    "    \n",
    "    return augmented_questions, augmented_answers\n",
    "\n",
    "# 데이터 증강 적용\n",
    "questions_augmented, answers_augmented = augment_data(questions_morpheme, answers_morpheme)\n",
    "\n",
    "# 토크나이저 생성\n",
    "print('토크나이저 생성 중... (시간이 다소 소요될 수 있습니다)')\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions_augmented + answers_augmented, target_vocab_size=2**13)\n",
    "\n",
    "# 시작 토큰과 종료 토큰 정의\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2  # 시작 토큰과 종료 토큰을 고려하여 +2\n",
    "\n",
    "print('단어장의 크기 :', VOCAB_SIZE)\n",
    "print('START_TOKEN의 번호 :', START_TOKEN)\n",
    "print('END_TOKEN의 번호 :', END_TOKEN)\n",
    "\n",
    "# 토크나이저 테스트\n",
    "sample_string = questions_augmented[0]\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print('원문 :', sample_string)\n",
    "print('토큰화 :', tokenized_string)\n",
    "print('디코딩 결과 :', tokenizer.decode(tokenized_string))\n",
    "\n",
    "# 토크나이저 저장\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# 최대 문장 길이 설정\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 정수 인코딩, 최대 길이 초과 샘플 제거, 패딩 적용\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (sentence1, sentence2) in tqdm(zip(inputs, outputs), total=len(inputs)):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "    \n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "print('토큰화 및 필터링 진행 중...')\n",
    "questions_tokenized, answers_tokenized = tokenize_and_filter(questions_augmented, answers_augmented)\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions_tokenized)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers_tokenized)))\n",
    "\n",
    "# 토큰화된 데이터 저장\n",
    "np.save('questions_tokenized.npy', questions_tokenized)\n",
    "np.save('answers_tokenized.npy', answers_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46bd214",
   "metadata": {},
   "source": [
    "## Step 3. 모델 구성 및 개선\n",
    "\n",
    "### 더 깊은 레이어와 더 큰 모델 차원\n",
    "\n",
    "### 드롭아웃 비율 조정\n",
    "\n",
    "### 임베딩 레이어 분리 및 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e32e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding, [1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output, attention_weights\n",
    "\n",
    "# 멀티헤드 어텐션 레이어 (개선: 어텐션 가중치 반환 추가)\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                    (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# 패딩 마스크 생성 함수\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# 룩어헤드 마스크 생성 함수\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "\n",
    "# 개선된 인코더 레이어 (드롭아웃 비율 조정 가능)\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 개선된 인코더 (임베딩 레이어 분리)\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 개선된 디코더 레이어\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "\n",
    "# 개선된 디코더\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "\n",
    "# 개선된 트랜스포머 모델\n",
    "def improved_transformer(vocab_size,\n",
    "                        num_layers,\n",
    "                        units,\n",
    "                        d_model,\n",
    "                        num_heads,\n",
    "                        dropout,\n",
    "                        name=\"improved_transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 출력층 앞에 추가 레이어 (성능 향상)\n",
    "    dec_outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(dec_outputs)\n",
    "    dec_outputs = tf.keras.layers.Dropout(rate=dropout)(dec_outputs)\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6409c598",
   "metadata": {},
   "source": [
    "## Step 4. 모델 학습 + 검증 세트 도입\n",
    "\n",
    "### 검증 세트 도입\n",
    "\n",
    "### 조기 종료 \n",
    "\n",
    "### 모델 체크포인트\n",
    "\n",
    "### 학습률 동적 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad5729e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"improved_transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    12436480    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    16643072    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_20 (LayerNo (None, None, 512)    1024        decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, None, 512)    0           layer_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 7862)   4033206     dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 33,113,782\n",
      "Trainable params: 33,113,782\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "288/288 [==============================] - 65s 186ms/step - loss: 1.6779 - accuracy: 0.0257 - val_loss: 1.3361 - val_accuracy: 0.0474\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.33606, saving model to ./checkpoints/transformer/cp-0001.ckpt\n",
      "Epoch 2/20\n",
      "288/288 [==============================] - 51s 179ms/step - loss: 1.1796 - accuracy: 0.0528 - val_loss: 1.0949 - val_accuracy: 0.0775\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.33606 to 1.09490, saving model to ./checkpoints/transformer/cp-0002.ckpt\n",
      "Epoch 3/20\n",
      "288/288 [==============================] - 52s 179ms/step - loss: 1.0042 - accuracy: 0.0720 - val_loss: 0.9406 - val_accuracy: 0.0910\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.09490 to 0.94062, saving model to ./checkpoints/transformer/cp-0003.ckpt\n",
      "Epoch 4/20\n",
      "288/288 [==============================] - 51s 179ms/step - loss: 0.9068 - accuracy: 0.0806 - val_loss: 0.8656 - val_accuracy: 0.0994\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.94062 to 0.86558, saving model to ./checkpoints/transformer/cp-0004.ckpt\n",
      "Epoch 5/20\n",
      "288/288 [==============================] - 52s 179ms/step - loss: 0.8449 - accuracy: 0.0871 - val_loss: 0.8162 - val_accuracy: 0.1059\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.86558 to 0.81616, saving model to ./checkpoints/transformer/cp-0005.ckpt\n",
      "Epoch 6/20\n",
      "288/288 [==============================] - 52s 179ms/step - loss: 0.7983 - accuracy: 0.0922 - val_loss: 0.7676 - val_accuracy: 0.1112\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.81616 to 0.76761, saving model to ./checkpoints/transformer/cp-0006.ckpt\n",
      "Epoch 7/20\n",
      "288/288 [==============================] - 52s 179ms/step - loss: 0.7582 - accuracy: 0.0970 - val_loss: 0.7295 - val_accuracy: 0.1175\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.76761 to 0.72949, saving model to ./checkpoints/transformer/cp-0007.ckpt\n",
      "Epoch 8/20\n",
      "288/288 [==============================] - 52s 179ms/step - loss: 0.7213 - accuracy: 0.1011 - val_loss: 0.6928 - val_accuracy: 0.1230\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.72949 to 0.69282, saving model to ./checkpoints/transformer/cp-0008.ckpt\n",
      "Epoch 9/20\n",
      "288/288 [==============================] - 52s 179ms/step - loss: 0.6877 - accuracy: 0.1057 - val_loss: 0.6540 - val_accuracy: 0.1295\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.69282 to 0.65399, saving model to ./checkpoints/transformer/cp-0009.ckpt\n",
      "Epoch 10/20\n",
      "288/288 [==============================] - 52s 179ms/step - loss: 0.6569 - accuracy: 0.1095 - val_loss: 0.6312 - val_accuracy: 0.1332\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.65399 to 0.63120, saving model to ./checkpoints/transformer/cp-0010.ckpt\n",
      "Epoch 11/20\n",
      "288/288 [==============================] - 51s 179ms/step - loss: 0.6286 - accuracy: 0.1133 - val_loss: 0.6025 - val_accuracy: 0.1403\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.63120 to 0.60252, saving model to ./checkpoints/transformer/cp-0011.ckpt\n",
      "Epoch 12/20\n",
      "288/288 [==============================] - 51s 179ms/step - loss: 0.6026 - accuracy: 0.1170 - val_loss: 0.5844 - val_accuracy: 0.1409\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.60252 to 0.58439, saving model to ./checkpoints/transformer/cp-0012.ckpt\n",
      "Epoch 13/20\n",
      "288/288 [==============================] - 51s 178ms/step - loss: 0.5800 - accuracy: 0.1200 - val_loss: 0.5678 - val_accuracy: 0.1449\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.58439 to 0.56779, saving model to ./checkpoints/transformer/cp-0013.ckpt\n",
      "Epoch 14/20\n",
      "288/288 [==============================] - 51s 179ms/step - loss: 0.5642 - accuracy: 0.1222 - val_loss: 0.5619 - val_accuracy: 0.1457\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.56779 to 0.56192, saving model to ./checkpoints/transformer/cp-0014.ckpt\n",
      "Epoch 15/20\n",
      "288/288 [==============================] - 51s 179ms/step - loss: 0.5420 - accuracy: 0.1253 - val_loss: 0.5498 - val_accuracy: 0.1499\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.56192 to 0.54981, saving model to ./checkpoints/transformer/cp-0015.ckpt\n",
      "Epoch 16/20\n",
      "288/288 [==============================] - 51s 179ms/step - loss: 0.5170 - accuracy: 0.1291 - val_loss: 0.5277 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.54981 to 0.52770, saving model to ./checkpoints/transformer/cp-0016.ckpt\n",
      "Epoch 17/20\n",
      "288/288 [==============================] - 51s 178ms/step - loss: 0.4917 - accuracy: 0.1330 - val_loss: 0.5247 - val_accuracy: 0.1537\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.52770 to 0.52466, saving model to ./checkpoints/transformer/cp-0017.ckpt\n",
      "Epoch 18/20\n",
      "288/288 [==============================] - 51s 178ms/step - loss: 0.4686 - accuracy: 0.1366 - val_loss: 0.5117 - val_accuracy: 0.1581\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.52466 to 0.51172, saving model to ./checkpoints/transformer/cp-0018.ckpt\n",
      "Epoch 19/20\n",
      "288/288 [==============================] - 51s 178ms/step - loss: 0.4497 - accuracy: 0.1396 - val_loss: 0.4986 - val_accuracy: 0.1594\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.51172 to 0.49861, saving model to ./checkpoints/transformer/cp-0019.ckpt\n",
      "Epoch 20/20\n",
      "288/288 [==============================] - 51s 178ms/step - loss: 0.4304 - accuracy: 0.1430 - val_loss: 0.4847 - val_accuracy: 0.1628\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.49861 to 0.48471, saving model to ./checkpoints/transformer/cp-0020.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 준비\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 데이터셋 분할 (검증 세트 추가)\n",
    "train_size = int(0.9 * len(questions_tokenized))\n",
    "\n",
    "# 학습 데이터셋\n",
    "train_questions = questions_tokenized[:train_size]\n",
    "train_answers = answers_tokenized[:train_size]\n",
    "\n",
    "# 검증 데이터셋\n",
    "val_questions = questions_tokenized[train_size:]\n",
    "val_answers = answers_tokenized[train_size:]\n",
    "\n",
    "# 학습 데이터셋 생성\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': train_questions,\n",
    "        'dec_inputs': train_answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': train_answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# 검증 데이터셋 생성\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': val_questions,\n",
    "        'dec_inputs': val_answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': val_answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# 모델 하이퍼파라미터 설정\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터 (개선: 더 깊은 레이어와 더 큰 모델 차원)\n",
    "NUM_LAYERS = 4  # 인코더와 디코더의 층의 개수 (2→4)\n",
    "D_MODEL = 512   # 인코더와 디코더 내부의 입, 출력의 고정 차원 (256→512)\n",
    "NUM_HEADS = 8   # 멀티 헤드 어텐션에서의 헤드 수\n",
    "UNITS = 1024    # 피드 포워드 신경망의 은닉층의 크기 (512→1024)\n",
    "DROPOUT = 0.2   # 드롭아웃의 비율 (0.1→0.2)\n",
    "\n",
    "# 손실 함수\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# 커스텀 학습률 스케줄 (학습률 동적 조정)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# 학습률 설정\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# 정확도 함수\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# 모델 생성\n",
    "model = improved_transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()\n",
    "\n",
    "# 콜백 정의 (조기 종료 및 모델 체크포인트)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint_path = \"./checkpoints/transformer/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 체크포인트 콜백 생성\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss')\n",
    "\n",
    "# 학습률 감소 콜백\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping, cp_callback, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 학습 결과 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 최종 모델 저장\n",
    "model.save_weights('./checkpoints/transformer/final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f872aa",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가 + 빔 서치 디코딩 구현\n",
    "\n",
    "### 빔 서치 디코딩 구현\n",
    "\n",
    "### 대화 맥락을 고려한 응답 생성\n",
    "\n",
    "### BLEU 점수 도입 (객관적 평가 지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43fd73b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 테스트 문장 평가 =====\n",
      "입력 : 안녕하세요\n",
      "출력 (그리디 디코딩) : 저 도 요 .\n",
      "출력 (빔 서치) : 저 랑 한 잔 해요 .\n",
      "입력 : 오늘 날씨가 어때요?\n",
      "출력 (그리디 디코딩) : 건강 에 좋 은 습관 이 네요 .\n",
      "출력 (빔 서치) : 맛있 는 거 드세요 .\n",
      "입력 : 내일 시간 있으세요?\n",
      "출력 (그리디 디코딩) : 저 도 요 !\n",
      "출력 (빔 서치) : 저 랑 놀 아요 .\n",
      "입력 : 영화 보러 갈래요?\n",
      "출력 (그리디 디코딩) : 친구 가 좋 아 하 나 봐요 .\n",
      "출력 (빔 서치) : 친구 한테 부탁 해 보 세요 .\n",
      "입력 : 맛있는 음식점 추천해주세요\n",
      "출력 (그리디 디코딩) : 같이 갈 친구 가 있 으면 좋 겠 네요 .\n",
      "출력 (빔 서치) : 축하 해요 !\n",
      "모델 평가 중...\n",
      "입력 : 죽을거 같네\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 내일 시험이야\n",
      "출력 (그리디 디코딩) : 건강 에 좋 은 습관 이 네요 .\n",
      "입력 : 정말.내 자신이 싫다\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 이별후 네달째\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 한가 봐요 .\n",
      "입력 : 쌍커풀 해볼까\n",
      "출력 (그리디 디코딩) : 건강 에 좋 은 습관 이 네요 .\n",
      "입력 : 내 생각 하나만 바꾸면 편할텐데.\n",
      "출력 (그리디 디코딩) : 저 도 요 !\n",
      "입력 : 어떻게 살아가야 할까\n",
      "출력 (그리디 디코딩) : 저 도 궁금 하 네요 .\n",
      "입력 : 발 아파\n",
      "출력 (그리디 디코딩) : 비 가 오 려나요 .\n",
      "입력 : 썸 타는 것도 귀찮아.\n",
      "출력 (그리디 디코딩) : 썸 타 는 중 인데 사귀 는 사이 로 바쁘 면 될까요 ?\n",
      "입력 : 좋아하는 애랑 전화하면\n",
      "출력 (그리디 디코딩) : 사람 마다 정도 는 다르 지만 사귀 고 난 후 가 좋 겠 어요 .\n",
      "평가 진행: 10/100\n",
      "입력 : 뿌염해야지\n",
      "출력 (그리디 디코딩) : 저 도 밥 먹 고 싶 어요\n",
      "입력 : 여행 왔는데 좋아하는 선물로 뭐가 괜찮을까?\n",
      "출력 (그리디 디코딩) : 먼저 다가가 보 세요 .\n",
      "입력 : 괜찮아졌는줄 알았는데. . .\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 한가 봐요 .\n",
      "입력 : 오늘 너무 피곤해\n",
      "출력 (그리디 디코딩) : 오늘 은 쉬 면서 보 세요 .\n",
      "입력 : 애정운 궁금하다\n",
      "출력 (그리디 디코딩) : 저 도 궁금 하 네요 .\n",
      "입력 : 콩깍지 언제 벗겨져?\n",
      "출력 (그리디 디코딩) : 사람 마다 정도 는 다르 지만 사귀 고 난 후 가 좋 겠 어요 .\n",
      "입력 : 남자친구가 적극적이지가 않아.\n",
      "출력 (그리디 디코딩) : 사람 마다 정도 는 다르 지만 사귀 고 난 후 가 좋 겠 어요 .\n",
      "입력 : 이제 택시타지 말아야지\n",
      "출력 (그리디 디코딩) : 저 도 요 .\n",
      "입력 : 나 혼자 야근해\n",
      "출력 (그리디 디코딩) : 건강 에 좋 은 습관 이 네요 .\n",
      "입력 : 기침도 못하겠어\n",
      "출력 (그리디 디코딩) : 시간 이 흐르 는 것 처럼 마음 도 흘러갈 거 예요 .\n",
      "평가 진행: 20/100\n",
      "입력 : 절친인데 쌩깠어\n",
      "출력 (그리디 디코딩) : 맛있 게 드세요 .\n",
      "입력 : 완벽해지는 방법\n",
      "출력 (그리디 디코딩) : 오늘 은 그냥 뒹굴 뒹글 같이 놀 아요 .\n",
      "입력 : 가스비 너무 많이 나왔다.\n",
      "출력 (그리디 디코딩) : 술 만 먹 으면 연락 안 되 는 거 아니 에요 .\n",
      "입력 : 셀카 잘 찍는 방법\n",
      "출력 (그리디 디코딩) : 저 도 요 .\n",
      "입력 : 전 제가 찬건 줄 알았는데\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 눈물 나올라 그래\n",
      "출력 (그리디 디코딩) : 시간 이 흐르 는 것 처럼 마음 도 흘러갈 거 예요 .\n",
      "입력 : 변기 막혔는데 아무 생각이 안 난다.\n",
      "출력 (그리디 디코딩) : 건강 에 좋 은 습관 이 네요 .\n",
      "입력 : 포기해야할까?\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 이혼을 준비중인 부부라면\n",
      "출력 (그리디 디코딩) : 사랑 하 는 사람 이 있 으면 헤어짐 이 있 으니까요 .\n",
      "입력 : 잘 살고 싶어\n",
      "출력 (그리디 디코딩) : 저 도 요 .\n",
      "평가 진행: 30/100\n",
      "입력 : 놀러가고싶다!\n",
      "출력 (그리디 디코딩) : 저 도 요 !\n",
      "입력 : 수도가 얼었나봐\n",
      "출력 (그리디 디코딩) : 저 도 요 .\n",
      "입력 : 마음 정리가 되네.\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 한가 봐요 .\n",
      "입력 : 화 잘 내는 법\n",
      "출력 (그리디 디코딩) : 저 도 보 고 싶 어요 .\n",
      "입력 : 잊자 잊자 지워버리자\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 한가 봐요 .\n",
      "입력 : 이 좀 여유롭게 살고 싶다\n",
      "출력 (그리디 디코딩) : 사랑 은 알 기 힘들 어요 .\n",
      "입력 : 우산이 없는데 빌릴까\n",
      "출력 (그리디 디코딩) : 저 도 보 고 싶 어요 .\n",
      "입력 : 이게 사람 얼굴인지.\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 근황이 궁금해\n",
      "출력 (그리디 디코딩) : 당신 의 사랑 을 인정 하 게 해 보 세요 .\n",
      "입력 : 노메이크업인데 전남친 만남\n",
      "출력 (그리디 디코딩) : 저 도 그러 면 돼요 .\n",
      "평가 진행: 40/100\n",
      "입력 : 잊어볼 마음에 다른 여자 만나고왔습니다.\n",
      "출력 (그리디 디코딩) : 사랑 은 알 기 힘들 어요 .\n",
      "입력 : 커피 없으면 집중이 안돼\n",
      "출력 (그리디 디코딩) : 오늘 은 쉬 면서 보 세요 .\n",
      "입력 : 저금통 깰까\n",
      "출력 (그리디 디코딩) : 같이 가 보 세요 .\n",
      "입력 : 주차할데 없어서 짜증나\n",
      "출력 (그리디 디코딩) : 저 도 밥 을 먹 고 있 어요 .\n",
      "입력 : 잘안되는군\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 오늘은 그녀를 만나기로 약속한 날\n",
      "출력 (그리디 디코딩) : 마음 의 준비 가 필요 한가 봐요 .\n",
      "입력 : 이게 뭐라고 떨려\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 머 좀 물을게\n",
      "출력 (그리디 디코딩) : 저 도 요 .\n",
      "입력 : 택시비 너무 비싸\n",
      "출력 (그리디 디코딩) : 저 도 요 !\n",
      "입력 : 숙취 때문에 지끈거려\n",
      "출력 (그리디 디코딩) : 저 도 요 !\n",
      "평가 진행: 50/100\n",
      "입력 : 짝남 전여친 못잊는거 보는게 너무 맘이 아파.\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 첫사랑 생각만해도 아련해\n",
      "출력 (그리디 디코딩) : 사랑 은 알 기 힘들 어요 .\n",
      "입력 : 예쁜데 연애 안하는 여자\n",
      "출력 (그리디 디코딩) : 나 한테 만 부리 면 좋 아요 .\n",
      "입력 : 일 하면서 알게 된 사람한테 연락해도 될까?\n",
      "출력 (그리디 디코딩) : 사람 마다 정도 는 다르 지만 사귀 고 난 후 가 좋 겠 어요 .\n",
      "입력 : 요즘 내가 내가 아닌 거 같아\n",
      "출력 (그리디 디코딩) : 마음 이 따뜻 할 것 같 아요 .\n",
      "입력 : 사내커플인데 비밀연애하니까 더 떨려.\n",
      "출력 (그리디 디코딩) : 사랑 하 는 사람 과 함께 있 는 게 아니 라 서로 에게 너무 힘들 어 하 는 게 맘 이 에요 .\n",
      "입력 : 참 무섭네 사람 마음이란게\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 쇼핑했더니 힘드네\n",
      "출력 (그리디 디코딩) : 저 도 보 고 싶 어요 .\n",
      "입력 : 일만 하다 죽을 것 같아\n",
      "출력 (그리디 디코딩) : 저 도 밥 을 먹 고 있 어요 .\n",
      "입력 : 점점 괜찮아 지는것 같다가도.\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 한가 봐요 .\n",
      "평가 진행: 60/100\n",
      "입력 : 몰래 sns 훔쳐보고 있는 나 한심해\n",
      "출력 (그리디 디코딩) : 같이 가 보 세요 .\n",
      "입력 : 말할 때 너무 떨려\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 이제 내 짝남 못봐. 군대 가거든.\n",
      "출력 (그리디 디코딩) : 사랑 은 유지 하 는 게 중요 한데 대단 하 네요 .\n",
      "입력 : 어장인거 아는데도 좋아해.\n",
      "출력 (그리디 디코딩) : 사랑 에 나이 는 중요 하 지 않 아요 .\n",
      "입력 : 성덕 되면 내 마음도 편해 지겠지\n",
      "출력 (그리디 디코딩) : 저 도 궁금 하 네요 .\n",
      "입력 : 좋은 사람들은 다 어디 갔을까\n",
      "출력 (그리디 디코딩) : 같이 갈 친구 가 있 으면 좋 겠 네요 .\n",
      "입력 : 아직도 힘들지만.\n",
      "출력 (그리디 디코딩) : 시간 이 흐르 는 것 처럼 마음 도 흘러갈 거 예요 .\n",
      "입력 : 할줄 아는 게 없어\n",
      "출력 (그리디 디코딩) : 저 도 보 고 싶 어요 .\n",
      "입력 : 임용 결과 발표 기다리고 있어\n",
      "출력 (그리디 디코딩) : 같이 갈 때 같이 가요 .\n",
      "입력 : 공시생인데 연애 해도 될까?\n",
      "출력 (그리디 디코딩) : 친구 가 좋 아 하 나 봐요 .\n",
      "평가 진행: 70/100\n",
      "입력 : 어젯밤 꿈에나타났습니다\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 한가 봐요 .\n",
      "입력 : 나만 기다렸나봐\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 머리 어떻게 깎을까?\n",
      "출력 (그리디 디코딩) : 오늘 은 쉬 면서 보 세요 .\n",
      "입력 : 학원에 좋아하는 여자애가 있는데 말 거는 방법 좀.\n",
      "출력 (그리디 디코딩) : 직접 물 어 보 는 게 좋 을 것 같 아요 .\n",
      "입력 : 맨날 똑같애\n",
      "출력 (그리디 디코딩) : 저 도 궁금 하 네요 .\n",
      "입력 : 갑작스럽게 연락이 왔네.\n",
      "출력 (그리디 디코딩) : 당신 이 잘 알 고 있 을 거 예요 .\n",
      "입력 : 썸 사이에서 원래 질투유발하고 그래?\n",
      "출력 (그리디 디코딩) : 썸 에서 연인 으로 성공 하 길 바라 요 .\n",
      "입력 : 어디까지 가야 끝이보일지\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 4년 연애 후 이별 6개월. 새로운 시작을 하는 전여친. 너무 힘들어.\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 한가 봐요 .\n",
      "입력 : 화 참을 때 어떻게 하지?\n",
      "출력 (그리디 디코딩) : 저 도 보 고 싶 어요 .\n",
      "평가 진행: 80/100\n",
      "입력 : 짝남한테 게임 초대 톡 왔음.\n",
      "출력 (그리디 디코딩) : 당신 이 잘 돼야 성덕 이 될 수 있 을 거 예요 .\n",
      "입력 : 비행기 타러 공항 간다\n",
      "출력 (그리디 디코딩) : 잘 하 실 거 예요 !\n",
      "입력 : 결혼식 또 가야돼\n",
      "출력 (그리디 디코딩) : 같이 갈 때 같이 가요 .\n",
      "입력 : 메뉴얼이 있으면 뭐해\n",
      "출력 (그리디 디코딩) : 먹 으면서 다이어트 하 는 분 들 진짜 엄청 대단 한 분 들 이 에요 .\n",
      "입력 : 뭐라고 하고 싶었는데 참았어\n",
      "출력 (그리디 디코딩) : 저 도 궁금 하 네요 .\n",
      "입력 : 새로운 사랑을 시작하기에 앞서서.\n",
      "출력 (그리디 디코딩) : 사랑 은 알 다가 도 모르 는 게 아니 라 아니 에요 .\n",
      "입력 : 냄새 나면 어쩌지?\n",
      "출력 (그리디 디코딩) : 맛있 게 드세요 .\n",
      "입력 : 새 남자가 생겼대\n",
      "출력 (그리디 디코딩) : 저 도 요 .\n",
      "입력 : 당당하기가 어려워\n",
      "출력 (그리디 디코딩) : 사랑 은 유지 하 는 게 중요 한데 대단 하 네요 .\n",
      "입력 : 정장 사야겠지\n",
      "출력 (그리디 디코딩) : 저 도 요 .\n",
      "평가 진행: 90/100\n",
      "입력 : 첫사랑 부모님 반대로 이별했습니다.\n",
      "출력 (그리디 디코딩) : 사랑 했 던 사람 이 니까요 .\n",
      "입력 : 답이 안와\n",
      "출력 (그리디 디코딩) : 당신 의 사랑 을 인정 하 게 만들 길 바랍니다 .\n",
      "입력 : 누군가를 좋아한다는건 정말 힘들일이야.\n",
      "출력 (그리디 디코딩) : 사랑 하 는 사람 이 있 으면 이별 하 는 건 어떻 게 잊 는 거 예요 .\n",
      "입력 : 월급 받아서 주택청약 들었어\n",
      "출력 (그리디 디코딩) : 저 도 요 !\n",
      "입력 : 유부녀를 좋아하게 되었어.\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요 .\n",
      "입력 : 편안하게 살고 싶다.\n",
      "출력 (그리디 디코딩) : 저 도 밥 을 먹 고 싶 어요 .\n",
      "입력 : 독학하려니까 힘들어\n",
      "출력 (그리디 디코딩) : 저 도 보 고 싶 어요 .\n",
      "입력 : 오늘 지각인듯 뭐라 그러지\n",
      "출력 (그리디 디코딩) : 공부 좋 죠 .\n",
      "입력 : 헤어진지 3주\n",
      "출력 (그리디 디코딩) : 시간 이 흐르 는 것 처럼 마음 도 흘러갈 거 예요 .\n",
      "입력 : 너무 빨리 철 들었어\n",
      "출력 (그리디 디코딩) : 저 도 밥 먹 고 싶 어요 .\n",
      "평가 진행: 100/100\n",
      "\n",
      "===== 평가 결과 =====\n",
      "그리디 디코딩 평균 BLEU-1: 0.0017\n",
      "그리디 디코딩 평균 BLEU-2: 0.0006\n",
      "빔 서치 디코딩 평균 BLEU-1: 0.0041\n",
      "빔 서치 디코딩 평균 BLEU-2: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44536 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47532 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 46356 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 48724 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 52824 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51216 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49688 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 48708 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44368 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44536 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47532 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 46356 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 48724 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 52824 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51216 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49688 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 48708 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44368 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 대화 인터페이스 =====\n",
      "챗봇과 대화를 시작합니다. '종료'를 입력하면 대화가 종료됩니다.\n",
      "사용자: 안녕 내 이름은 류지호야.\n",
      "챗봇: 돈 버 는 게 쉽 지 않 아요 .\n",
      "사용자: 맞아. 돈 버는게 쉽지 않지. 그래서 나는 취업을 위해 AI에 대해 공부하고 있어.\n",
      "챗봇: 내 가 좋 아 하 는 사람 이 나 좋 아 하 는 것 같 아\n",
      "사용자: 연애와 결혼도 취업만큼이나 중요하지. 넌 돈 버는 것만큼이나 연애에도 관심이 많구나?\n",
      "챗봇: 잘 하 실 거 예요 !\n",
      "사용자: 내 걱정 말고 너나 잘해. 넌 더 똑똑해질 필요가 있어보여.\n",
      "챗봇: 전 여친 생일 이 야\n",
      "사용자: 갑자기?\n",
      "챗봇: 사랑 에 빠졌 나 봐요 .\n",
      "대화가 종료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# NLTK 다운로드\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 빔 서치를 활용한 향상된 문장 생성 함수\n",
    "def beam_search_decoder(sentence, beam_width=5, max_length=MAX_LENGTH):\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_korean_text(sentence)\n",
    "    \n",
    "    # 형태소 분석 적용\n",
    "    sentence = morpheme_tokenize(sentence)\n",
    "    \n",
    "    # 정수 인코딩 후 시작 토큰과 종료 토큰 추가\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "    \n",
    "    # 초기 상태: 시작 토큰\n",
    "    initial_state = tf.expand_dims(START_TOKEN, 0)\n",
    "    \n",
    "    # 초기 빔: [(시퀀스, 점수)]\n",
    "    beams = [(initial_state, 0.0)]\n",
    "    \n",
    "    # 빔 서치 반복\n",
    "    for _ in range(max_length):\n",
    "        candidates = []\n",
    "        \n",
    "        # 현재 빔의 각 시퀀스에 대해\n",
    "        for seq, score in beams:\n",
    "            # 종료 토큰이 이미 있으면 후보에 추가하고 계속\n",
    "            if END_TOKEN[0] in seq[0][1:]:\n",
    "                candidates.append((seq, score))\n",
    "                continue\n",
    "            \n",
    "            # 모델 예측\n",
    "            predictions = model(inputs=[sentence, seq], training=False)\n",
    "            predictions = predictions[:, -1, :]\n",
    "            \n",
    "            # 상위 beam_width개 토큰 선택\n",
    "            top_k_values, top_k_indices = tf.nn.top_k(\n",
    "                tf.nn.softmax(predictions[0]), k=beam_width)\n",
    "            \n",
    "            # 각 후보에 대해\n",
    "            for i in range(beam_width):\n",
    "                # 새 토큰 추가\n",
    "                new_seq = tf.concat([seq, tf.reshape(top_k_indices[i], (1, 1))], axis=-1)\n",
    "                # 로그 확률 합산 (점수)\n",
    "                new_score = score + tf.math.log(top_k_values[i])\n",
    "                candidates.append((new_seq, new_score))\n",
    "        \n",
    "        # 후보들 중 상위 beam_width개 선택\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        beams = candidates[:beam_width]\n",
    "        \n",
    "        # 모든 빔이 종료 토큰을 가지면 중단\n",
    "        if all(END_TOKEN[0] in seq[0][1:] for seq, _ in beams):\n",
    "            break\n",
    "    \n",
    "    # 최고 점수 시퀀스 선택\n",
    "    best_seq, _ = beams[0]\n",
    "    \n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환\n",
    "    best_seq = tf.squeeze(best_seq, axis=0)\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in best_seq if i < tokenizer.vocab_size and i != START_TOKEN[0]])\n",
    "    \n",
    "    return predicted_sentence\n",
    "\n",
    "# 기존 디코더 추론 함수 (비교용)\n",
    "def decoder_inference(sentence):\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_korean_text(sentence)\n",
    "    \n",
    "    # 형태소 분석 적용\n",
    "    sentence = morpheme_tokenize(sentence)\n",
    "    \n",
    "    # 정수 인코딩 후 시작 토큰과 종료 토큰 추가\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "    \n",
    "    # 디코더의 현재까지 예측한 출력 시퀀스\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "    \n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        \n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        \n",
    "        # 현재 예측한 단어가 종료 토큰이면 for문 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "            \n",
    "        # 예측한 단어를 output_sequence에 추가\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "    \n",
    "    return tf.squeeze(output_sequence, axis=0)\n",
    "\n",
    "# 기존 문장 생성 함수 (비교용)\n",
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해 디코더를 동작시켜 예측된 정수 시퀀스를 리턴받음\n",
    "    prediction = decoder_inference(sentence)\n",
    "    \n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size and i != START_TOKEN[0]])\n",
    "    \n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 (그리디 디코딩) : {}'.format(predicted_sentence))\n",
    "    \n",
    "    return predicted_sentence\n",
    "\n",
    "# 향상된 문장 생성 함수 (빔 서치 사용)\n",
    "def improved_sentence_generation(sentence):\n",
    "    # 그리디 디코딩 결과\n",
    "    greedy_result = sentence_generation(sentence)\n",
    "    \n",
    "    # 빔 서치 디코딩 결과\n",
    "    beam_result = beam_search_decoder(sentence, beam_width=5)\n",
    "    \n",
    "    print('출력 (빔 서치) : {}'.format(beam_result))\n",
    "    \n",
    "    return beam_result\n",
    "\n",
    "# BLEU 점수 계산 함수\n",
    "def calculate_bleu(reference, candidate):\n",
    "    # 토큰화\n",
    "    reference_tokens = reference.split()\n",
    "    candidate_tokens = candidate.split()\n",
    "    \n",
    "    # BLEU 점수 계산 (스무딩 적용)\n",
    "    smoothie = SmoothingFunction().method1\n",
    "    try:\n",
    "        bleu1 = sentence_bleu([reference_tokens], candidate_tokens, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "        bleu2 = sentence_bleu([reference_tokens], candidate_tokens, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie)\n",
    "    except:\n",
    "        bleu1, bleu2 = 0, 0\n",
    "    \n",
    "    return bleu1, bleu2\n",
    "\n",
    "# 대화 맥락을 고려한 챗봇 인터페이스\n",
    "def interactive_chat(max_turns=5):\n",
    "    # 대화 기록\n",
    "    conversation_history = []\n",
    "    \n",
    "    print(\"챗봇과 대화를 시작합니다. '종료'를 입력하면 대화가 종료됩니다.\")\n",
    "    \n",
    "    for turn in range(max_turns):\n",
    "        # 사용자 입력\n",
    "        user_input = input(\"사용자: \")\n",
    "        \n",
    "        if user_input.lower() == '종료':\n",
    "            print(\"대화를 종료합니다.\")\n",
    "            break\n",
    "        \n",
    "        # 대화 기록에 사용자 입력 추가\n",
    "        conversation_history.append(user_input)\n",
    "        \n",
    "        # 최근 대화 맥락 구성 (최대 3턴)\n",
    "        if len(conversation_history) > 1:\n",
    "            context = \" \".join(conversation_history[-3:])\n",
    "        else:\n",
    "            context = user_input\n",
    "        \n",
    "        # 챗봇 응답 생성 (빔 서치 사용)\n",
    "        bot_response = beam_search_decoder(context)\n",
    "        \n",
    "        # 대화 기록에 챗봇 응답 추가\n",
    "        conversation_history.append(bot_response)\n",
    "        \n",
    "        print(f\"챗봇: {bot_response}\")\n",
    "    \n",
    "    print(\"대화가 종료되었습니다.\")\n",
    "\n",
    "# 모델 평가\n",
    "def evaluate_model():\n",
    "    # 테스트 세트 생성 (원본 데이터에서 랜덤 샘플링)\n",
    "    np.random.seed(42)\n",
    "    test_indices = np.random.choice(len(data), 100, replace=False)\n",
    "    test_questions = [data.loc[i, 'Q'] for i in test_indices]\n",
    "    test_answers = [data.loc[i, 'A'] for i in test_indices]\n",
    "    \n",
    "    # 평가 지표 저장\n",
    "    greedy_bleu1_scores = []\n",
    "    greedy_bleu2_scores = []\n",
    "    beam_bleu1_scores = []\n",
    "    beam_bleu2_scores = []\n",
    "    \n",
    "    print(\"모델 평가 중...\")\n",
    "    \n",
    "    for i, (question, reference) in enumerate(zip(test_questions, test_answers)):\n",
    "        # 그리디 디코딩\n",
    "        greedy_result = sentence_generation(question)\n",
    "        \n",
    "        # 빔 서치 디코딩\n",
    "        beam_result = beam_search_decoder(question)\n",
    "        \n",
    "        # BLEU 점수 계산\n",
    "        greedy_bleu1, greedy_bleu2 = calculate_bleu(reference, greedy_result)\n",
    "        beam_bleu1, beam_bleu2 = calculate_bleu(reference, beam_result)\n",
    "        \n",
    "        greedy_bleu1_scores.append(greedy_bleu1)\n",
    "        greedy_bleu2_scores.append(greedy_bleu2)\n",
    "        beam_bleu1_scores.append(beam_bleu1)\n",
    "        beam_bleu2_scores.append(beam_bleu2)\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"평가 진행: {i+1}/100\")\n",
    "    \n",
    "    # 결과 요약\n",
    "    print(\"\\n===== 평가 결과 =====\")\n",
    "    print(f\"그리디 디코딩 평균 BLEU-1: {np.mean(greedy_bleu1_scores):.4f}\")\n",
    "    print(f\"그리디 디코딩 평균 BLEU-2: {np.mean(greedy_bleu2_scores):.4f}\")\n",
    "    print(f\"빔 서치 디코딩 평균 BLEU-1: {np.mean(beam_bleu1_scores):.4f}\")\n",
    "    print(f\"빔 서치 디코딩 평균 BLEU-2: {np.mean(beam_bleu2_scores):.4f}\")\n",
    "    \n",
    "    # 결과 시각화\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(['그리디 BLEU-1', '빔 서치 BLEU-1'], \n",
    "            [np.mean(greedy_bleu1_scores), np.mean(beam_bleu1_scores)])\n",
    "    plt.title('BLEU-1 점수 비교')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(['그리디 BLEU-2', '빔 서치 BLEU-2'], \n",
    "            [np.mean(greedy_bleu2_scores), np.mean(beam_bleu2_scores)])\n",
    "    plt.title('BLEU-2 점수 비교')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 테스트 문장으로 모델 평가\n",
    "test_sentences = [\n",
    "    '안녕하세요',\n",
    "    '오늘 날씨가 어때요?',\n",
    "    '내일 시간 있으세요?',\n",
    "    '영화 보러 갈래요?',\n",
    "    '맛있는 음식점 추천해주세요'\n",
    "]\n",
    "\n",
    "print(\"\\n===== 테스트 문장 평가 =====\")\n",
    "for test_sentence in test_sentences:\n",
    "    improved_sentence_generation(test_sentence)\n",
    "\n",
    "# 전체 모델 평가 실행\n",
    "evaluate_model()\n",
    "\n",
    "# 대화 인터페이스 실행\n",
    "print(\"\\n===== 대화 인터페이스 =====\")\n",
    "interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
