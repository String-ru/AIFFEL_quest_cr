{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0ac89d",
   "metadata": {},
   "source": [
    "# 프로젝트: 한국어 데이터로 챗봇 만들기 C1 류지호"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3553ecd",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집 및 전처리 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5e3cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.9/site-packages (from konlpy) (1.21.4)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (4.6.3)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.16.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (2.26.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.11.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.19)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.0.17->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "데이터셋 크기 : 11823\n",
      "데이터셋 구성 : Index(['Q', 'A', 'label'], dtype='object')\n",
      "데이터셋 미리보기 :\n",
      "                 Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n",
      "Mecab 형태소 분석기를 사용합니다.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac1a25d7691461fb64ff64a5ea01969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/76.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8f7c6b8941466585955e2deb254985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/263 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2593fe3c70646e2a43f3e1a28d77eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7feec7228aa4ce0a3c4a625bcac3a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/352M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT 모델 로드 성공\n",
      "형태소 분석 및 임베딩 추출 진행 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11823/11823 [01:54<00:00, 103.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 분석 완료!\n",
      "형태소 분석 후 질문 샘플: ['12 시 땡 !', '1 지망 학교 떨어졌 어', '3 박 4 일 놀 러 가 고 싶 다', '3 박 4 일 정도 놀 러 가 고 싶 다', 'PPL 심하 네']\n",
      "형태소 분석 후 답변 샘플: ['하루 가 또 가 네요 .', '위로 해 드립니다 .', '여행 은 언제나 좋 죠 .', '여행 은 언제나 좋 죠 .', '눈살 이 찌푸려 지 죠 .']\n",
      "임베딩 추출 완료: 1183 질문, 1183 답변\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "\n",
    "# KoNLPy 형태소 분석기 설치\n",
    "!pip install konlpy\n",
    "!pip install transformers\n",
    "\n",
    "from konlpy.tag import Mecab, Okt\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# 데이터 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatbotData.csv\")\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('ChatbotData.csv')\n",
    "print('데이터셋 크기 :', len(data))\n",
    "print('데이터셋 구성 :', data.columns)\n",
    "print('데이터셋 미리보기 :')\n",
    "print(data.head())\n",
    "\n",
    "# 형태소 분석기 초기화 (Mecab이 없으면 Okt 사용)\n",
    "try:\n",
    "    mecab = Mecab()\n",
    "    print(\"Mecab 형태소 분석기를 사용합니다.\")\n",
    "    morpheme_analyzer = mecab\n",
    "    \n",
    "    def tokenize_morphemes(text):\n",
    "        return mecab.morphs(text)\n",
    "        \n",
    "    def get_pos_tags(text):\n",
    "        return mecab.pos(text)\n",
    "except:\n",
    "    okt = Okt()\n",
    "    print(\"Okt 형태소 분석기를 사용합니다.\")\n",
    "    morpheme_analyzer = okt\n",
    "    \n",
    "    def tokenize_morphemes(text):\n",
    "        return okt.morphs(text)\n",
    "        \n",
    "    def get_pos_tags(text):\n",
    "        return okt.pos(text)\n",
    "\n",
    "# 개선된 한국어 전처리 함수 (신조어, 이모티콘 처리 강화)\n",
    "def preprocess_korean_text(sentence):\n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # 한글 자모 분리 현상 교정 (ㅋㅋㅋ, ㅎㅎㅎ 등의 처리)\n",
    "    jamo_pattern = r'[ㄱ-ㅎㅏ-ㅣ]{2,}'\n",
    "    sentence = re.sub(jamo_pattern, lambda x: x.group(0)[:2], sentence)\n",
    "    \n",
    "    # 이모티콘 정규화 (더 다양한 이모티콘 처리)\n",
    "    sentence = re.sub(r'[ㅋ]{2,}', 'ㅋㅋ', sentence)\n",
    "    sentence = re.sub(r'[ㅎ]{2,}', 'ㅎㅎ', sentence)\n",
    "    sentence = re.sub(r'[ㅜㅠ]{2,}', 'ㅜㅜ', sentence)\n",
    "    sentence = re.sub(r'[ㅡ]{2,}', 'ㅡㅡ', sentence)\n",
    "    \n",
    "    # URL 제거\n",
    "    sentence = re.sub(r'https?://\\S+|www\\.\\S+', '[URL]', sentence)\n",
    "    \n",
    "    # 이메일 제거\n",
    "    sentence = re.sub(r'\\S+@\\S+', '[EMAIL]', sentence)\n",
    "    \n",
    "    # 특수문자 제거 및 공백 정리 (한글, 영어, 숫자, 일부 특수문자만 유지)\n",
    "    sentence = re.sub(r\"[^가-힣a-zA-Z0-9?.!,~]+\", \" \", sentence)\n",
    "    \n",
    "    # 여러 공백을 하나의 공백으로 대체\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # 구두점 앞에 공백 추가\n",
    "    sentence = re.sub(r\"([?.!,~])\", r\" \\1 \", sentence)\n",
    "    \n",
    "    # 다시 여러 공백을 하나의 공백으로 대체\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # 신조어 및 축약어 처리 (예시)\n",
    "    slang_dict = {\n",
    "        '갑툭튀': '갑자기 툭 튀어나온',\n",
    "        '꾸안꾸': '꾸민 듯 안 꾸민 듯',\n",
    "        '별다줄': '별 다른 줄거리',\n",
    "        '억텐': '억지 텐션',\n",
    "        '완내스': '완전 내 스타일',\n",
    "        '좋댓구알': '좋아요 댓글 구독 알림설정',\n",
    "        '케바케': '케이스 바이 케이스',\n",
    "        # 추가 신조어 사전\n",
    "    }\n",
    "    \n",
    "    for slang, meaning in slang_dict.items():\n",
    "        if slang in sentence:\n",
    "            sentence = sentence.replace(slang, meaning)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# 품사 정보를 활용한 향상된 형태소 분석 함수\n",
    "def enhanced_morpheme_tokenize(sentence):\n",
    "    # 전처리 적용\n",
    "    preprocessed = preprocess_korean_text(sentence)\n",
    "    \n",
    "    # 품사 태깅\n",
    "    pos_tagged = get_pos_tags(preprocessed)\n",
    "    \n",
    "    # 중요 품사에 가중치 부여 (명사, 동사, 형용사 등)\n",
    "    important_pos = ['NNG', 'NNP', 'VV', 'VA', 'MAG']  # 일반명사, 고유명사, 동사, 형용사, 부사\n",
    "    \n",
    "    # 형태소와 품사 정보 결합\n",
    "    morphemes_with_pos = []\n",
    "    for word, pos in pos_tagged:\n",
    "        if pos in important_pos:\n",
    "            # 중요 품사는 그대로 유지\n",
    "            morphemes_with_pos.append(word)\n",
    "        else:\n",
    "            # 덜 중요한 품사는 그대로 추가\n",
    "            morphemes_with_pos.append(word)\n",
    "    \n",
    "    # 형태소를 공백으로 구분하여 결합\n",
    "    return ' '.join(morphemes_with_pos)\n",
    "\n",
    "# 의미론적 임베딩 추출 함수 (BERT 기반)\n",
    "def load_bert_model():\n",
    "    try:\n",
    "        # KoBERT 모델 로드 (또는 다른 한국어 BERT 모델)\n",
    "        tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
    "        bert_model = BertModel.from_pretrained('monologg/kobert')\n",
    "        print(\"BERT 모델 로드 성공\")\n",
    "        return tokenizer, bert_model\n",
    "    except:\n",
    "        print(\"BERT 모델 로드 실패, 임베딩 기능은 비활성화됩니다.\")\n",
    "        return None, None\n",
    "\n",
    "# BERT 모델 로드 시도\n",
    "bert_tokenizer, bert_model = load_bert_model()\n",
    "\n",
    "def get_semantic_embedding(text):\n",
    "    if bert_model is None or bert_tokenizer is None:\n",
    "        # BERT 모델이 없으면 간단한 대체 임베딩 반환\n",
    "        return np.zeros((1, 768))\n",
    "    \n",
    "    try:\n",
    "        inputs = bert_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        outputs = bert_model(**inputs)\n",
    "        return outputs.last_hidden_state[:, 0, :].detach().numpy()  # [CLS] 토큰 임베딩\n",
    "    except:\n",
    "        print(f\"임베딩 추출 실패: {text}\")\n",
    "        return np.zeros((1, 768))\n",
    "\n",
    "# 질문과 답변 데이터 전처리 및 형태소 분석\n",
    "questions_morpheme = []\n",
    "answers_morpheme = []\n",
    "question_embeddings = []\n",
    "answer_embeddings = []\n",
    "\n",
    "print('형태소 분석 및 임베딩 추출 진행 중...')\n",
    "for i in tqdm(range(len(data))):\n",
    "    # 향상된 형태소 분석 적용\n",
    "    q_morpheme = enhanced_morpheme_tokenize(data.loc[i, 'Q'])\n",
    "    a_morpheme = enhanced_morpheme_tokenize(data.loc[i, 'A'])\n",
    "    \n",
    "    questions_morpheme.append(q_morpheme)\n",
    "    answers_morpheme.append(a_morpheme)\n",
    "    \n",
    "    # 의미 임베딩 추출 (BERT 기반, 10% 샘플링)\n",
    "    if i % 10 == 0 and bert_model is not None:\n",
    "        q_embedding = get_semantic_embedding(data.loc[i, 'Q'])\n",
    "        a_embedding = get_semantic_embedding(data.loc[i, 'A'])\n",
    "        question_embeddings.append((i, q_embedding))\n",
    "        answer_embeddings.append((i, a_embedding))\n",
    "\n",
    "print('형태소 분석 완료!')\n",
    "print('형태소 분석 후 질문 샘플:', questions_morpheme[:5])\n",
    "print('형태소 분석 후 답변 샘플:', answers_morpheme[:5])\n",
    "print(f'임베딩 추출 완료: {len(question_embeddings)} 질문, {len(answer_embeddings)} 답변')\n",
    "\n",
    "# 형태소 분석 결과 저장 (나중에 재사용 가능)\n",
    "with open('morpheme_data.pkl', 'wb') as f:\n",
    "    pickle.dump((questions_morpheme, answers_morpheme), f)\n",
    "\n",
    "# 임베딩 결과 저장\n",
    "if len(question_embeddings) > 0:\n",
    "    with open('embedding_data.pkl', 'wb') as f:\n",
    "        pickle.dump((question_embeddings, answer_embeddings), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a5a3a",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 증강 및 토큰화 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fafac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증강 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "순서 뒤집기 증강: 100%|██████████| 11823/11823 [00:00<00:00, 506224.61it/s]\n",
      "유사 표현 증강: 100%|██████████| 11823/11823 [00:00<00:00, 1064147.13it/s]\n",
      "동의어 대체 증강: 100%|██████████| 11823/11823 [00:00<00:00, 2000534.78it/s]\n",
      "주제 분류: 100%|██████████| 11823/11823 [00:00<00:00, 86357.23it/s]\n",
      "주제 기반 증강: 100%|██████████| 7/7 [00:00<00:00, 10407.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 크기: 11823\n",
      "증강 후 데이터 크기: 20716\n",
      "토크나이저 생성 중... (시간이 다소 소요될 수 있습니다)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 11890\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 5945\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 2972\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 1486\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 743\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 371\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 185\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 92\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 46\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 23\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 11\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 5\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 2\n",
      "INFO:absl:SubwordTextEncoder build: trying min_token_count 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 7887\n",
      "START_TOKEN의 번호 : [7885]\n",
      "END_TOKEN의 번호 : [7886]\n",
      "원문 : 12 시 땡 !\n",
      "토큰화 : [3140, 173, 6093, 115]\n",
      "디코딩 결과 : 12 시 땡 !\n",
      "토큰화 및 필터링 진행 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "토큰화 및 필터링: 100%|██████████| 20716/20716 [00:00<00:00, 25186.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링 후의 질문 샘플 개수: 20716\n",
      "필터링 후의 답변 샘플 개수: 20716\n"
     ]
    }
   ],
   "source": [
    "# 주제 분류기 구현\n",
    "def topic_classifier(text):\n",
    "    # 주제별 키워드 정의\n",
    "    topics = {\n",
    "        '학업': ['시험', '공부', '학교', '숙제', '성적', '교수', '학생', '강의'],\n",
    "        '건강': ['아프다', '병원', '운동', '다이어트', '피곤', '건강', '약', '치료'],\n",
    "        '연애': ['좋아해', '사랑', '고백', '썸', '이별', '남자친구', '여자친구', '연인'],\n",
    "        '일상': ['밥', '날씨', '쇼핑', '영화', '여행', '취미', '휴식', '주말'],\n",
    "        '감정': ['기쁘다', '슬프다', '화나다', '불안', '걱정', '우울', '행복', '스트레스'],\n",
    "        '직장': ['회사', '업무', '상사', '동료', '퇴근', '출근', '프로젝트', '이직']\n",
    "    }\n",
    "    \n",
    "    # 형태소 분석 적용\n",
    "    morphemes = enhanced_morpheme_tokenize(text)\n",
    "    \n",
    "    # 주제 점수 계산\n",
    "    topic_scores = {}\n",
    "    for topic, keywords in topics.items():\n",
    "        score = sum(1 for word in morphemes.split() if any(keyword in word for keyword in keywords))\n",
    "        topic_scores[topic] = score\n",
    "    \n",
    "    # 가장 높은 점수의 주제 반환\n",
    "    return max(topic_scores.items(), key=lambda x: x[1])[0] if any(topic_scores.values()) else '일반'\n",
    "\n",
    "# 감정 분석 함수\n",
    "def analyze_emotion(text):\n",
    "    # 감정 키워드 정의\n",
    "    emotions = {\n",
    "        '기쁨': ['좋아', '행복', '신나', '즐거워', '기뻐', '웃', '신남', '좋았'],\n",
    "        '슬픔': ['슬퍼', '우울', '힘들어', '아파', '눈물', '울', '서럽', '그리움'],\n",
    "        '분노': ['화나', '짜증', '열받아', '미쳐', '짜증나', '화가', '분노', '억울'],\n",
    "        '불안': ['걱정', '불안', '긴장', '두려워', '무서워', '겁나', '조마조마', '떨려'],\n",
    "        '중립': ['그냥', '보통', '평범', '일상', '특별하지않아', '괜찮', '그저', '별거']\n",
    "    }\n",
    "    \n",
    "    # 형태소 분석 적용\n",
    "    morphemes = enhanced_morpheme_tokenize(text)\n",
    "    \n",
    "    # 감정 점수 계산\n",
    "    emotion_scores = {}\n",
    "    for emotion, keywords in emotions.items():\n",
    "        score = sum(1 for word in morphemes.split() if any(keyword in word for keyword in keywords))\n",
    "        emotion_scores[emotion] = score\n",
    "    \n",
    "    # 가장 높은 점수의 감정 반환\n",
    "    return max(emotion_scores.items(), key=lambda x: x[1])[0] if any(emotion_scores.values()) else '중립'\n",
    "\n",
    "# 개선된 데이터 증강 함수 (주제 및 감정 기반)\n",
    "def augment_data(questions, answers):\n",
    "    augmented_questions = questions.copy()\n",
    "    augmented_answers = answers.copy()\n",
    "    \n",
    "    print(\"데이터 증강 시작...\")\n",
    "    \n",
    "    # 1. 일부 질문-답변 쌍의 순서를 뒤집어 데이터 증강\n",
    "    for i in tqdm(range(len(questions)), desc=\"순서 뒤집기 증강\"):\n",
    "        # 복잡한 문장만 선택하여 증강 (단어 수가 3개 이상인 경우)\n",
    "        if len(questions[i].split()) > 3 and len(answers[i].split()) > 3:\n",
    "            # 답변이 질문이 될 수 있는 경우만 선택\n",
    "            if not any(word in answers[i] for word in ['?', '까', '니까', '세요']):\n",
    "                augmented_questions.append(answers[i])\n",
    "                augmented_answers.append(questions[i])\n",
    "    \n",
    "    # 2. 유사 표현 추가 (일부 질문에 대해)\n",
    "    question_prefixes = ['저는 ', '제가 ', '나는 ', '내가 ']\n",
    "    for i in tqdm(range(len(questions)), desc=\"유사 표현 증강\"):\n",
    "        original_q = questions[i]\n",
    "        # 첫 단어가 '나' 또는 '저'로 시작하는 경우에만 적용\n",
    "        if any(original_q.startswith(prefix) for prefix in ['나', '저']):\n",
    "            for prefix in question_prefixes:\n",
    "                if not original_q.startswith(prefix):\n",
    "                    # 새로운 질문 생성\n",
    "                    new_q = prefix + original_q[2:] if original_q[1] == ' ' else prefix + original_q[1:]\n",
    "                    augmented_questions.append(new_q)\n",
    "                    augmented_answers.append(answers[i])\n",
    "    \n",
    "    # 3. 백 트랜슬레이션 시뮬레이션 (실제 번역 API 없이 간단한 변형)\n",
    "    synonyms = {\n",
    "        '좋아': ['마음에 들어', '괜찮아', '훌륭해'],\n",
    "        '싫어': ['마음에 안 들어', '별로야', '안 좋아'],\n",
    "        '행복': ['기쁨', '즐거움', '좋은 기분'],\n",
    "        '슬픔': ['우울함', '서러움', '마음 아픔'],\n",
    "        '화나': ['짜증나', '열받아', '분노'],\n",
    "        '걱정': ['불안', '염려', '근심'],\n",
    "        '사랑': ['좋아함', '애정', '마음'],\n",
    "        '미워': ['싫어함', '증오', '반감']\n",
    "    }\n",
    "    \n",
    "    for i in tqdm(range(len(questions)), desc=\"동의어 대체 증강\"):\n",
    "        if i % 5 == 0:  # 20% 샘플링\n",
    "            q = questions[i]\n",
    "            a = answers[i]\n",
    "            \n",
    "            # 동의어 대체\n",
    "            for word, replacements in synonyms.items():\n",
    "                if word in q:\n",
    "                    for replacement in replacements:\n",
    "                        new_q = q.replace(word, replacement)\n",
    "                        augmented_questions.append(new_q)\n",
    "                        augmented_answers.append(a)\n",
    "                        break  # 하나의 대체어만 사용\n",
    "    \n",
    "    # 4. 주제 기반 데이터 증강 (같은 주제의 질문-답변 쌍 조합)\n",
    "    topic_data = {}\n",
    "    for i in tqdm(range(len(questions)), desc=\"주제 분류\"):\n",
    "        if i % 10 == 0:  # 10% 샘플링\n",
    "            topic = topic_classifier(questions[i])\n",
    "            if topic not in topic_data:\n",
    "                topic_data[topic] = []\n",
    "            topic_data[topic].append((questions[i], answers[i]))\n",
    "    \n",
    "    # 같은 주제 내에서 질문-답변 쌍 조합\n",
    "    for topic, qa_pairs in tqdm(topic_data.items(), desc=\"주제 기반 증강\"):\n",
    "        if len(qa_pairs) >= 2:\n",
    "            for _ in range(min(len(qa_pairs), 10)):  # 최대 10개 증강\n",
    "                idx1, idx2 = random.sample(range(len(qa_pairs)), 2)\n",
    "                q1, a1 = qa_pairs[idx1]\n",
    "                q2, a2 = qa_pairs[idx2]\n",
    "                \n",
    "                # 질문1-답변2 조합\n",
    "                augmented_questions.append(q1)\n",
    "                augmented_answers.append(a2)\n",
    "    \n",
    "    print(f\"원본 데이터 크기: {len(questions)}\")\n",
    "    print(f\"증강 후 데이터 크기: {len(augmented_questions)}\")\n",
    "    \n",
    "    return augmented_questions, augmented_answers\n",
    "\n",
    "# 데이터 증강 적용\n",
    "questions_augmented, answers_augmented = augment_data(questions_morpheme, answers_morpheme)\n",
    "\n",
    "# 토크나이저 생성 (개선: 더 큰 단어장 크기)\n",
    "print('토크나이저 생성 중... (시간이 다소 소요될 수 있습니다)')\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions_augmented + answers_augmented, target_vocab_size=2**14)  # 단어장 크기 2배 증가\n",
    "\n",
    "# 시작 토큰과 종료 토큰 정의\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2  # 시작 토큰과 종료 토큰을 고려하여 +2\n",
    "\n",
    "print('단어장의 크기 :', VOCAB_SIZE)\n",
    "print('START_TOKEN의 번호 :', START_TOKEN)\n",
    "print('END_TOKEN의 번호 :', END_TOKEN)\n",
    "\n",
    "# 토크나이저 테스트\n",
    "sample_string = questions_augmented[0]\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print('원문 :', sample_string)\n",
    "print('토큰화 :', tokenized_string)\n",
    "print('디코딩 결과 :', tokenizer.decode(tokenized_string))\n",
    "\n",
    "# 토크나이저 저장\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# 최대 문장 길이 설정 (증가)\n",
    "MAX_LENGTH = 50  # 40에서 50으로 증가\n",
    "\n",
    "# 정수 인코딩, 최대 길이 초과 샘플 제거, 패딩 적용\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "    for (sentence1, sentence2) in tqdm(zip(inputs, outputs), total=len(inputs), desc=\"토큰화 및 필터링\"):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "    \n",
    "    # 최대 길이로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    \n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "print('토큰화 및 필터링 진행 중...')\n",
    "questions_tokenized, answers_tokenized = tokenize_and_filter(questions_augmented, answers_augmented)\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions_tokenized)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers_tokenized)))\n",
    "\n",
    "# 토큰화된 데이터 저장\n",
    "np.save('questions_tokenized.npy', questions_tokenized)\n",
    "np.save('answers_tokenized.npy', answers_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd2ccf",
   "metadata": {},
   "source": [
    "## Step 3. 모델 아키텍처 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e7817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding, [1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# 스케일드 닷 프로덕트 어텐션 함수 (개선: 어텐션 가중치 반환)\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output, attention_weights\n",
    "\n",
    "# 멀티헤드 어텐션 레이어 (개선: 어텐션 가중치 반환 추가)\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                    (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# 패딩 마스크 생성 함수\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# 룩어헤드 마스크 생성 함수\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n",
    "\n",
    "# 개선된 인코더 레이어 (드롭아웃 비율 조정 가능)\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 개선된 인코더 (임베딩 레이어 분리)\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 개선된 디코더 레이어\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "\n",
    "# 개선된 디코더\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "    \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "\n",
    "# 개선된 트랜스포머 모델 (출력층 앞에 추가 레이어)\n",
    "def improved_transformer(vocab_size,\n",
    "                        num_layers,\n",
    "                        units,\n",
    "                        d_model,\n",
    "                        num_heads,\n",
    "                        dropout,\n",
    "                        name=\"improved_transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 출력층 앞에 추가 레이어 (성능 향상)\n",
    "    dec_outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(dec_outputs)\n",
    "    dec_outputs = tf.keras.layers.Dropout(rate=dropout)(dec_outputs)\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6232fd5",
   "metadata": {},
   "source": [
    "## Step 4. 모델 학습 및 평가 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8942be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"improved_transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    22952448    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    29262336    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_30 (LayerNo (None, None, 512)    1024        decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, None, 512)    0           layer_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 7887)   4046031     dropout_26[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 56,261,839\n",
      "Trainable params: 56,261,839\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "292/292 [==============================] - 129s 384ms/step - loss: 1.3151 - accuracy: 0.0242 - val_loss: 1.1226 - val_accuracy: 0.0431\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.12256, saving model to ./checkpoints/transformer/cp-0001.ckpt\n",
      "Epoch 2/30\n",
      "292/292 [==============================] - 109s 372ms/step - loss: 1.0969 - accuracy: 0.0396 - val_loss: 1.0207 - val_accuracy: 0.0513\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.12256 to 1.02073, saving model to ./checkpoints/transformer/cp-0002.ckpt\n",
      "Epoch 3/30\n",
      "292/292 [==============================] - 109s 371ms/step - loss: 1.0111 - accuracy: 0.0470 - val_loss: 0.9258 - val_accuracy: 0.0610\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.02073 to 0.92577, saving model to ./checkpoints/transformer/cp-0003.ckpt\n",
      "Epoch 4/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.9350 - accuracy: 0.0565 - val_loss: 0.8447 - val_accuracy: 0.0717\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.92577 to 0.84472, saving model to ./checkpoints/transformer/cp-0004.ckpt\n",
      "Epoch 5/30\n",
      "292/292 [==============================] - 109s 371ms/step - loss: 0.8795 - accuracy: 0.0621 - val_loss: 0.7966 - val_accuracy: 0.0776\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.84472 to 0.79663, saving model to ./checkpoints/transformer/cp-0005.ckpt\n",
      "Epoch 6/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.8395 - accuracy: 0.0659 - val_loss: 0.7691 - val_accuracy: 0.0796\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.79663 to 0.76908, saving model to ./checkpoints/transformer/cp-0006.ckpt\n",
      "Epoch 7/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.8070 - accuracy: 0.0690 - val_loss: 0.7308 - val_accuracy: 0.0854\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.76908 to 0.73077, saving model to ./checkpoints/transformer/cp-0007.ckpt\n",
      "Epoch 8/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.7790 - accuracy: 0.0719 - val_loss: 0.7043 - val_accuracy: 0.0883\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.73077 to 0.70426, saving model to ./checkpoints/transformer/cp-0008.ckpt\n",
      "Epoch 9/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.7556 - accuracy: 0.0741 - val_loss: 0.6788 - val_accuracy: 0.0911\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.70426 to 0.67876, saving model to ./checkpoints/transformer/cp-0009.ckpt\n",
      "Epoch 10/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.7341 - accuracy: 0.0764 - val_loss: 0.6581 - val_accuracy: 0.0935\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.67876 to 0.65811, saving model to ./checkpoints/transformer/cp-0010.ckpt\n",
      "Epoch 11/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.7146 - accuracy: 0.0784 - val_loss: 0.6367 - val_accuracy: 0.0960\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.65811 to 0.63666, saving model to ./checkpoints/transformer/cp-0011.ckpt\n",
      "Epoch 12/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.6952 - accuracy: 0.0806 - val_loss: 0.6166 - val_accuracy: 0.0985\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.63666 to 0.61659, saving model to ./checkpoints/transformer/cp-0012.ckpt\n",
      "Epoch 13/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.6771 - accuracy: 0.0826 - val_loss: 0.5996 - val_accuracy: 0.1012\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.61659 to 0.59962, saving model to ./checkpoints/transformer/cp-0013.ckpt\n",
      "Epoch 14/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.6596 - accuracy: 0.0846 - val_loss: 0.5818 - val_accuracy: 0.1029\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.59962 to 0.58184, saving model to ./checkpoints/transformer/cp-0014.ckpt\n",
      "Epoch 15/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.6420 - accuracy: 0.0868 - val_loss: 0.5613 - val_accuracy: 0.1056\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.58184 to 0.56135, saving model to ./checkpoints/transformer/cp-0015.ckpt\n",
      "Epoch 16/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.6260 - accuracy: 0.0885 - val_loss: 0.5421 - val_accuracy: 0.1087\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.56135 to 0.54208, saving model to ./checkpoints/transformer/cp-0016.ckpt\n",
      "Epoch 17/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.6099 - accuracy: 0.0905 - val_loss: 0.5269 - val_accuracy: 0.1121\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.54208 to 0.52687, saving model to ./checkpoints/transformer/cp-0017.ckpt\n",
      "Epoch 18/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.5933 - accuracy: 0.0926 - val_loss: 0.5117 - val_accuracy: 0.1136\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.52687 to 0.51170, saving model to ./checkpoints/transformer/cp-0018.ckpt\n",
      "Epoch 19/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.5776 - accuracy: 0.0948 - val_loss: 0.4975 - val_accuracy: 0.1157\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.51170 to 0.49755, saving model to ./checkpoints/transformer/cp-0019.ckpt\n",
      "Epoch 20/30\n",
      "292/292 [==============================] - 108s 370ms/step - loss: 0.5620 - accuracy: 0.0968 - val_loss: 0.4776 - val_accuracy: 0.1195\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.49755 to 0.47756, saving model to ./checkpoints/transformer/cp-0020.ckpt\n",
      "Epoch 21/30\n",
      "292/292 [==============================] - 108s 371ms/step - loss: 0.5462 - accuracy: 0.0988 - val_loss: 0.4637 - val_accuracy: 0.1215\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.47756 to 0.46369, saving model to ./checkpoints/transformer/cp-0021.ckpt\n",
      "Epoch 22/30\n",
      "292/292 [==============================] - 108s 370ms/step - loss: 0.5316 - accuracy: 0.1007 - val_loss: 0.4495 - val_accuracy: 0.1237\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.46369 to 0.44949, saving model to ./checkpoints/transformer/cp-0022.ckpt\n",
      "Epoch 23/30\n",
      "292/292 [==============================] - 108s 370ms/step - loss: 0.5175 - accuracy: 0.1027 - val_loss: 0.4369 - val_accuracy: 0.1256\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.44949 to 0.43692, saving model to ./checkpoints/transformer/cp-0023.ckpt\n",
      "Epoch 24/30\n",
      "292/292 [==============================] - 108s 370ms/step - loss: 0.5032 - accuracy: 0.1045 - val_loss: 0.4228 - val_accuracy: 0.1278\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.43692 to 0.42276, saving model to ./checkpoints/transformer/cp-0024.ckpt\n",
      "Epoch 25/30\n",
      "292/292 [==============================] - 108s 370ms/step - loss: 0.4897 - accuracy: 0.1064 - val_loss: 0.4129 - val_accuracy: 0.1293\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.42276 to 0.41287, saving model to ./checkpoints/transformer/cp-0025.ckpt\n",
      "Epoch 26/30\n",
      "292/292 [==============================] - 108s 370ms/step - loss: 0.4755 - accuracy: 0.1084 - val_loss: 0.4009 - val_accuracy: 0.1311\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.41287 to 0.40092, saving model to ./checkpoints/transformer/cp-0026.ckpt\n",
      "Epoch 27/30\n",
      "292/292 [==============================] - 108s 370ms/step - loss: 0.4628 - accuracy: 0.1102 - val_loss: 0.3907 - val_accuracy: 0.1334\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.40092 to 0.39068, saving model to ./checkpoints/transformer/cp-0027.ckpt\n",
      "Epoch 28/30\n",
      "292/292 [==============================] - 108s 370ms/step - loss: 0.4498 - accuracy: 0.1120 - val_loss: 0.3816 - val_accuracy: 0.1353\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.39068 to 0.38155, saving model to ./checkpoints/transformer/cp-0028.ckpt\n",
      "Epoch 29/30\n",
      "292/292 [==============================] - 108s 370ms/step - loss: 0.4380 - accuracy: 0.1136 - val_loss: 0.3736 - val_accuracy: 0.1363\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.38155 to 0.37358, saving model to ./checkpoints/transformer/cp-0029.ckpt\n",
      "Epoch 30/30\n",
      "292/292 [==============================] - 108s 370ms/step - loss: 0.4257 - accuracy: 0.1157 - val_loss: 0.3632 - val_accuracy: 0.1378\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.37358 to 0.36323, saving model to ./checkpoints/transformer/cp-0030.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 ./checkpoints/transformer/final_model에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 준비\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 데이터셋 분할 (검증 세트 추가)\n",
    "train_size = int(0.9 * len(questions_tokenized))\n",
    "\n",
    "# 학습 데이터셋\n",
    "train_questions = questions_tokenized[:train_size]\n",
    "train_answers = answers_tokenized[:train_size]\n",
    "\n",
    "# 검증 데이터셋\n",
    "val_questions = questions_tokenized[train_size:]\n",
    "val_answers = answers_tokenized[train_size:]\n",
    "\n",
    "# 학습 데이터셋 생성\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': train_questions,\n",
    "        'dec_inputs': train_answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': train_answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# 검증 데이터셋 생성\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': val_questions,\n",
    "        'dec_inputs': val_answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': val_answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# 모델 하이퍼파라미터 설정\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터 (개선: 더 깊은 레이어와 더 큰 모델 차원)\n",
    "NUM_LAYERS = 6  # 인코더와 디코더의 층의 개수 (4→6)\n",
    "D_MODEL = 512   # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8   # 멀티 헤드 어텐션에서의 헤드 수\n",
    "UNITS = 2048    # 피드 포워드 신경망의 은닉층의 크기 (1024→2048)\n",
    "DROPOUT = 0.2   # 드롭아웃의 비율\n",
    "\n",
    "# 가중치 손실 함수 (패딩 토큰에 낮은 가중치 부여)\n",
    "def weighted_loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    # 패딩 토큰(0)에는 낮은 가중치, 실제 토큰에는 높은 가중치\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    \n",
    "    # 가중치 조정 (실제 토큰에 1.2배 가중치)\n",
    "    weighted_mask = tf.where(mask > 0, 1.2 * mask, mask)\n",
    "    \n",
    "    loss = tf.multiply(loss, weighted_mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# 커스텀 학습률 스케줄 (완전히 수정된 부분)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "        # 0으로 나누기 방지를 위한 작은 상수\n",
    "        self.epsilon = 1e-7\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        # step을 float32로 명시적 변환\n",
    "        step = tf.maximum(tf.cast(step, tf.float32), self.epsilon)  # 0 방지\n",
    "        \n",
    "        # 안전한 제곱근 계산\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * tf.math.pow(self.warmup_steps, -1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "    # 직렬화 가능하도록 get_config 메서드 추가\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"d_model\": float(self.d_model),\n",
    "            \"warmup_steps\": float(self.warmup_steps),\n",
    "            \"epsilon\": float(self.epsilon)\n",
    "        }\n",
    "\n",
    "# 학습률 설정 - 고정 학습률로 변경\n",
    "# learning_rate = CustomSchedule(D_MODEL)\n",
    "learning_rate = 1e-4  # 고정 학습률 사용\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# 정확도 함수\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# 모델 생성\n",
    "model = improved_transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=optimizer, loss=weighted_loss_function, metrics=[accuracy])\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()\n",
    "\n",
    "# 콜백 정의 (조기 종료 및 모델 체크포인트)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 디렉토리 생성 확인\n",
    "import os\n",
    "checkpoint_dir = \"./checkpoints/transformer\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"cp-{epoch:04d}.ckpt\")\n",
    "\n",
    "# 체크포인트 콜백 생성\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss')\n",
    "\n",
    "# 학습률 감소 콜백 - 고정 학습률을 사용하므로 제거\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss',\n",
    "#     factor=0.2,\n",
    "#     patience=2,\n",
    "#     min_lr=1e-6\n",
    "# )\n",
    "\n",
    "# 텐서보드 콜백 완전 제거 (에러 발생 가능성 제거)\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "#     log_dir=\"./logs\"\n",
    "# )\n",
    "\n",
    "# 모델 학습 - 콜백 수정\n",
    "EPOCHS = 30\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[early_stopping, cp_callback],  # 문제 있는 콜백 제거\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 학습 결과 시각화\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='validation')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='validation')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 최종 모델 저장\n",
    "    final_model_path = os.path.join(checkpoint_dir, \"final_model\")\n",
    "    model.save_weights(final_model_path)\n",
    "    print(f\"모델이 {final_model_path}에 저장되었습니다.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"학습 중 오류 발생: {e}\")\n",
    "    \n",
    "    # 오류 발생 시 더 간단한 모델로 시도\n",
    "    print(\"더 간단한 모델로 다시 시도합니다...\")\n",
    "    \n",
    "    # 더 작은 모델 생성\n",
    "    SIMPLE_NUM_LAYERS = 2\n",
    "    SIMPLE_D_MODEL = 256\n",
    "    SIMPLE_UNITS = 512\n",
    "    \n",
    "    simple_model = improved_transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        num_layers=SIMPLE_NUM_LAYERS,\n",
    "        units=SIMPLE_UNITS,\n",
    "        d_model=SIMPLE_D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        dropout=DROPOUT)\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    simple_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        loss=weighted_loss_function,\n",
    "        metrics=[accuracy]\n",
    "    )\n",
    "    \n",
    "    # 간단한 모델 학습 (에포크 수 감소)\n",
    "    simple_history = simple_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=10,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[early_stopping, cp_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 간단한 모델 저장\n",
    "    simple_model.save_weights(os.path.join(checkpoint_dir, \"simple_final_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab0343",
   "metadata": {},
   "source": [
    "## BLEU 점수 (간단 편리)\n",
    "\n",
    "### 정량적 측정\n",
    "생성된 텍스트와 참조 텍스트 간의 n-gram 일치도를 수치화(가중 기하평균 사용)하여 정량적인 평가를 제공\n",
    "\n",
    "1-gram(unigram): 단일 단어 (예: \"나는\", \"학교에\", \"갔다\")\n",
    "\n",
    "2-gram(bigram): 연속된 두 단어 (예: \"나는 학교에\", \"학교에 갔다\")\n",
    "\n",
    "3-gram(trigram): 연속된 세 단어 (예: \"나는 학교에 갔다\")\n",
    "\n",
    "4-gram: 연속된 네 단어\n",
    "\n",
    "### n-gram 일치도 \n",
    "생성된 텍스트와 참조 텍스트 사이에 얼마나 많은 n-gram이 일치하는지를 계산\n",
    "\n",
    "### 재현성\n",
    "동일한 데이터셋과 모델에 대해 항상 같은 점수가 나옴\n",
    "\n",
    "### 쓸만한 챗봇의 BLEU 점수 기준\n",
    "일반적으로 챗봇이나 대화 시스템에서 BLEU 점수는 다음과 같이 해석됨\n",
    "\n",
    "0.0-0.1: 매우 낮은 품질, 참조 응답과 거의 일치하지 않음\n",
    "\n",
    "0.1-0.2: 낮은 품질, 기본적인 의미 전달에 어려움\n",
    "\n",
    "0.2-0.4: 중간 품질, 기본적인 의미는 전달 가능\n",
    "\n",
    "0.4-0.6: 양호한 품질, 의미 전달이 비교적 명확함\n",
    "\n",
    "0.6 이상: 높은 품질, 참조 응답과 상당히 유사함\n",
    "\n",
    "### n-gram 일치도의 한계\n",
    "단어 순서만 고려: 의미적 유사성은 고려하지 않음\n",
    "\n",
    "동의어 인식 불가: 같은 의미의 다른 단어는 불일치로 처리\n",
    "\n",
    "문맥 이해 부족: 더 넓은 문맥적 의미를 파악하지 못함\n",
    "\n",
    "참조 텍스트 의존성: 가능한 좋은 응답이 여러 개일 수 있음에도 참조 텍스트와 다르면 낮은 점수\n",
    "\n",
    "### 그리디 디코딩\n",
    "각 단계에서 가장 확률이 높은 단일 토큰만을 선택하는 방식\n",
    "\n",
    "### 빔 서치 디코딩 \n",
    "각 단계에서 상위 k개(빔 너비)의 가능한 토큰 시퀀스를 유지하며 탐색하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663be0be",
   "metadata": {},
   "source": [
    "## Step 5. 추론 및 대화 인터페이스 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8d15f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /aiffel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 테스트 문장 평가 =====\n",
      "입력 : 안녕하세요\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "출력 (빔 서치) : 축하 해요!\n",
      "입력 : 오늘 날씨가 어때요?\n",
      "출력 (그리디 디코딩) : 건강 에 안 좋 아요.\n",
      "출력 (빔 서치) : 감기 조심 하 세요.\n",
      "입력 : 내일 시간 있으세요?\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "출력 (빔 서치) : 축하 해요!\n",
      "입력 : 영화 보러 갈래요?\n",
      "출력 (그리디 디코딩) : 직접 물 어 보 세요.\n",
      "출력 (빔 서치) : 직접 물 어 보 세요.\n",
      "입력 : 맛있는 음식점 추천해주세요\n",
      "출력 (그리디 디코딩) : 좋 은 생각 이에요.\n",
      "출력 (빔 서치) : 좋 은 생각 이에요.\n",
      "모델 평가 중...\n",
      "입력 : 죽을거 같네\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 한가 봐요.\n",
      "입력 : 내일 시험이야\n",
      "출력 (그리디 디코딩) : 다음 에 는 우산 에 이름 이랑 연락처 를 적 어 보 세요.\n",
      "입력 : 정말.내 자신이 싫다\n",
      "출력 (그리디 디코딩) : 당신 의 마음 이 좀 더 정리 되 었 길 바랍니다.\n",
      "입력 : 이별후 네달째\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요.\n",
      "입력 : 쌍커풀 해볼까\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 내 생각 하나만 바꾸면 편할텐데.\n",
      "출력 (그리디 디코딩) : 잘 하 고 있 어요.\n",
      "입력 : 어떻게 살아가야 할까\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 발 아파\n",
      "출력 (그리디 디코딩) : 맛있 게 드세요.\n",
      "입력 : 썸 타는 것도 귀찮아.\n",
      "출력 (그리디 디코딩) : 연락 해보 세요.\n",
      "입력 : 좋아하는 애랑 전화하면\n",
      "출력 (그리디 디코딩) : 직접 물 어 보 세요.\n",
      "평가 진행: 10/100\n",
      "입력 : 뿌염해야지\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 여행 왔는데 좋아하는 선물로 뭐가 괜찮을까?\n",
      "출력 (그리디 디코딩) : 직접 물 어 보 세요.\n",
      "입력 : 괜찮아졌는줄 알았는데. . .\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 오늘 너무 피곤해\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 애정운 궁금하다\n",
      "출력 (그리디 디코딩) : 안 해도 괜찮 을 거 예요.\n",
      "입력 : 콩깍지 언제 벗겨져?\n",
      "출력 (그리디 디코딩) : 사랑 은 알 수 없 어요.\n",
      "입력 : 남자친구가 적극적이지가 않아.\n",
      "출력 (그리디 디코딩) : 직접 물 어 보 세요.\n",
      "입력 : 이제 택시타지 말아야지\n",
      "출력 (그리디 디코딩) : 좋 은 생각 이에요.\n",
      "입력 : 나 혼자 야근해\n",
      "출력 (그리디 디코딩) : 축하 해요!\n",
      "입력 : 기침도 못하겠어\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "평가 진행: 20/100\n",
      "입력 : 절친인데 쌩깠어\n",
      "출력 (그리디 디코딩) : 건강 에 좋 겠 네요.\n",
      "입력 : 완벽해지는 방법\n",
      "출력 (그리디 디코딩) : 오늘 도 고생 이 많 았 어요.\n",
      "입력 : 가스비 너무 많이 나왔다.\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 셀카 잘 찍는 방법\n",
      "출력 (그리디 디코딩) : 좋 은 생각 이에요.\n",
      "입력 : 전 제가 찬건 줄 알았는데\n",
      "출력 (그리디 디코딩) : 사랑 했 던 사람 이 니까요.\n",
      "입력 : 눈물 나올라 그래\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 변기 막혔는데 아무 생각이 안 난다.\n",
      "출력 (그리디 디코딩) : 축하 해요!\n",
      "입력 : 포기해야할까?\n",
      "출력 (그리디 디코딩) : 사랑 했 던 사람 이 니까요.\n",
      "입력 : 이혼을 준비중인 부부라면\n",
      "출력 (그리디 디코딩) : 사랑 하는 사람 이 있 는데 결혼 하 기 힘들 어요.\n",
      "입력 : 잘 살고 싶어\n",
      "출력 (그리디 디코딩) : 잘 하 고 있 어요.\n",
      "평가 진행: 30/100\n",
      "입력 : 놀러가고싶다!\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 수도가 얼었나봐\n",
      "출력 (그리디 디코딩) : 마음 의 준비 를 하 세요.\n",
      "입력 : 마음 정리가 되네.\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요.\n",
      "입력 : 화 잘 내는 법\n",
      "출력 (그리디 디코딩) : 좋 은 생각 이에요.\n",
      "입력 : 잊자 잊자 지워버리자\n",
      "출력 (그리디 디코딩) : 잘 하 고 있 어요.\n",
      "입력 : 이 좀 여유롭게 살고 싶다\n",
      "출력 (그리디 디코딩) : 사랑 했 던 사람 이 니까요.\n",
      "입력 : 우산이 없는데 빌릴까\n",
      "출력 (그리디 디코딩) : 좋 은 생각 이에요.\n",
      "입력 : 이게 사람 얼굴인지.\n",
      "출력 (그리디 디코딩) : 마음 의 준비 를 하 세요.\n",
      "입력 : 근황이 궁금해\n",
      "출력 (그리디 디코딩) : 안 해도 괜찮 을 거 예요.\n",
      "입력 : 노메이크업인데 전남친 만남\n",
      "출력 (그리디 디코딩) : 마음 의 준비 를 하 세요.\n",
      "평가 진행: 40/100\n",
      "입력 : 잊어볼 마음에 다른 여자 만나고왔습니다.\n",
      "출력 (그리디 디코딩) : 사랑 은 변하 고 사람 이 니까요.\n",
      "입력 : 커피 없으면 집중이 안돼\n",
      "출력 (그리디 디코딩) : 돈 을 얼른 모아야 할 이유 가 생겼 네요.\n",
      "입력 : 저금통 깰까\n",
      "출력 (그리디 디코딩) : 좋 은 생각 이에요.\n",
      "입력 : 주차할데 없어서 짜증나\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 잘안되는군\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요.\n",
      "입력 : 오늘은 그녀를 만나기로 약속한 날\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 이게 뭐라고 떨려\n",
      "출력 (그리디 디코딩) : 마음 의 준비 를 하 세요.\n",
      "입력 : 머 좀 물을게\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 택시비 너무 비싸\n",
      "출력 (그리디 디코딩) : 마음 에 드 는 걸로 하 세요.\n",
      "입력 : 숙취 때문에 지끈거려\n",
      "출력 (그리디 디코딩) : 축하 해요!\n",
      "평가 진행: 50/100\n",
      "입력 : 짝남 전여친 못잊는거 보는게 너무 맘이 아파.\n",
      "출력 (그리디 디코딩) : 당신 이 잘 돼야 보 세요.\n",
      "입력 : 첫사랑 생각만해도 아련해\n",
      "출력 (그리디 디코딩) : 사랑 은 변하 고 사람 이 니까요.\n",
      "입력 : 예쁜데 연애 안하는 여자\n",
      "출력 (그리디 디코딩) : 사랑 하는 사람 이 있 는데 결혼 하 기 힘들 어요.\n",
      "입력 : 일 하면서 알게 된 사람한테 연락해도 될까?\n",
      "출력 (그리디 디코딩) : 사귀 기 전 에 감정 을 확인 하는 게 필요 하 죠.\n",
      "입력 : 요즘 내가 내가 아닌 거 같아\n",
      "출력 (그리디 디코딩) : 마음 의 준비 를 하 세요.\n",
      "입력 : 사내커플인데 비밀연애하니까 더 떨려.\n",
      "출력 (그리디 디코딩) : 저도 밥 먹 고 싶 어요\n",
      "입력 : 참 무섭네 사람 마음이란게\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요.\n",
      "입력 : 쇼핑했더니 힘드네\n",
      "출력 (그리디 디코딩) : 다음 에 는 받 을 수있 을 거 예요.\n",
      "입력 : 일만 하다 죽을 것 같아\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 점점 괜찮아 지는것 같다가도.\n",
      "출력 (그리디 디코딩) : 이별 은 상처 를 남겨서 마음 이 아프 네요.\n",
      "평가 진행: 60/100\n",
      "입력 : 몰래 sns 훔쳐보고 있는 나 한심해\n",
      "출력 (그리디 디코딩) : 마음 의 준비 를 하 세요.\n",
      "입력 : 말할 때 너무 떨려\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요.\n",
      "입력 : 이제 내 짝남 못봐. 군대 가거든.\n",
      "출력 (그리디 디코딩) : 사랑 은 알 수 없 어요.\n",
      "입력 : 어장인거 아는데도 좋아해.\n",
      "출력 (그리디 디코딩) : 사랑 은 변하 고 사람 이 니까요.\n",
      "입력 : 성덕 되면 내 마음도 편해 지겠지\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요.\n",
      "입력 : 좋은 사람들은 다 어디 갔을까\n",
      "출력 (그리디 디코딩) : 좋 은 생각 이에요.\n",
      "입력 : 아직도 힘들지만.\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 한가 봐요.\n",
      "입력 : 할줄 아는 게 없어\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 임용 결과 발표 기다리고 있어\n",
      "출력 (그리디 디코딩) : 축하 해요!\n",
      "입력 : 공시생인데 연애 해도 될까?\n",
      "출력 (그리디 디코딩) : 서로 에게 부담 없 는 선물 이 좋 아요.\n",
      "평가 진행: 70/100\n",
      "입력 : 어젯밤 꿈에나타났습니다\n",
      "출력 (그리디 디코딩) : 마음 이 복잡 하 겠 어요.\n",
      "입력 : 나만 기다렸나봐\n",
      "출력 (그리디 디코딩) : 사랑 했 던 사람 이 니까요.\n",
      "입력 : 머리 어떻게 깎을까?\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 학원에 좋아하는 여자애가 있는데 말 거는 방법 좀.\n",
      "출력 (그리디 디코딩) : 직접 물 어 보 세요.\n",
      "입력 : 맨날 똑같애\n",
      "출력 (그리디 디코딩) : 마음 의 준비 를 하 세요.\n",
      "입력 : 갑작스럽게 연락이 왔네.\n",
      "출력 (그리디 디코딩) : 사랑 은 알 수 없 어요.\n",
      "입력 : 썸 사이에서 원래 질투유발하고 그래?\n",
      "출력 (그리디 디코딩) : 서로 에게 부담 없 는 선물 이 좋 아요.\n",
      "입력 : 어디까지 가야 끝이보일지\n",
      "출력 (그리디 디코딩) : 사랑 했 던 시간 이 있 으니까요.\n",
      "입력 : 4년 연애 후 이별 6개월. 새로운 시작을 하는 전여친. 너무 힘들어.\n",
      "출력 (그리디 디코딩) : 사랑 했 던 사람 이 니까요.\n",
      "입력 : 화 참을 때 어떻게 하지?\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "평가 진행: 80/100\n",
      "입력 : 짝남한테 게임 초대 톡 왔음.\n",
      "출력 (그리디 디코딩) : 직접 물 어 보 세요.\n",
      "입력 : 비행기 타러 공항 간다\n",
      "출력 (그리디 디코딩) : 잘 하 고 있 어요.\n",
      "입력 : 결혼식 또 가야돼\n",
      "출력 (그리디 디코딩) : 건강 에 좋 겠 네요.\n",
      "입력 : 메뉴얼이 있으면 뭐해\n",
      "출력 (그리디 디코딩) : 오늘 은 쉬 세요.\n",
      "입력 : 뭐라고 하고 싶었는데 참았어\n",
      "출력 (그리디 디코딩) : 마음 의 준비 를 하 세요.\n",
      "입력 : 새로운 사랑을 시작하기에 앞서서.\n",
      "출력 (그리디 디코딩) : 사랑 은 알 수 없 어요.\n",
      "입력 : 냄새 나면 어쩌지?\n",
      "출력 (그리디 디코딩) : 맛있 게 드세요.\n",
      "입력 : 새 남자가 생겼대\n",
      "출력 (그리디 디코딩) : 좋 은 친구 를 두 셨 네요.\n",
      "입력 : 당당하기가 어려워\n",
      "출력 (그리디 디코딩) : 마음 의 준비 를 하 세요.\n",
      "입력 : 정장 사야겠지\n",
      "출력 (그리디 디코딩) : 감기 조심 하 세요.\n",
      "평가 진행: 90/100\n",
      "입력 : 첫사랑 부모님 반대로 이별했습니다.\n",
      "출력 (그리디 디코딩) : 사랑 했 던 시간 이 있 으니까요.\n",
      "입력 : 답이 안와\n",
      "출력 (그리디 디코딩) : 마음 에 드 는 걸로 하 세요.\n",
      "입력 : 누군가를 좋아한다는건 정말 힘들일이야.\n",
      "출력 (그리디 디코딩) : 사랑 하는 사람 이 있 는데 결혼 하 기 힘들 어요.\n",
      "입력 : 월급 받아서 주택청약 들었어\n",
      "출력 (그리디 디코딩) : 건강 에 좋 겠 네요.\n",
      "입력 : 유부녀를 좋아하게 되었어.\n",
      "출력 (그리디 디코딩) : 마음 의 준비 를 하 세요.\n",
      "입력 : 편안하게 살고 싶다.\n",
      "출력 (그리디 디코딩) : 저도 좋 아 해요.\n",
      "입력 : 독학하려니까 힘들어\n",
      "출력 (그리디 디코딩) : 마음 에 드 는 걸로 하 세요.\n",
      "입력 : 오늘 지각인듯 뭐라 그러지\n",
      "출력 (그리디 디코딩) : 안 됐 네요.\n",
      "입력 : 헤어진지 3주\n",
      "출력 (그리디 디코딩) : 잘 하 고 있 어요.\n",
      "입력 : 너무 빨리 철 들었어\n",
      "출력 (그리디 디코딩) : 돈 을 얼른 모아야 할 이유 가 생겼 네요.\n",
      "평가 진행: 100/100\n",
      "\n",
      "===== 평가 결과 =====\n",
      "그리디 디코딩 평균 BLEU-1: 0.0060\n",
      "그리디 디코딩 평균 BLEU-2: 0.0021\n",
      "빔 서치 디코딩 평균 BLEU-1: 0.0060\n",
      "빔 서치 디코딩 평균 BLEU-2: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44536 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 47532 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 46356 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 48724 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 52824 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51216 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49688 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 48708 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44368 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44536 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 47532 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 46356 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 48724 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 52824 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51216 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49688 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 48708 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44368 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 대화 인터페이스 =====\n",
      "챗봇과 대화를 시작합니다. '종료'를 입력하면 대화가 종료됩니다.\n",
      "사용자: 금요일이어서 공부하기 싫어.\n",
      "챗봇: 마음 의 준비 를 하 세요.\n",
      "사용자: 그래... 그래도 열심히 해야지. 마음을 다잡아 볼게.\n",
      "챗봇: 마음 이 복잡 하 겠 어요.\n",
      "사용자: 그래서 방금 사람들과 잠시 게임을 했어!ㅋㅋ\n",
      "챗봇: 잘 하 고 있 어요.\n",
      "사용자: 오 너 아까보다 많이 똑똑해졌다잉~? 보람이 있네.\n",
      "챗봇: 잘 하 고 있 어요.\n",
      "사용자: 아니구나 내 착각이었어. 1+1이 뭔지 답할 수 있어?\n",
      "챗봇: 사람 마다 다르 겠 지만 사귀 고 난 후 가 좋 겠 어요.\n",
      "사용자: 나랑 사귀자고? 갑자기 고백을 하다니...!\n",
      "챗봇: 사랑 의 예의 가 없 네요.\n",
      "사용자: 사랑이 뭔데? 너가 사랑을 알아?\n",
      "챗봇: 사랑 의 예의 가 없 네요.\n",
      "사용자: 내가 너무 기대가 컸네ㅎㅎ 그래도 오늘 하루 수고했어~\n",
      "챗봇: 마음 의 준비 를 하 세요.\n",
      "사용자: 그래^^ 안녕!!\n",
      "챗봇: 돈 을 얼른 모아야 할 이유 가 생겼 네요.\n",
      "사용자: 돈은 왜 모으려고?\n",
      "응답 품질 문제: 질문과 응답의 관련성이 낮고 응답이 짧습니다.\n",
      "챗봇: 연락 해보 세요.\n",
      "대화가 종료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import random\n",
    "\n",
    "# NLTK 다운로드\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 형태소 결합 후처리 함수\n",
    "def postprocess_korean_response(morpheme_response):\n",
    "    # 특수 패턴 처리\n",
    "    patterns = {\n",
    "        '저 도': '저도',\n",
    "        '것 이': '것이',\n",
    "        '수 있': '수있',\n",
    "        '것 같': '것같',\n",
    "        '해 보': '해보',\n",
    "        '해 주': '해주',\n",
    "        '되 어': '되어',\n",
    "        '하 지': '하지',\n",
    "        '하 는': '하는',\n",
    "        '이 에요': '이에요',\n",
    "        '가 요': '가요',\n",
    "        '어 요': '어요',\n",
    "        '네 요': '네요'\n",
    "    }\n",
    "    \n",
    "    processed = morpheme_response\n",
    "    for pattern, replacement in patterns.items():\n",
    "        processed = processed.replace(pattern, replacement)\n",
    "    \n",
    "    # 공백 정리\n",
    "    processed = re.sub(r'\\s+', ' ', processed)\n",
    "    processed = re.sub(r'\\s([.,!?])', r'\\1', processed)\n",
    "    \n",
    "    return processed\n",
    "\n",
    "# 개선된 빔 서치 디코더 (다양성 및 창의성 향상)\n",
    "def beam_search_decoder(sentence, beam_width=5, max_length=MAX_LENGTH, temperature=0.8, top_p=0.9):\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_korean_text(sentence)\n",
    "    \n",
    "    # 형태소 분석 적용\n",
    "    sentence = enhanced_morpheme_tokenize(sentence)\n",
    "    \n",
    "    # 정수 인코딩 후 시작 토큰과 종료 토큰 추가\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "    \n",
    "    # 초기 상태: 시작 토큰\n",
    "    initial_state = tf.expand_dims(START_TOKEN, 0)\n",
    "    \n",
    "    # 초기 빔: [(시퀀스, 점수)]\n",
    "    beams = [(initial_state, 0.0)]\n",
    "    \n",
    "    # 빔 서치 반복\n",
    "    for _ in range(max_length):\n",
    "        candidates = []\n",
    "        \n",
    "        # 현재 빔의 각 시퀀스에 대해\n",
    "        for seq, score in beams:\n",
    "            # 종료 토큰이 이미 있으면 후보에 추가하고 계속\n",
    "            if END_TOKEN[0] in seq[0][1:]:\n",
    "                candidates.append((seq, score))\n",
    "                continue\n",
    "            \n",
    "            # 모델 예측\n",
    "            predictions = model(inputs=[sentence, seq], training=False)\n",
    "            predictions = predictions[:, -1, :]\n",
    "            \n",
    "            # 온도 조절 적용 (다양성 향상)\n",
    "            predictions = predictions / temperature\n",
    "            \n",
    "            # top_p 샘플링 적용 (다양성 향상)\n",
    "            probs = tf.nn.softmax(predictions[0])\n",
    "            sorted_indices = tf.argsort(probs, direction='DESCENDING')\n",
    "            sorted_probs = tf.sort(probs, direction='DESCENDING')\n",
    "            cumulative_probs = tf.cumsum(sorted_probs)\n",
    "            \n",
    "            # top_p 기준으로 토큰 필터링\n",
    "            sorted_indices_to_keep = cumulative_probs <= top_p\n",
    "            \n",
    "            # 최소 하나의 토큰은 유지\n",
    "            sorted_indices_to_keep = tf.concat(\n",
    "                [tf.ones(1, dtype=tf.bool), sorted_indices_to_keep[1:]], axis=0)\n",
    "            \n",
    "            # 필터링된 인덱스만 유지\n",
    "            indices_to_keep = tf.boolean_mask(sorted_indices, sorted_indices_to_keep)\n",
    "            \n",
    "            # 상위 beam_width개 토큰 선택 (최대 필터링된 토큰 수까지)\n",
    "            k = tf.minimum(tf.shape(indices_to_keep)[0], beam_width)\n",
    "            top_k_indices = indices_to_keep[:k]\n",
    "            top_k_probs = tf.gather(probs, top_k_indices)\n",
    "            \n",
    "            # 각 후보에 대해\n",
    "            for i in range(k):\n",
    "                # 새 토큰 추가\n",
    "                new_seq = tf.concat([seq, tf.reshape(top_k_indices[i], (1, 1))], axis=-1)\n",
    "                # 로그 확률 합산 (점수)\n",
    "                new_score = score + tf.math.log(top_k_probs[i])\n",
    "                candidates.append((new_seq, new_score))\n",
    "        \n",
    "        # 후보들 중 상위 beam_width개 선택\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        beams = candidates[:beam_width]\n",
    "        \n",
    "        # 모든 빔이 종료 토큰을 가지면 중단\n",
    "        if all(END_TOKEN[0] in seq[0][1:] for seq, _ in beams):\n",
    "            break\n",
    "    \n",
    "    # 최고 점수 시퀀스 선택\n",
    "    best_seq, _ = beams[0]\n",
    "    \n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환\n",
    "    best_seq = tf.squeeze(best_seq, axis=0)\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in best_seq if i < tokenizer.vocab_size and i != START_TOKEN[0]])\n",
    "    \n",
    "    # 후처리 적용\n",
    "    predicted_sentence = postprocess_korean_response(predicted_sentence)\n",
    "    \n",
    "    return predicted_sentence\n",
    "\n",
    "# 기존 디코더 추론 함수 (비교용)\n",
    "def decoder_inference(sentence):\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_korean_text(sentence)\n",
    "    \n",
    "    # 형태소 분석 적용\n",
    "    sentence = enhanced_morpheme_tokenize(sentence)\n",
    "    \n",
    "    # 정수 인코딩 후 시작 토큰과 종료 토큰 추가\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "    \n",
    "    # 디코더의 현재까지 예측한 출력 시퀀스\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "    \n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        \n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        \n",
    "        # 현재 예측한 단어가 종료 토큰이면 for문 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "            \n",
    "        # 예측한 단어를 output_sequence에 추가\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "    \n",
    "    return tf.squeeze(output_sequence, axis=0)\n",
    "\n",
    "# 기존 문장 생성 함수 (비교용)\n",
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해 디코더를 동작시켜 예측된 정수 시퀀스를 리턴받음\n",
    "    prediction = decoder_inference(sentence)\n",
    "    \n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size and i != START_TOKEN[0]])\n",
    "    \n",
    "    # 후처리 적용\n",
    "    predicted_sentence = postprocess_korean_response(predicted_sentence)\n",
    "    \n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 (그리디 디코딩) : {}'.format(predicted_sentence))\n",
    "    \n",
    "    return predicted_sentence\n",
    "\n",
    "# 향상된 문장 생성 함수 (빔 서치 사용)\n",
    "def improved_sentence_generation(sentence):\n",
    "    # 그리디 디코딩 결과\n",
    "    greedy_result = sentence_generation(sentence)\n",
    "    \n",
    "    # 빔 서치 디코딩 결과\n",
    "    beam_result = beam_search_decoder(sentence, beam_width=5)\n",
    "    \n",
    "    print('출력 (빔 서치) : {}'.format(beam_result))\n",
    "    \n",
    "    return beam_result\n",
    "\n",
    "# 응답 품질 평가 함수\n",
    "def evaluate_response_quality(question, response):\n",
    "    # 1. 응답 길이 평가\n",
    "    if len(response.split()) < 3:\n",
    "        return False, \"응답이 너무 짧습니다.\"\n",
    "    \n",
    "    # 2. 질문-응답 관련성 평가 (간단한 키워드 기반)\n",
    "    question_keywords = set(enhanced_morpheme_tokenize(question).split())\n",
    "    response_keywords = set(enhanced_morpheme_tokenize(response).split())\n",
    "    \n",
    "    # 공통 키워드 비율 계산\n",
    "    common_keywords = question_keywords.intersection(response_keywords)\n",
    "    if len(question_keywords) > 0:\n",
    "        keyword_overlap = len(common_keywords) / len(question_keywords)\n",
    "    else:\n",
    "        keyword_overlap = 0\n",
    "    \n",
    "    # 3. 응답 다양성 평가\n",
    "    common_responses = [\"저도요\", \"마음이 복잡하겠어요\", \"같이 가보세요\"]\n",
    "    if response in common_responses:\n",
    "        return False, \"너무 일반적인 응답입니다.\"\n",
    "    \n",
    "    # 종합 평가\n",
    "    if keyword_overlap < 0.1 and len(response.split()) < 5:\n",
    "        return False, \"질문과 응답의 관련성이 낮고 응답이 짧습니다.\"\n",
    "    \n",
    "    return True, \"응답 품질이 적절합니다.\"\n",
    "\n",
    "# 감정별 공감 응답 템플릿\n",
    "empathy_templates = {\n",
    "    '기쁨': [\"정말 기쁘시겠네요!\", \"좋은 일이 있으셨군요, 축하드려요.\"],\n",
    "    '슬픔': [\"많이 힘드시겠어요. 위로의 말씀 드립니다.\", \"그런 상황이라면 정말 마음이 아프겠네요.\"],\n",
    "    '분노': [\"화가 나는 상황이었군요. 충분히 이해됩니다.\", \"그런 일이 있으셨군요. 정말 화나셨겠어요.\"],\n",
    "    '불안': [\"걱정이 많으시군요. 함께 생각해볼까요?\", \"불안한 마음이 드는 건 자연스러운 일이에요.\"],\n",
    "    '중립': [\"어떤 생각을 하고 계신가요?\", \"더 자세히 말씀해주실 수 있을까요?\"]\n",
    "}\n",
    "\n",
    "# 주제별 응답 템플릿\n",
    "topic_templates = {\n",
    "    '학업': [\"공부하느라 정말 고생 많으시네요.\", \"학업에 열중하는 모습이 멋집니다.\"],\n",
    "    '건강': [\"건강이 최우선입니다.\", \"규칙적인 생활습관이 중요해요.\"],\n",
    "    '연애': [\"사랑은 타이밍이 중요한 것 같아요.\", \"진심을 전하는 게 가장 중요하지 않을까요?\"],\n",
    "    '일상': [\"소소한 일상의 행복이 가장 중요하죠.\", \"일상의 작은 변화가 큰 기쁨이 될 수 있어요.\"],\n",
    "    '직장': [\"일과 삶의 균형이 중요해요.\", \"업무에 최선을 다하는 모습이 멋집니다.\"],\n",
    "    '취미': [\"취미 생활은 삶의 활력소가 되죠.\", \"자신만의 시간을 갖는 것은 중요합니다.\"]\n",
    "}\n",
    "\n",
    "# 대화 전략 관리자 클래스\n",
    "class ConversationStrategyManager:\n",
    "    def __init__(self):\n",
    "        self.strategies = {\n",
    "            '정보수집': self.information_gathering_strategy,\n",
    "            '공감': self.empathy_strategy,\n",
    "            '문제해결': self.problem_solving_strategy,\n",
    "            '일상대화': self.casual_conversation_strategy\n",
    "        }\n",
    "        self.current_strategy = '일상대화'\n",
    "        \n",
    "    def select_strategy(self, user_input, conversation_history):\n",
    "        # 사용자 입력과 대화 기록을 분석하여 적절한 전략 선택\n",
    "        if any(word in user_input for word in ['어떻게', '방법', '알려줘']):\n",
    "            return '정보수집'\n",
    "        elif any(word in user_input for word in ['슬퍼', '힘들어', '아파']):\n",
    "            return '공감'\n",
    "        elif any(word in user_input for word in ['문제', '해결', '도와줘']):\n",
    "            return '문제해결'\n",
    "        else:\n",
    "            return '일상대화'\n",
    "    \n",
    "    def apply_strategy(self, strategy, user_input, conversation_history):\n",
    "        strategy_func = self.strategies.get(strategy, self.casual_conversation_strategy)\n",
    "        return strategy_func(user_input, conversation_history)\n",
    "    \n",
    "    # 각 전략별 구현\n",
    "    def information_gathering_strategy(self, user_input, conversation_history):\n",
    "        # 정보 수집을 위한 질문 생성\n",
    "        return \"더 자세히 알려주실 수 있을까요? 어떤 정보가 필요하신가요?\"\n",
    "    \n",
    "    def empathy_strategy(self, user_input, conversation_history):\n",
    "        # 감정 분석 후 공감 응답 생성\n",
    "        emotion = analyze_emotion(user_input)\n",
    "        return random.choice(empathy_templates[emotion])\n",
    "    \n",
    "    def problem_solving_strategy(self, user_input, conversation_history):\n",
    "        # 문제 해결을 위한 단계적 접근\n",
    "        return \"그 문제를 해결하기 위해 어떤 시도를 해보셨나요?\"\n",
    "    \n",
    "    def casual_conversation_strategy(self, user_input, conversation_history):\n",
    "        # 일상적인 대화 응답 생성\n",
    "        return beam_search_decoder(user_input)\n",
    "\n",
    "# 대화 맥락 관리 클래스\n",
    "class ConversationManager:\n",
    "    def __init__(self, max_history=5):\n",
    "        self.history = []\n",
    "        self.max_history = max_history\n",
    "        self.strategy_manager = ConversationStrategyManager()\n",
    "        \n",
    "    def add_message(self, role, content):\n",
    "        self.history.append({\"role\": role, \"content\": content})\n",
    "        if len(self.history) > self.max_history * 2:  # 각 턴은 사용자와 챗봇 메시지로 구성\n",
    "            self.history = self.history[-self.max_history * 2:]\n",
    "            \n",
    "    def get_context(self):\n",
    "        return \" \".join([msg[\"content\"] for msg in self.history])\n",
    "    \n",
    "    def get_last_user_message(self):\n",
    "        for msg in reversed(self.history):\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                return msg[\"content\"]\n",
    "        return \"\"\n",
    "    \n",
    "    def generate_response(self, user_input):\n",
    "        # 사용자 메시지 추가\n",
    "        self.add_message(\"user\", user_input)\n",
    "        \n",
    "        # 대화 맥락 구성\n",
    "        context = self.get_context()\n",
    "        \n",
    "        # 대화 전략 선택\n",
    "        strategy = self.strategy_manager.select_strategy(user_input, self.history)\n",
    "        \n",
    "        # 전략에 따른 응답 생성\n",
    "        response = self.strategy_manager.apply_strategy(strategy, user_input, self.history)\n",
    "        \n",
    "        # 응답 품질 평가\n",
    "        is_quality, message = evaluate_response_quality(user_input, response)\n",
    "        \n",
    "        # 품질이 낮으면 빔 서치로 다시 생성\n",
    "        if not is_quality:\n",
    "            print(f\"응답 품질 문제: {message}\")\n",
    "            response = beam_search_decoder(context if len(context) > 0 else user_input)\n",
    "        \n",
    "        # 챗봇 메시지 추가\n",
    "        self.add_message(\"assistant\", response)\n",
    "        \n",
    "        return response\n",
    "\n",
    "# 개선된 대화 인터페이스\n",
    "def enhanced_interactive_chat(max_turns=10):\n",
    "    # 대화 관리자 초기화\n",
    "    conversation_manager = ConversationManager()\n",
    "    \n",
    "    print(\"챗봇과 대화를 시작합니다. '종료'를 입력하면 대화가 종료됩니다.\")\n",
    "    \n",
    "    for turn in range(max_turns):\n",
    "        # 사용자 입력\n",
    "        user_input = input(\"사용자: \")\n",
    "        \n",
    "        if user_input.lower() == '종료':\n",
    "            print(\"대화를 종료합니다.\")\n",
    "            break\n",
    "        \n",
    "        # 대화 관리자를 통한 응답 생성\n",
    "        bot_response = conversation_manager.generate_response(user_input)\n",
    "        \n",
    "        print(f\"챗봇: {bot_response}\")\n",
    "    \n",
    "    print(\"대화가 종료되었습니다.\")\n",
    "\n",
    "# BLEU 점수 계산 함수\n",
    "def calculate_bleu(reference, candidate):\n",
    "    # 토큰화\n",
    "    reference_tokens = reference.split()\n",
    "    candidate_tokens = candidate.split()\n",
    "    \n",
    "    # BLEU 점수 계산 (스무딩 적용)\n",
    "    smoothie = SmoothingFunction().method1\n",
    "    try:\n",
    "        bleu1 = sentence_bleu([reference_tokens], candidate_tokens, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "        bleu2 = sentence_bleu([reference_tokens], candidate_tokens, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie)\n",
    "    except:\n",
    "        bleu1, bleu2 = 0, 0\n",
    "    \n",
    "    return bleu1, bleu2\n",
    "\n",
    "# 모델 평가\n",
    "def evaluate_model():\n",
    "    # 테스트 세트 생성 (원본 데이터에서 랜덤 샘플링)\n",
    "    np.random.seed(42)\n",
    "    test_indices = np.random.choice(len(data), 100, replace=False)\n",
    "    test_questions = [data.loc[i, 'Q'] for i in test_indices]\n",
    "    test_answers = [data.loc[i, 'A'] for i in test_indices]\n",
    "    \n",
    "    # 평가 지표 저장\n",
    "    greedy_bleu1_scores = []\n",
    "    greedy_bleu2_scores = []\n",
    "    beam_bleu1_scores = []\n",
    "    beam_bleu2_scores = []\n",
    "    \n",
    "    print(\"모델 평가 중...\")\n",
    "    \n",
    "    for i, (question, reference) in enumerate(zip(test_questions, test_answers)):\n",
    "        # 그리디 디코딩\n",
    "        greedy_result = sentence_generation(question)\n",
    "        \n",
    "        # 빔 서치 디코딩\n",
    "        beam_result = beam_search_decoder(question)\n",
    "        \n",
    "        # BLEU 점수 계산\n",
    "        greedy_bleu1, greedy_bleu2 = calculate_bleu(reference, greedy_result)\n",
    "        beam_bleu1, beam_bleu2 = calculate_bleu(reference, beam_result)\n",
    "        \n",
    "        greedy_bleu1_scores.append(greedy_bleu1)\n",
    "        greedy_bleu2_scores.append(greedy_bleu2)\n",
    "        beam_bleu1_scores.append(beam_bleu1)\n",
    "        beam_bleu2_scores.append(beam_bleu2)\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"평가 진행: {i+1}/100\")\n",
    "    \n",
    "    # 결과 요약\n",
    "    print(\"\\n===== 평가 결과 =====\")\n",
    "    print(f\"그리디 디코딩 평균 BLEU-1: {np.mean(greedy_bleu1_scores):.4f}\")\n",
    "    print(f\"그리디 디코딩 평균 BLEU-2: {np.mean(greedy_bleu2_scores):.4f}\")\n",
    "    print(f\"빔 서치 디코딩 평균 BLEU-1: {np.mean(beam_bleu1_scores):.4f}\")\n",
    "    print(f\"빔 서치 디코딩 평균 BLEU-2: {np.mean(beam_bleu2_scores):.4f}\")\n",
    "    \n",
    "    # 결과 시각화\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(['그리디 BLEU-1', '빔 서치 BLEU-1'], \n",
    "            [np.mean(greedy_bleu1_scores), np.mean(beam_bleu1_scores)])\n",
    "    plt.title('BLEU-1 점수 비교')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(['그리디 BLEU-2', '빔 서치 BLEU-2'], \n",
    "            [np.mean(greedy_bleu2_scores), np.mean(beam_bleu2_scores)])\n",
    "    plt.title('BLEU-2 점수 비교')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 테스트 문장으로 모델 평가\n",
    "test_sentences = [\n",
    "    '안녕하세요',\n",
    "    '오늘 날씨가 어때요?',\n",
    "    '내일 시간 있으세요?',\n",
    "    '영화 보러 갈래요?',\n",
    "    '맛있는 음식점 추천해주세요'\n",
    "]\n",
    "\n",
    "print(\"\\n===== 테스트 문장 평가 =====\")\n",
    "for test_sentence in test_sentences:\n",
    "    improved_sentence_generation(test_sentence)\n",
    "\n",
    "# 전체 모델 평가 실행\n",
    "evaluate_model()\n",
    "\n",
    "# 대화 인터페이스 실행\n",
    "print(\"\\n===== 대화 인터페이스 =====\")\n",
    "enhanced_interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
