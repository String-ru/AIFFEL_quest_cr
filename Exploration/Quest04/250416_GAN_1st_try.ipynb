{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2c7c9d",
   "metadata": {},
   "source": [
    "# STEP 1. 작업환경 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48e332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/aiffel/dcgan_newimage/cifar10/generated_samples\n",
    "!mkdir -p ~/aiffel/dcgan_newimage/cifar10/training_checkpoints\n",
    "!mkdir -p ~/aiffel/dcgan_newimage/cifar10/training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e2d2f1",
   "metadata": {},
   "source": [
    "# STEP 2. 데이터셋 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe736d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# CIFAR-10 데이터셋 불러오기\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(train_x, _), (test_x, _) = cifar10.load_data()\n",
    "print(train_x.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2225a7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습에 사용할 train_x의 이미지를 -1, 1로 정규화\n",
    "train_x = (train_x - 127.5) / 127.5\n",
    "\n",
    "# 로드한 학습 데이터 시각화로 확인\n",
    "plt.imshow((train_x[0] * 127.5 + 127.5).astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.savefig('first_image.png')  # Jupyter에서 시각화 확인용 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5123c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data.Dataset으로 미니배치 데이터셋 구성\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 50000\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_x).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f861215",
   "metadata": {},
   "source": [
    "# STEP 3. 생성자 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40aa368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((8, 8, 256)))\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ca764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 노이즈로 이미지 생성\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "print(generated_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36998e",
   "metadata": {},
   "source": [
    "# STEP 4. 판별자 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e76550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[32, 32, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84cb4f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00200354]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 생성된 랜덤 이미지 판별 결과 확인\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a224e70",
   "metadata": {},
   "source": [
    "# STEP 5. 손실함수와 최적화 함수 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c11101",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_accuracy(real_output, fake_output):\n",
    "    real_accuracy = tf.reduce_mean(tf.cast(tf.math.greater_equal(real_output, 0.5), tf.float32))\n",
    "    fake_accuracy = tf.reduce_mean(tf.cast(tf.math.less(fake_output, 0.5), tf.float32))\n",
    "    return (real_accuracy + fake_accuracy) / 2.0\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9ee63",
   "metadata": {},
   "source": [
    "# STEP 6. 훈련과정 상세 기능 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddacf363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    return gen_loss, disc_loss, discriminator_accuracy(real_output, fake_output)\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input, save_dir):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        img = (predictions[i] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.savefig(os.path.join(save_dir, f'image_at_epoch_{epoch:04d}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "def draw_train_history(history, epoch, save_dir):\n",
    "    plt.figure()\n",
    "    plt.plot(history['gen_loss'], label='Generator Loss')\n",
    "    plt.plot(history['disc_loss'], label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, f'loss_at_epoch_{epoch:04d}.png'))\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    plt.plot(history['disc_accuracy'], label='Discriminator Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, f'accuracy_at_epoch_{epoch:04d}.png'))\n",
    "    plt.close()\n",
    "\n",
    "checkpoint_dir = os.path.expanduser('~/aiffel/dcgan_newimage/cifar10/training_checkpoints')\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a413aa",
   "metadata": {},
   "source": [
    "# STEP 7. 학습 과정 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3db30ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Gen Loss: 0.9690486192703247, Disc Loss: 1.106738805770874, Disc Accuracy: 0.711359977722168\n",
      "Epoch 2, Gen Loss: 1.7266546487808228, Disc Loss: 0.776763916015625, Disc Accuracy: 0.8132792711257935\n",
      "Epoch 3, Gen Loss: 1.7833011150360107, Disc Loss: 0.6056503653526306, Disc Accuracy: 0.8819116950035095\n",
      "Epoch 4, Gen Loss: 1.9430433511734009, Disc Loss: 0.6563794612884521, Disc Accuracy: 0.8644770383834839\n",
      "Epoch 5, Gen Loss: 1.9298081398010254, Disc Loss: 0.7163292765617371, Disc Accuracy: 0.851375162601471\n",
      "Epoch 6, Gen Loss: 1.6751601696014404, Disc Loss: 0.7579068541526794, Disc Accuracy: 0.8408940434455872\n",
      "Epoch 7, Gen Loss: 1.5835198163986206, Disc Loss: 0.852989137172699, Disc Accuracy: 0.8152742385864258\n",
      "Epoch 8, Gen Loss: 1.4792627096176147, Disc Loss: 0.838854193687439, Disc Accuracy: 0.8097895383834839\n",
      "Epoch 9, Gen Loss: 1.5966918468475342, Disc Loss: 0.8042907118797302, Disc Accuracy: 0.8185586929321289\n",
      "Epoch 10, Gen Loss: 1.5653830766677856, Disc Loss: 0.8663508892059326, Disc Accuracy: 0.8033860921859741\n",
      "Epoch 11, Gen Loss: 1.703365445137024, Disc Loss: 0.8108904957771301, Disc Accuracy: 0.8250478506088257\n",
      "Epoch 12, Gen Loss: 1.6890772581100464, Disc Loss: 0.8523778915405273, Disc Accuracy: 0.8115811944007874\n",
      "Epoch 13, Gen Loss: 1.6457581520080566, Disc Loss: 0.7765412330627441, Disc Accuracy: 0.8371611833572388\n",
      "Epoch 14, Gen Loss: 1.6540727615356445, Disc Loss: 0.7526718378067017, Disc Accuracy: 0.8371432423591614\n",
      "Epoch 15, Gen Loss: 1.6070332527160645, Disc Loss: 0.7632327675819397, Disc Accuracy: 0.8410455584526062\n",
      "Epoch 16, Gen Loss: 1.4549657106399536, Disc Loss: 0.973461925983429, Disc Accuracy: 0.7716338634490967\n",
      "Epoch 17, Gen Loss: 1.3694666624069214, Disc Loss: 1.0120444297790527, Disc Accuracy: 0.75830078125\n",
      "Epoch 18, Gen Loss: 1.3684508800506592, Disc Loss: 1.0164785385131836, Disc Accuracy: 0.7607641220092773\n",
      "Epoch 19, Gen Loss: 1.3181432485580444, Disc Loss: 1.0193963050842285, Disc Accuracy: 0.7594208121299744\n",
      "Epoch 20, Gen Loss: 1.2913001775741577, Disc Loss: 1.0750858783721924, Disc Accuracy: 0.7296296954154968\n",
      "Epoch 21, Gen Loss: 1.2536691427230835, Disc Loss: 1.0929815769195557, Disc Accuracy: 0.7173289656639099\n",
      "Epoch 22, Gen Loss: 1.2911914587020874, Disc Loss: 1.058950424194336, Disc Accuracy: 0.7418028116226196\n",
      "Epoch 23, Gen Loss: 1.299924612045288, Disc Loss: 1.0895791053771973, Disc Accuracy: 0.7413205504417419\n",
      "Epoch 24, Gen Loss: 1.3301239013671875, Disc Loss: 1.0673421621322632, Disc Accuracy: 0.7479910850524902\n",
      "Epoch 25, Gen Loss: 1.3043063879013062, Disc Loss: 0.9774327278137207, Disc Accuracy: 0.7763751149177551\n",
      "Epoch 26, Gen Loss: 1.3410207033157349, Disc Loss: 1.0657176971435547, Disc Accuracy: 0.7303271889686584\n",
      "Epoch 27, Gen Loss: 1.1714859008789062, Disc Loss: 1.0562372207641602, Disc Accuracy: 0.7536750435829163\n",
      "Epoch 28, Gen Loss: 1.2865726947784424, Disc Loss: 1.1034618616104126, Disc Accuracy: 0.7199617624282837\n",
      "Epoch 29, Gen Loss: 1.337039589881897, Disc Loss: 1.0558960437774658, Disc Accuracy: 0.7403917908668518\n",
      "Epoch 30, Gen Loss: 1.3292407989501953, Disc Loss: 1.0457401275634766, Disc Accuracy: 0.746410608291626\n",
      "Epoch 31, Gen Loss: 1.3186736106872559, Disc Loss: 1.0403980016708374, Disc Accuracy: 0.7479910850524902\n",
      "Epoch 32, Gen Loss: 1.3631657361984253, Disc Loss: 0.9402743577957153, Disc Accuracy: 0.7817602157592773\n",
      "Epoch 33, Gen Loss: 1.3830417394638062, Disc Loss: 1.0034180879592896, Disc Accuracy: 0.753523588180542\n",
      "Epoch 34, Gen Loss: 1.4497873783111572, Disc Loss: 0.9402074217796326, Disc Accuracy: 0.7769531011581421\n",
      "Epoch 35, Gen Loss: 1.4070804119110107, Disc Loss: 0.9834929704666138, Disc Accuracy: 0.7639548778533936\n",
      "Epoch 36, Gen Loss: 1.4063297510147095, Disc Loss: 0.9907486438751221, Disc Accuracy: 0.7607800364494324\n",
      "Epoch 37, Gen Loss: 1.4905623197555542, Disc Loss: 0.9419846534729004, Disc Accuracy: 0.7837252616882324\n",
      "Epoch 38, Gen Loss: 1.3739635944366455, Disc Loss: 1.0088024139404297, Disc Accuracy: 0.7691825032234192\n",
      "Epoch 39, Gen Loss: 1.5357983112335205, Disc Loss: 0.9832313060760498, Disc Accuracy: 0.765031099319458\n",
      "Epoch 40, Gen Loss: 1.4745380878448486, Disc Loss: 1.026389479637146, Disc Accuracy: 0.7645986080169678\n",
      "Epoch 41, Gen Loss: 1.4667105674743652, Disc Loss: 0.9521446824073792, Disc Accuracy: 0.780781626701355\n",
      "Epoch 42, Gen Loss: 1.508009672164917, Disc Loss: 0.9417376518249512, Disc Accuracy: 0.7806301712989807\n",
      "Epoch 43, Gen Loss: 1.4904265403747559, Disc Loss: 1.0020042657852173, Disc Accuracy: 0.7592215538024902\n",
      "Epoch 44, Gen Loss: 1.4247299432754517, Disc Loss: 1.0051486492156982, Disc Accuracy: 0.7574976086616516\n",
      "Epoch 45, Gen Loss: 1.4463831186294556, Disc Loss: 0.9450002908706665, Disc Accuracy: 0.7834063768386841\n",
      "Epoch 46, Gen Loss: 1.437577486038208, Disc Loss: 1.0122768878936768, Disc Accuracy: 0.7511399984359741\n",
      "Epoch 47, Gen Loss: 1.4611088037490845, Disc Loss: 0.9435954093933105, Disc Accuracy: 0.7766501903533936\n",
      "Epoch 48, Gen Loss: 1.5853550434112549, Disc Loss: 0.9295178651809692, Disc Accuracy: 0.7830795645713806\n",
      "Epoch 49, Gen Loss: 1.6102601289749146, Disc Loss: 0.9808415770530701, Disc Accuracy: 0.7666832804679871\n",
      "Epoch 50, Gen Loss: 1.4424388408660889, Disc Loss: 1.0735268592834473, Disc Accuracy: 0.7357023358345032\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "save_every = 5\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "history = {'gen_loss': [], 'disc_loss': [], 'disc_accuracy': []}\n",
    "generated_samples_dir = os.path.expanduser('~/aiffel/dcgan_newimage/cifar10/generated_samples')\n",
    "training_history_dir = os.path.expanduser('~/aiffel/dcgan_newimage/cifar10/training_history')\n",
    "\n",
    "def train(dataset, epochs, save_every):\n",
    "    for epoch in range(epochs):\n",
    "        gen_loss_list = []\n",
    "        disc_loss_list = []\n",
    "        disc_accuracy_list = []\n",
    "        for image_batch in dataset:\n",
    "            g_loss, d_loss, d_acc = train_step(image_batch)\n",
    "            gen_loss_list.append(g_loss)\n",
    "            disc_loss_list.append(d_loss)\n",
    "            disc_accuracy_list.append(d_acc)\n",
    "        history['gen_loss'].append(np.mean(gen_loss_list))\n",
    "        history['disc_loss'].append(np.mean(disc_loss_list))\n",
    "        history['disc_accuracy'].append(np.mean(disc_accuracy_list))\n",
    "        generate_and_save_images(generator, epoch + 1, seed, generated_samples_dir)\n",
    "        draw_train_history(history, epoch + 1, training_history_dir)\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "        print(f'Epoch {epoch+1}, Gen Loss: {history[\"gen_loss\"][-1]}, Disc Loss: {history[\"disc_loss\"][-1]}, Disc Accuracy: {history[\"disc_accuracy\"][-1]}')\n",
    "\n",
    "train(train_dataset, EPOCHS, save_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4f8b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 과정 시각화 (GIF 생성)\n",
    "import imageio\n",
    "\n",
    "def make_gif(images_dir, gif_name):\n",
    "    images = []\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        filename = os.path.join(images_dir, f'image_at_epoch_{epoch:04d}.png')\n",
    "        images.append(imageio.imread(filename))\n",
    "    imageio.mimsave(gif_name, images, fps=5)\n",
    "\n",
    "make_gif(generated_samples_dir, 'cifar10_dcgan.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb38a364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습된 모델 로드 및 이미지 생성\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "checkpoint.restore(latest)\n",
    "generator = checkpoint.generator\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "np_generated = generated_image.numpy()\n",
    "np_generated = (np_generated * 127.5 + 127.5).astype(np.uint8)\n",
    "plt.imshow(np_generated[0])\n",
    "plt.axis('off')\n",
    "plt.savefig('generated_image.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ea3c3",
   "metadata": {},
   "source": [
    "## 학습이 불안정한 결과\n",
    "\n",
    "### 생성자 손실 (Gen Loss)\n",
    "Epoch 1: 0.969 → Epoch 50: 1.442\n",
    "중간에 Epoch 4에서 1.943까지 증가한 후 점차 감소하다가 다시 약간 증가하는 추세\n",
    "전체적으로 손실이 안정화되지 않고 변동이 큼\n",
    "\n",
    "### 판별자 손실 (Disc Loss)\n",
    "Epoch 1: 1.106 → Epoch 50: 1.073\n",
    "Epoch 3에서 0.605까지 내려갔다가 다시 증가하며 1.0 근처에서 변동이 있음\n",
    "판별자도 손실이 일정하게 수렴하지 않고 오르내림\n",
    "\n",
    "### 판별자 정확도 (Disc Accuracy)\n",
    "Epoch 1: 0.711 → Epoch 50: 0.735\n",
    "Epoch 3에서 0.882로 최고점을 찍은 후 점차 감소하며 0.7~0.8 사이를 맴돌고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c757f",
   "metadata": {},
   "source": [
    "## Step8. (optional) GAN 훈련 과정 개선하기\n",
    "\n",
    "### 1. 학습률 조정\n",
    "현재 생성자와 판별자의 학습률이 서로 균형을 맞추지 못했을 가능성이 있음\n",
    "ex) 생성자의 학습률을 조금 낮추거나(예: 0.0001), 판별자의 학습률을 살짝 높여서(예: 0.0004) 둘의 균형을 조정 가능\n",
    "\n",
    "### 2. 모델 구조 변경\n",
    "생성자나 판별자의 네트워크를 조금 더 깊게 만들거나(레이어 추가), 필터 수를 늘려서 모델의 표현력을 키워볼 수 있음\n",
    "ex) 생성자에 컨볼루션 레이어를 하나 더 추가하거나 판별자의 필터를 64개에서 128개로 늘리는 식으로 실험 가능\n",
    "\n",
    "### 3. 정규화 기법 사용\n",
    "배치 정규화(Batch Normalization)나 드롭아웃(Dropout)을 추가해서 모델이 과적합되거나 불안정해지는 걸 줄일 수 있음\n",
    "ex) 판별자에 드롭아웃(예: 0.3)을 넣으면 과도하게 강해지는 걸 막을 수 있음\n",
    "\n",
    "### 4. 학습 데이터 증강\n",
    "ex) 이미지 회전, 뒤집기, 자르기 같은 증강 기법을 써서 모델의 일반화 성능을 높일 수 있음\n",
    "\n",
    "### 5. 더 많은 에포크 학습\n",
    "현재: 50 에포크까지 학습\n",
    "ex) 100 에포크 정도 더 학습하면서 손실이 안정화되는지 관찰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad42a1d",
   "metadata": {},
   "source": [
    "# Step8은 다음 파일에서 진행"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
